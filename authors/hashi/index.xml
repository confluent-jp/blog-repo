<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>hashi | Confluent Japan Community</title><link>https://confluent-jp.github.io/community/authors/hashi/</link><atom:link href="https://confluent-jp.github.io/community/authors/hashi/index.xml" rel="self" type="application/rss+xml"/><description>hashi</description><generator>Wowchemy (https://wowchemy.com)</generator><language>ja-jp</language><lastBuildDate>Mon, 30 Oct 2023 00:00:00 +0000</lastBuildDate><image><url>https://confluent-jp.github.io/community/authors/hashi/avatar_hudc0c7c8d0c95e5f09e296b73be3a2ab5_129312_270x270_fill_q75_lanczos_center.jpg</url><title>hashi</title><link>https://confluent-jp.github.io/community/authors/hashi/</link></image><item><title>Apache Flink 1.18 アップデート</title><link>https://confluent-jp.github.io/community/blog/apache-flink-1.8/</link><pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/apache-flink-1.8/</guid><description>&lt;p>Apache Flinkの新バージョン1.18が公開されました。&lt;a href="https://www.confluent.io/blog/announcing-apache-flink-1-18/" target="_blank" rel="noopener">Conflunet Blog&lt;/a>ではその具体的な改善点をエリア毎に詳しく説明しており、ConfluentだけでなくVerverica、Aiven、Alibaba CloudのFlinkコミッターも共著として参加し、結果としてFlinkの情報発信として非常なものとなっております。&lt;/p>
&lt;p>昨年発表されたAkkaのライセンス変更に伴い、&lt;a href="https://flink.apache.org/2022/09/08/regarding-akkas-licensing-change/" target="_blank" rel="noopener">1年前にAkkaの代替模索に入った&lt;/a>Flinkプロジェクト。ようやくAkkaから&lt;a href="https://pekko.apache.org/" target="_blank" rel="noopener">Apache Pekko&lt;/a>に切り替えた節目のリリースとなりました。一方、ストリーム処理/バッチ処理を含め、Flinkのストリーム処理基盤としての成熟度がさらに増す多くの改善も含まれています。&lt;/p>
&lt;p>本エントリでは、一部ではありますがそのうちの幾つかをご紹介します。&lt;/p>
&lt;h3 id="flip-293-introduce-flink-jdbc-driver-for-sql-gatewayhttpscwikiapacheorgconfluencedisplayflinkflip-2933aintroduceflinkjdbcdriverforsqlgateway">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-293%3A&amp;#43;Introduce&amp;#43;Flink&amp;#43;Jdbc&amp;#43;Driver&amp;#43;For&amp;#43;Sql&amp;#43;Gateway" target="_blank" rel="noopener">FLIP-293: Introduce Flink Jdbc Driver For Sql Gateway&lt;/a>&lt;/h3>
&lt;p>FlinkクラスタへのRESTエンドポイントを提供する&lt;a href="https://github.com/ververica/flink-sql-gateway/blob/master/README.md" target="_blank" rel="noopener">Flink SQL Ga†eway&lt;/a>に、新たに汎用的なJDBC経由で通信できる&lt;a href="https://github.com/ververica/flink-jdbc-driver" target="_blank" rel="noopener">Flink JDBC Driver&lt;/a>が接続出来るようになりました。&lt;/p>
&lt;p>これまでSQL Gatewayにはコンソールベースでのアクセスは可能でしたが、セッションを保持したアプリケーションからのアクセスは出来ませんでした。一方JDBC Driverの基本利用はFlink Jobの登録にあり、インタラクティブなクエリはサポートされていませんでした。本FLIPによりこの2者を繋げ、SQL Gateway経由でJDBC接続が可能な多くのデータベースに対してJDBC Driverから接続出来るようになりました。&lt;/p>
&lt;h3 id="flip-311-support-call-stored-procedurehttpscwikiapacheorgconfluencedisplayflinkflip-3113asupportcallstoredprocedure">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-311%3A&amp;#43;Support&amp;#43;Call&amp;#43;Stored&amp;#43;Procedure" target="_blank" rel="noopener">FLIP-311: Support Call Stored Procedure&lt;/a>&lt;/h3>
&lt;p>これまでFlinkから見たデータソースはSourceでありSinkであり、あくまでデータストアという扱いにおける接続に限られました。本FLIPによってFlinkからStored Procedureの一覧取得と実行が可能となります。&lt;/p>
&lt;p>Stored Procedure実行におけるインターフェース変更に合わせ、&lt;a href="https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/table/catalog/Catalog.html" target="_blank" rel="noopener">Catalog Interface&lt;/a>にもStored Procedure用のメソッドが追加されており一覧の取得も可能です。&lt;/p>
&lt;h3 id="flip-308-support-time-travelhttpscwikiapacheorgconfluencedisplayflinkflip-3083asupporttimetravel">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-308%3A&amp;#43;Support&amp;#43;Time&amp;#43;Travel" target="_blank" rel="noopener">FLIP-308: Support Time Travel&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/SQL:2011" target="_blank" rel="noopener">SQL:2011 Standard&lt;/a>のTime Travel Queryがサポートされます。どちらもSQL:2011標準であるようタイムスタンプでの指定となりますが、特定時点ならびに期間指定がサポートされます。&lt;/p>
&lt;p>用途としてはデータレイクに長期格納しているデータに対してFlinkからソースアタッチする際に特定の過去時点でのデータも同様の方法で取得可能となります。IcebergやDelta Lake等、Time Travel Queryをサポートしているストレージに限られた機能となり、またConnectorが新しいインターフェースに沿って実装する必要があります。&lt;/p>
&lt;h3 id="flip-292-enhance-compiled-plan-to-support-operator-level-state-ttl-configurationhttpscwikiapacheorgconfluencedisplayflinkflip-2923aenhancecompiledplantosupportoperator-levelstatettlconfiguration">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-292%3A&amp;#43;Enhance&amp;#43;COMPILED&amp;#43;PLAN&amp;#43;to&amp;#43;support&amp;#43;operator-level&amp;#43;state&amp;#43;TTL&amp;#43;configuration" target="_blank" rel="noopener">FLIP-292: Enhance COMPILED PLAN to support operator-level state TTL configuration&lt;/a>&lt;/h3>
&lt;p>Table APIやSQLを利用してステートフルなストリームパイプラインを構築する際の、ステート管理に関わる改善です。JOINをしたり同じTableデータに異なる条件で集約したりする場合に、そのステートのベースとなるイベントの有効期間 (TTL: Time To Live) の制御によっては処理の対象となるイベントが変わります。&lt;/p>
&lt;p>本FLIPでは、それぞれの対象ソースに対して個別のTTLを設定出来るようになります。これにより要件に即したステート管理を行うことができるようになります。より粒度の細かなスコープの指定や、特定ユースケースにおけるステートストアの大幅な削減等が可能です。&lt;/p>
&lt;h3 id="flip-296-extend-watermark-related-features-for-sqlhttpscwikiapacheorgconfluencedisplayflinkflip-2963aextendwatermark-relatedfeaturesforsql">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-296%3A&amp;#43;Extend&amp;#43;watermark-related&amp;#43;features&amp;#43;for&amp;#43;SQL" target="_blank" rel="noopener">FLIP-296: Extend watermark-related features for SQL&lt;/a>&lt;/h3>
&lt;p>ストリーム処理においてデータの整合性をいかに評価/制御することは極めて重要ですが、Flinkでは&lt;a href="https://www.youtube.com/watch?v=sdhwpUAjqaI" target="_blank" rel="noopener">Event TimeとWatermark&lt;/a>を利用する事により明示的にそれぞれのデータ処理ウィンドウを決定しています。&lt;/p>
&lt;p>Watermarkはその振る舞いを制御する重要な仕組みであり、&lt;a href="https://nightlies.apache.org/flink/flink-docs-release-1.18/docs/dev/datastream/overview/" target="_blank" rel="noopener">DataStream API&lt;/a>であればその&lt;a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/event-time/generating_watermarks/#watermark-alignment" target="_blank" rel="noopener">関連性の定義を制御(Watermark Alignment)&lt;/a>する事も出来ました。但しWatermarkの制御をする為にはローレベルなDataStream APIを利用する必要がありました。&lt;/p>
&lt;p>本FLIPでは、Flink SQLによってその制御を可能とします。具体的にはTable作成時やクエリにアノテーションを指定する事で：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TABLE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_actions&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TIMESTAMP&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">WATERMARK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">FOR&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INTERVAL&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;5&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SECOND&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;scan.watermark.emit.strategy&amp;#39;&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;on-event&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>とWatermark生成インターバルを指定したり：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">source_table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="cm">/*+ OPTIONS(&amp;#39;scan.watermark.emit.strategy&amp;#39;=&amp;#39;on-event&amp;#39;) */&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>SELECT時にWatermarkの出力タイプを指定できます。&lt;/p>
&lt;h3 id="バッチ処理速度改善">バッチ処理速度改善&lt;/h3>
&lt;p>&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-324%3A&amp;#43;Introduce&amp;#43;Runtime&amp;#43;Filter&amp;#43;for&amp;#43;Flink&amp;#43;Batch&amp;#43;Jobs" target="_blank" rel="noopener">FLIP-324: Introduce Runtime Filter for Flink Batch Jobs&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-315&amp;#43;Support&amp;#43;Operator&amp;#43;Fusion&amp;#43;Codegen&amp;#43;for&amp;#43;Flink&amp;#43;SQL" target="_blank" rel="noopener">FLIP-315 Support Operator Fusion Codegen for Flink SQL&lt;/a>&lt;/p>
&lt;p>全バージョン(Flink 1.17)ではバッチ処理におけるスループットが大きく改善しました。その改善は本リリースでも継続して行われており、さらにそのパフォーマンスが向上しています 。今回のリリースにおける主要な改善は：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>FLIP-324&lt;/strong> &lt;a href="https://www.alibabacloud.com/blog/query-performance-optimization-runtime-filter_598126" target="_blank" rel="noopener">Runtime Filter&lt;/a>は集約処理の前段階で対象レコードを絞るアプローチで、これにより集約やJoinにかかるネットワーク通信や必要処理の大規模化を削減する事ができます。このFLIPでは、クエリのプラン中に関連処理の中からローカルでの集約可能な処理を特定し、Runtime Filterとして実行するようになりました。&lt;/li>
&lt;li>&lt;strong>FLIP-315&lt;/strong> 利用可能メモリの増加からCPUの処理能力にボトルネックが移る中、処理プロセスにおける無駄が全体スループットに大きな影響を与えています。幾つかの改善ポイントを評価した結果、ベクター化とコード生成方式のうちコード生成方式の&lt;a href="https://www.vldb.org/pvldb/vol4/p539-neumann.pdf" target="_blank" rel="noopener">Operator Fusion&lt;/a>の実装を導入しました。&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="TPC-DS ベンチマーク結果" srcset="
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_63116ec5b524eace18e376eece97e72f.webp 400w,
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_f70905be7f3875dac26b79cb80bf7b1c.webp 760w,
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_63116ec5b524eace18e376eece97e72f.webp"
width="760"
height="529"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
結果として&lt;a href="https://www.tpc.org/tpcds/" target="_blank" rel="noopener">TPC-DS&lt;/a>のベンチマーク結果がFlink 1.17と比べて13%、1.16とでは35%改善しました。&lt;/p>
&lt;h3 id="おわりに">おわりに&lt;/h3>
&lt;p>今回のご紹介はApache Flink1.18で導入された新機能や改善のごく一部ではありますが、ストリーム処理からバッチ、クラウドネイティブ化に向けた改善等、非常に多岐に渡る改善が含まれています。ksqlDBを知る身としてはFlinkの分散データ処理基盤としての重厚さを感じることにもなりました。是非&lt;a href="https://www.confluent.io/blog/announcing-apache-flink-1-18/" target="_blank" rel="noopener">オリジナルのブログ&lt;/a>もご覧ください。&lt;/p></description></item><item><title>Apache Kafka 3.6 アップデート</title><link>https://confluent-jp.github.io/community/blog/apache-kafka-3.6/</link><pubDate>Thu, 12 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/apache-kafka-3.6/</guid><description>&lt;p>Apache Kafkaの新バージョン3.6が公開されました。
ZookeeperモードからKRaftモードへの移行ではありますが、KRaftの強化だけでなく新たな機能も多く追加されております。詳細は&lt;a href="https://www.confluent.io/blog/introducing-apache-kafka-3-6/" target="_blank" rel="noopener">Confluentのアナウンスメント&lt;/a>と&lt;a href="https://www.youtube.com/watch?v=GW3625sEJyc" target="_blank" rel="noopener">YouTube&lt;/a>で説明されています。より詳細には&lt;a href="https://kafka.apache.org/blog#apache_kafka_360_release_announcement" target="_blank" rel="noopener">本家のリリースノート&lt;/a>には全ての関連kIPのリストが公開されています。&lt;/p>
&lt;p>本エントリでは、中でも重要なKIPについてご紹介します。&lt;/p>
&lt;h3 id="kip-405-kafka-tiered-storage-early-accesshttpscwikiapacheorgconfluencedisplaykafkakip-4053akafkatieredstorage">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A&amp;#43;Kafka&amp;#43;Tiered&amp;#43;Storage" target="_blank" rel="noopener">KIP-405: Kafka Tiered Storage (Early Access)&lt;/a>&lt;/h3>
&lt;p>&lt;a href="../kip405-why-tiered-storage-important/">こちらのブログエントリ&lt;/a>でもご紹介していたTiered Storageがアーリーアクセスとして利用可能となりました。単純に古いセグメントがオブジェクトストレージに退避されるだけでなく、既存のKafkaの設計やパフォーマンスへの影響を与えずに、Kafka自身がよりクラウドネイティブな姿へと変わる上で重要な機能です。&lt;/p>
&lt;p>今回3.6に登場したバージョンはまだ本番環境における利用を想定していない旨にご留意ください。機能の安定性だけでなく、JBODやCompacted Topic等機能制限もあります。既存Topicもバージョンを3.6にアップグレードすればTiered Storageに変更出来ますが、2.8.0より前に作成されたTopicには適用出来ない点もご注意下さい。アーリーアクセス版の制限はこちらの&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka&amp;#43;Tiered&amp;#43;Storage&amp;#43;Early&amp;#43;Access&amp;#43;Release&amp;#43;Notes" target="_blank" rel="noopener">Tiered Storage アーリーアクセスリリースノート&lt;/a>に記載されています。&lt;/p>
&lt;h3 id="kip-868-metadata-transactionshttpscwikiapacheorgconfluencedisplaykafkakip-868metadatatransactions">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-868&amp;#43;Metadata&amp;#43;Transactions" target="_blank" rel="noopener">KIP-868 Metadata Transactions&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://developer.confluent.io/learn/kraft/" target="_blank" rel="noopener">KRaft&lt;/a>の内部処理に関する改善です。KRaftではメタデータの更新時に関連レコード (例：Topic登録時の全Partitionのレコード) をアトミックに更新する仕様となっています。この為Controllerが処理中に障害に陥った場合でも部分的なメタデータの更新がなされないようになっています。&lt;/p>
&lt;p>一方このバッチサイズはKRaftのフェッチサイズが上限となっており、アップデート前ではこのサイズは8kbとなっています。この為非常に大きなメタデータの更新時にはフェッチ上限を超えるバッチが生成される可能性がありました。&lt;/p>
&lt;p>この改善で新たにメタデータにトランザクションの概念が導入され、トランザクションの開始/終了等のマーカーレコードを挿入するようになります。これによりKRaftのフェッチサイズを超える更新バッチサイズになった場合でも処理が可能となります。&lt;/p>
&lt;h3 id="kip-941-range-queries-to-accept-null-lower-and-upper-boundshttpscwikiapacheorgconfluencedisplaykafkakip-9413arangequeriestoacceptnulllowerandupperbounds">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-941%3A&amp;#43;Range&amp;#43;queries&amp;#43;to&amp;#43;accept&amp;#43;null&amp;#43;lower&amp;#43;and&amp;#43;upper&amp;#43;bounds" target="_blank" rel="noopener">KIP-941: Range queries to accept null lower and upper bounds&lt;/a>&lt;/h3>
&lt;p>Kafka StreamsにてマテリアライズしたState Storeに対してアクセスするには&lt;a href="https://docs.confluent.io/platform/current/streams/developer-guide/interactive-queries.html" target="_blank" rel="noopener">Interactive Query&lt;/a>を利用します。これにより、アクセスするデータが分散配置されているKafka Streamsのどのインスタンスにて保存されているのかを意識せずとも適切なデータを取得する事が出来ます。&lt;/p>
&lt;p>一方内部ではそれぞれのデータはKafka Streamsインスタンスに部分的に保存されている為、レンジ指定をして取得する場合には処理に大きな負荷がかかります。この為レンジ指定のクエリは制限が多く、アップデート前ではnullを指定した取得が出来ませんでした。この為：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueAndTimestamp&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">StockTransactionAggregation&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">createRangeQuery&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withNoBounds&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(!&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withLowerBound&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="o">!&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withUpperBound&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withRange&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>このような回避的なコーディングが必要でした。&lt;/p>
&lt;p>今回レンジクエリにnull指定が出来るようになった事により：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withRange&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>これだけでnullを回避した実装が可能となります。&lt;/p>
&lt;h3 id="kip-875-first-class-offsets-support-in-kafka-connecthttpscwikiapacheorgconfluencedisplaykafkakip-8753afirst-classoffsetssupportinkafkaconnect">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-875%3A&amp;#43;First-class&amp;#43;offsets&amp;#43;support&amp;#43;in&amp;#43;Kafka&amp;#43;Connect" target="_blank" rel="noopener">KIP-875: First-class offsets support in Kafka Connect&lt;/a>&lt;/h3>
&lt;p>Kafka Connectはその処理状況をKafkaネイティブにオフセットを管理する事により把握/管理しています。Connectorタスクが異常終了した場合でも、コミットされたオフセットを元に継続処理できるので、Connector自身には独自のステート管理のストレージ等が無くとも障害耐性を確保する事が出来ています。&lt;/p>
&lt;p>一方このオフセットはKafka上では参照できるもののKafka Connectとしては外部からアクセス出来るようにはなっていませんでした。何かしらの理由でオフセットを制御したい（特定レコードレンジを飛ばしたい、あるオフセットから再読み込みしたい、etc）場合にはハック的にKafka上のオフセット用Topicをいじる必要がありました。&lt;/p>
&lt;p>この改善によってKafka Connect API経由でオフセットの取得、更新、削除が可能となります。&lt;/p>
&lt;h3 id="おわりに">おわりに&lt;/h3>
&lt;p>Apache Kafka 3.6にはその他多くの改善が含まれています。今回のエントリではその一部しか触れていませんが、是非本家の&lt;a href="https://kafka.apache.org/blog#apache_kafka_360_release_announcement" target="_blank" rel="noopener">リリースノート&lt;/a>も併せてご参照ください。&lt;/p></description></item><item><title>Confluent Cloud Q3'23 Launch</title><link>https://confluent-jp.github.io/community/blog/confluent-cloud-23q3-launch/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/confluent-cloud-23q3-launch/</guid><description>&lt;p>Confluent Cloudはマネージドのプラットフォーム提供である為、様々な機能追加や改善は自動的に適用されます。これら改善はコアであるApache Kafkaのバージョンアップに限らず、またプラットフォーム製品であるConfluent Platformの機能にも限定されず、Confluent Cloud独自の機能も様々追加されています。&lt;/p>
&lt;p>Quarterly Launchは、そんなConfluent Cloudの新規機能を四半期毎にまとめてご紹介する&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/" target="_blank" rel="noopener">ブログ&lt;/a>と&lt;a href="https://www.youtube.com/watch?v=TS00diWO5Ak" target="_blank" rel="noopener">YouTube&lt;/a>エントリを指します。今回は&lt;a href="https://www.confluent.io/events/current/" target="_blank" rel="noopener">Current 2023&lt;/a>の開催を待った為だいぶ遅くなってしまいましたが、改めてそのハイライトをご紹介します。&lt;/p>
&lt;h3 id="apache-flink-on-confluent-cloud-open-previewhttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesflink-on-cloud">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#flink-on-cloud" target="_blank" rel="noopener">Apache Flink® on Confluent Cloud (Open Preview)&lt;/a>&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Flink on Confluent Cloud" srcset="
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1e22c54f68065fddec3fa2ce7b9ed953.webp 400w,
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_0bffbec27941e3f486699fef8632a7a8.webp 760w,
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1e22c54f68065fddec3fa2ce7b9ed953.webp"
width="600"
height="315"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
来年サービス提供開始予定のApache Flink on Confluent Cloudがオープンプレビューとして公開されました。提供インターフェースはFlink SQLのみ。現時点では&lt;a href="https://docs.confluent.io/cloud/current/flink/reference/op-supported-features-and-limitations.html#feature-limitations" target="_blank" rel="noopener">既知の機能制限&lt;/a>があり、この為本番利用には向きません。また現時点で&lt;a href="https://docs.confluent.io/cloud/current/flink/reference/op-supported-features-and-limitations.html#cloud-regions" target="_blank" rel="noopener">利用可能なクラウド/リージョン&lt;/a>は限定的ではあります。ただ、今日もうお試しいただけます。&lt;/p>
&lt;h3 id="enterprise-clustershttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesenterprise-clusters">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#enterprise-clusters" target="_blank" rel="noopener">Enterprise clusters&lt;/a>&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Enterprise Clusters" srcset="
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2d533c3cc14f04ebba6beda84afd4b62.webp 400w,
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2108090c6b8fd26c6bbd9d7601804391.webp 760w,
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2d533c3cc14f04ebba6beda84afd4b62.webp"
width="760"
height="380"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Confluent Cloudのサーバーレスなクラスタ提供に新たにEnterpriseというオプションが追加されました。Basic、Standardといった既存のサーバーレスクラスタと異なり閉塞ネットワーク接続&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>を可能としており、併せて標準でSLA 99.99%、最大1GBpsのスループット(Ingress/Egress合算)をサポートしています。&lt;/p>
&lt;p>残念ながらローンチ時点ではサポートされているリージョンは限定的&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>ですが、以降継続して拡張予定となっています。&lt;/p>
&lt;h3 id="confluent-terraform-provider-updateshttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesconfluent-terraform-provider">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#confluent-terraform-provider" target="_blank" rel="noopener">Confluent Terraform provider updates&lt;/a>&lt;/h3>
&lt;p>Confluent Terraform ProviderがHashiCorp Sentinel統合をサポートしました。これによりPolicy-as-Codeによる運用にConfluent Cloudを統合することが可能となります。&lt;/p>
&lt;p>また、新たにResource Importer機能を提供開始しました。これにより既存のConfluent CloudからTerraformの構成 (main.tf) ならびに状態 (terraform.tfstate) を逆生成する事が可能となります。&lt;/p>
&lt;h3 id="その他">その他&lt;/h3>
&lt;ul>
&lt;li>先日発表した&lt;a href="../confluent-platform-7.5-announcement/">Confluent Platform 7.5&lt;/a>でもご紹介した双方向Cluster LinkingがConfluent Cloudでもサポートされております。&lt;/li>
&lt;li>PrivateLink接続のConfluent Cloudクラスタ同士を&lt;a href="https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/private-networking.html" target="_blank" rel="noopener">直接Cluster Linkingで接続可能&lt;/a>することが可能となりました。&lt;/li>
&lt;/ul>
&lt;p>その他にも新たな機能が追加されておりますが、その全貌ならびに個々の詳細につきましては&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/" target="_blank" rel="noopener">Confluentブログのアナウンスメント&lt;/a>をご覧ください。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>2023年9月ローンチ時点では、AWS PrivateLink経由の接続のみサポートしております。その他クラウドの接続形態は後日提供となります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>2023年9月ローンチ時点では、AWSのus-east-2(Ohio)、us-west-2(Oregon)、ap-southeast-1(Singapore)等8リージョンでのみ提供開始となっています。日本リージョンでの利用開始は現時点では未定です。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>KafkaとトランザクションとExactly Once</title><link>https://confluent-jp.github.io/community/blog/kafka-transaction-how-it-works/</link><pubDate>Sat, 09 Sep 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kafka-transaction-how-it-works/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Kafkaの利用は&lt;a href="https://www.youtube.com/watch?v=9uCP3qHNbWw" target="_blank" rel="noopener">結果整合性&lt;/a>の概念の浸透とその実践的な活用ユースケースの登場によって飛躍的に広がりました。それまでのリレーショナルモデルに見られる&lt;a href="https://ja.wikipedia.org/wiki/ACID_%28%E3%82%B3%E3%83%B3%E3%83%94%E3%83%A5%E3%83%BC%E3%82%BF%E7%A7%91%E5%AD%A6%29" target="_blank" rel="noopener">ACID特性&lt;/a>を前提とした整合性の管理ではなく、&lt;a href="https://martin.kleppmann.com/2015/06/02/change-capture-at-berlin-buzzwords.html" target="_blank" rel="noopener">Change Data Capture&lt;/a>によって整合性を整理するという大きく異なるアプローチであり、既存の概念に挑戦するものでした。&lt;/p>
&lt;p>リレーショナルモデルにおけるトランザクションではない「今ではない近い将来にはデータは整合性を保った状態で連携先に届く」というアプローチである為、Change Data Captureを活用したソリューションにトランザクションの概念が登場すると混乱を招く事も多くあります。&lt;/p>
&lt;p>Kafkaもトランザクションをサポートしており、データを整合性を保ったままリアルタイムに扱う上で非常に重要な概念です。しかしながら、Kafkaのトランザクションの目的はリレーショナルモデルのそれとは大きく異なります。&lt;/p>
&lt;p>このエントリは、Kafkaにおけるトランザクションがどういうものであるかの説明と、トランザクションにまつわる様々な誤解を解く事を目的としています。&lt;/p>
&lt;h2 id="トランザクションとexactly-once">トランザクションとExactly Once&lt;/h2>
&lt;p>メッセージングの世界では「確実に1度だけメッセージをデリバリーする」という事が極めて難しいとされてきました。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> 一方、メッセージを (最低1回以上) 確実にデリバリーする手法は論理的にも実装的にも比較的容易である為、ほとんどのメッセージング基盤はこの手法を主に採用しています。OSSとして公開された当時のKafkaもその一つでした。データを送る側 (Producer) で1回だけ送るというのが難しい為、受け取り側 (Consumer) 側で重複メッセージの処理を行う必要があります。 &lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>Kafkaが&lt;a href="https://www.confluent.io/ja-jp/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/" target="_blank" rel="noopener">Exactly Once Delivery&lt;/a>機能をサポートしたのはバージョン0.11です。この頃より、結果整合性を前提としたソリューションの土台となり得るKafkaの利用が飛躍的に広がりました。&lt;/p>
&lt;p>Exactly Once Deliveryに関するKIPの正式名は&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98&amp;#43;-&amp;#43;Exactly&amp;#43;Once&amp;#43;Delivery&amp;#43;and&amp;#43;Transactional&amp;#43;Messaging" target="_blank" rel="noopener">Exactly Once Delivery and Transactional Messaging&lt;/a>であり、Idempotent Producerとトランザクションの双方を纏めて1つのKIPで定義しています。この為、Exactly Once Deliveryを達成する為には必ずトランザクションの導入が必要なよう誤解されている事も多いと思います。当然これら2つには強い関連性がある為同じKIP内で説明されていますが、それぞれ異なる機能であり、分解して理解する必要があります。&lt;/p>
&lt;p>Idempotent Producerについては&lt;a href="../idempotent-producer-and-max-inflight/">こちらのブログエントリ&lt;/a>でご紹介していますが、具体的にはProducerがKafkaに対してExactly Onceでメッセージを送る為に必要な機能であり、Kafkaトランザクション機能とは異なります。つまり明示的にトランザクションを使用しなくても、ProducerからKafkaへの書き込みはExactly Onceに指定できます。&lt;/p>
&lt;h3 id="kafka-transaction">Kafka Transaction&lt;/h3>
&lt;p>Kafkaトランザクション自体はリレーショナルDBにおけるトランザクションと近い思想を持つもので、異なるエンティティへの書き込み処理をアトミックに扱える機能ですが、Kafkaの世界では対象がTopicとなります。つまり、異なるTopicへの書き込みをCommit/Abortする事ができる機能です。利用方法もリレーショナルDB APIへのプログラムアクセスと似ており：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">initTransactions&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">IllegalStateException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">beginTransaction&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">ProducerFencedException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">commitTransaction&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">ProducerFencedException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">abortTransaction&lt;/span>&lt;span class="o">()&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">ProducerFencedException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">sendOffsetsToTransaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TopicPartition&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OffsetAndMetadata&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">offsets&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">String&lt;/span> &lt;span class="n">consumerGroupId&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">ProducerFencedException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>これらメソッドを扱いプログラムコード内でアトミック処理の制御を行う事が出来ます。当然、&lt;code>Topic A&lt;/code>と&lt;code>Topic B&lt;/code>への書き込みをトランザクションで括ることも出来ます。しかしながら、リレーショナルモデル同様のトランザクションの使い方では、Kafkaへのトランザクション処理の導入が高い優先度で扱われたのも、この機能がExactly Once Deliveryと関連づけられ同一のKIP内で設計されていることも説明できません。&lt;/p>
&lt;p>上記には一般的なトランザクション処理では見られないメソッドも含まれていますが&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kt">void&lt;/span> &lt;span class="nf">sendOffsetsToTransaction&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">Map&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">TopicPartition&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">OffsetAndMetadata&lt;/span>&lt;span class="o">&amp;gt;&lt;/span> &lt;span class="n">offsets&lt;/span>&lt;span class="o">,&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="n">String&lt;/span> &lt;span class="n">consumerGroupId&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="kd">throws&lt;/span> &lt;span class="n">ProducerFencedException&lt;/span>&lt;span class="o">;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>このメソッドがExactly Once Deliveryとトランザクションを関連付ける重要な役割を担っています。&lt;/p>
&lt;h3 id="sendoffsetstotransaction">sendOffsetsToTransaction&lt;/h3>
&lt;p>このメソッドが何をするかは名前からもある程度推測できますが、「処理した一連のConsumer OffsetをConsumer Group Coordinatorに送りつつ、 &lt;strong>現在のトランザクションに関連付ける&lt;/strong> 」メソッドです。少々アクロバティックな処理ですが、この処理をトランザクションAPIに定義するには必要性があります。&lt;/p>
&lt;p>このメソッドは、全く異なる2つの処理を1メソッドに纏めるというタブーに近いメソッドです。さらに注意すべきなのは、トランザクションはProducerに関わる機能であり、Consumer OffsetはConsumerに関わる機能です。つまりこのメソッドはProducerでもありConsumerでもある処理でしか存在意義が無いメソッドです。&lt;/p>
&lt;p>一般的なメッセージングモデルではあまり検討しないこの処理ですが、Kafkaのエコシステムでは&lt;a href="https://www.confluent.io/ja-jp/online-talks/benefits-of-stream-processing-and-apache-kafka-use-cases-on-demand/" target="_blank" rel="noopener">ストリーム処理&lt;/a>における根本的かつ重要な要件となります。&lt;/p>
&lt;h2 id="ストリーム処理とexactly-once">ストリーム処理とExactly Once&lt;/h2>
&lt;h3 id="ストリーム処理">ストリーム処理&lt;/h3>
&lt;p>ストリーム処理とは、一般的なバッチ処理同様にInputとOutputを持つデータ処理を、中間的なストレージを経由する事により一連のデータフローとして形成するアプローチです。バッチとの違いは、その中間的なストレージがcsvファイルやDBの中間テーブルではなくKafka Topicを利用する事であり、これによりバッチ同様のデータフローをリアルタイム&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>に実行する事が出来る点です。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="ストリーム処理 - 論理フロー" srcset="
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-logical-view_hu7ad9a819e248931517be742776eecf4e_31936_5a33e9959c337d50f76925b46d5cd296.webp 400w,
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-logical-view_hu7ad9a819e248931517be742776eecf4e_31936_d1371efabf84eae9e2b715826d01647c.webp 760w,
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-logical-view_hu7ad9a819e248931517be742776eecf4e_31936_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-transaction-how-it-works/stream-processing-logical-view_hu7ad9a819e248931517be742776eecf4e_31936_5a33e9959c337d50f76925b46d5cd296.webp"
width="760"
height="261"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>この例ではSourceから発行されたイベントを、エンリッチしてアプリやDBに格納するフローと、集約した後ダッシュボードに転送するフローを表現しています。イベントはKafkaに発行されてから、Kafka内で変更/加工された後にSinkへとリアルタイムに繋げるデータフローとなっています。&lt;/p>
&lt;p>これはあくまで論理的なフローですが、実際にはデータフロー内の処理は全てKafkaとの通信で成り立っています。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="ストリーム処理 - コミュニケーションフロー" srcset="
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-communication-view_hu031934ae688d3286237b88f738ac776f_51202_00f4cd7a6318d7c24cfe9323baff398c.webp 400w,
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-communication-view_hu031934ae688d3286237b88f738ac776f_51202_6af0e3f468c88ba8a5049d51beed7777.webp 760w,
/community/media/blogs/kafka-transaction-how-it-works/stream-processing-communication-view_hu031934ae688d3286237b88f738ac776f_51202_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-transaction-how-it-works/stream-processing-communication-view_hu031934ae688d3286237b88f738ac776f_51202_00f4cd7a6318d7c24cfe9323baff398c.webp"
width="724"
height="418"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>SourceはProducerとして機能し、DBやダッシュボードへの転送はSink Connectorを利用しています。これらデータフローの両端はProducerもしくはConsumerのいずれかの役割を果たします。&lt;/p>
&lt;p>その他の処理はイベントを受け取り、加工の上次の処理に渡す為、ProducerでありConsumerである必要があります。より具体的には「前処理がProducerでイベント送ったTopicを、その次の処理がConsumeする」、この繰り返しでデータフローのトポロジーを形成します。このトポロジーをTopicも含めたフローで表現すると：&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="ストリーム処理におけるTopic" srcset="
/community/media/blogs/kafka-transaction-how-it-works/stream-procerssing-and-topics_hue370a54ad1ec1d1e167b7c34cfea6f36_45782_343facf8cdd825b71136fcb23fa6d7c9.webp 400w,
/community/media/blogs/kafka-transaction-how-it-works/stream-procerssing-and-topics_hue370a54ad1ec1d1e167b7c34cfea6f36_45782_a952ea042c1563d13fb4d4600816611c.webp 760w,
/community/media/blogs/kafka-transaction-how-it-works/stream-procerssing-and-topics_hue370a54ad1ec1d1e167b7c34cfea6f36_45782_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-transaction-how-it-works/stream-procerssing-and-topics_hue370a54ad1ec1d1e167b7c34cfea6f36_45782_343facf8cdd825b71136fcb23fa6d7c9.webp"
width="760"
height="522"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>このように分解できます。ここではProduceを点線、Consumeを実線で表現しています。処理自体はKafkaのTopicを境に完全に分離された構成となっており、バッチ処理における中間ストレージと同じ役割を果たしています。&lt;/p>
&lt;h3 id="exactly-once">Exactly Once&lt;/h3>
&lt;p>この処理のEnd-to-EndでExactly Onceを達成するには？という命題の為にKafka Transactionは定義されています。&lt;/p>
&lt;p>Kafka Consumerは、メッセージの処理後にConsumer Offsetを&lt;code>commitSync/commitAsync&lt;/code>というメソッドを使って更新します。このオフセットコミットが行われる事により、仮に処理後にConsumerのプロセスが落ちたとしても、新しいプロセスが引き継いで処理を継続する事が出来ます。&lt;/p>
&lt;p>しかしながら、処理後 (ストリーム処理ではConsumeし、データの処理を実行し、別のTopicにProduce前) に何らかの障害によってプロセスを失った場合、引き継いだプロセスはコミットされる前のオフセットをもとに処理、つまり同じメッセージを消費し再処理することとなります。これではProduceに関してはIdempotent Producerの設定によってExactly OnceでKafkaに書き込めても、End-to-EndのフローではExcatly Onceを保証出来ません。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="ストリーム処理とトランザクション" srcset="
/community/media/blogs/kafka-transaction-how-it-works/topics-and-transaction_hu2ddcc10237c855413716f2a234f348cc_66959_15c00aacbb43c2d849507986e092ea51.webp 400w,
/community/media/blogs/kafka-transaction-how-it-works/topics-and-transaction_hu2ddcc10237c855413716f2a234f348cc_66959_b6605ac37ee1b67734801f3b79b7721a.webp 760w,
/community/media/blogs/kafka-transaction-how-it-works/topics-and-transaction_hu2ddcc10237c855413716f2a234f348cc_66959_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-transaction-how-it-works/topics-and-transaction_hu2ddcc10237c855413716f2a234f348cc_66959_15c00aacbb43c2d849507986e092ea51.webp"
width="760"
height="458"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Kafkaにおけるトランザクション、そして中でも先ほど言及した&lt;code>sendOffsetsToTransaction&lt;/code>はまさしくこのProduceとConsumer Offsetのコミットをアトミックな処理としてに定義する事ができます。これにより、どのタイミングで障害が発生してもEnd-to-EndでExactly Once Deliveryを達成する事が出来ます。&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>&lt;/p>
&lt;h3 id="まとめ">まとめ&lt;/h3>
&lt;p>Kafka TransactionとIdempotent Producerは同じKIP内で定義されており、また併せて説明される事が多い機能ではありますが、使われる場所と用途は全く異なります。ただこれらはKafkaにおけるExactly Once Deliveryにおいてお互いを補完するものであり、双方が揃って初めてEnd-to-EndのExactly Once Deliveryが達成出来る事が分かります。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>分散システムにおける&lt;a href="https://ja.wikipedia.org/wiki/%E4%BA%8C%E4%BA%BA%E3%81%AE%E5%B0%86%E8%BB%8D%E5%95%8F%E9%A1%8C" target="_blank" rel="noopener">二人の将軍問題&lt;/a>等を用いて言及されています。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>この為Consumer側で冪等性を確保した処理が求められます。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>一般的に「リアルタイム処理」とは数ミリ秒誤差のものを指す為、厳密には準リアルタイムと呼ぶのが相応しいかも知れません。Kafkaのストリーム処理におけるEnd-to-Endのレイテンシは、処理にもよりますが数百ミリ秒から数秒程度のレイテンシとなります。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>図にもありますが、Consumerも未コミット状態のデータにアクセスしてはいけないので、分離レベルをRead Committedに指定する必要があります。ここはリレーショナルモデルの概念をそのまま踏襲しています。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Confluent Platform 7.5リリース</title><link>https://confluent-jp.github.io/community/blog/confluent-platform-7.5-announcement/</link><pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/confluent-platform-7.5-announcement/</guid><description>&lt;p>Confluent Platform 7.5がリリースされました。 &lt;a href="https://www.confluent.io/blog/introducing-confluent-platform-7-5/" target="_blank" rel="noopener">Confluent Blog&lt;/a> 内包されるApache Kafkaのバージョンは&lt;a href="https://www.youtube.com/watch?v=BVxDFL5iTx8" target="_blank" rel="noopener">3.5&lt;/a>となります。&lt;/p>
&lt;p>コアエンジンであるApache Kafkaのアップグレードだけでなく、エンタープライズ ソリューションとしてのConfluent Platformとしての機能追加や改善も含まれています。&lt;/p>
&lt;h3 id="sso-for-control-center-c3-for-confluent-platform">SSO for Control Center (C3) for Confluent Platform&lt;/h3>
&lt;p>Confluent Control CenterはConfluent Platformにおける管理ポータルとしての役割から、ごく一部のSREメンバーからのみアクセスされるという特殊なコンポーネントです。この為これまではアクセス制御のアプローチについては少し限定的でしたが、Broker等と同様OAuth2ベースの認証/認可の方法でアクセスする事が可能となりました。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="OIDC SSO to Conntrol Center" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_003085067e9660f4d2a75d91d83a2c4c.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_1ba41c13ea805b6d452f9ea265a8d6d8.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_003085067e9660f4d2a75d91d83a2c4c.webp"
width="760"
height="349"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="confluent-rest-proxy-produce-api-v3">Confluent REST Proxy Produce API v3&lt;/h3>
&lt;p>Confluent REST ProxyはKafka BrokerへのRESTベースのアクセスを可能としており、Confluent Platform/Cloudの双方で幅広く活用されています。一方、通常のKafkaプロトコルベースのアクセスに比べると制限もあり、これまでも段階的に改善がなされています。今回のProduce API v3では：&lt;/p>
&lt;ul>
&lt;li>カスタムヘッダーの追加 (トレーシングID、等)&lt;/li>
&lt;li>KeyとValueで異なるシリアライザの設定&lt;/li>
&lt;/ul>
&lt;p>が可能となります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="REST Proxy Produce API v3" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_83989a5797af7fe63286be6fe5bcda60.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_a2df8c6c08019d4a0d21e3f2b3a29d54.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_83989a5797af7fe63286be6fe5bcda60.webp"
width="760"
height="333"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="bidirectional-cluster-linking">Bidirectional Cluster Linking&lt;/h3>
&lt;p>双方向のCluster Linkingの設定が可能となりました。これまでも一方向のリンクを2本貼れば実際のレプリケーションを双方向にすることは可能でした。Consuemr観点ではローカルのTopicとMirror Topicそれぞれ個別のTopicを同時にConsumeするモデルであり、それぞれへのOffset Commitを実行します。この際、Mirror TopicへのOffset CommitはソースとなるTopicには反映されないので、障害時には部分的なConsumer Offset情報しか連携されていない状況となります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="2 Unidirectional Cluster Linking" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_a7ec30fb3db45ac5c6af35290b9d3c04.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_034036236e3424798a84919e80a03245.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_a7ec30fb3db45ac5c6af35290b9d3c04.webp"
width="760"
height="420"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
双方向のCluster Linkingは双方向へのリンクが1セットとして扱われる為、双方のクラスタでのOffset Commit情報も合わせて同期されます。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Bidirectional Cluster Linking" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_83366575928d4eb4fc54ae197fca70b1.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_bf7aca812d06fb55ea4bd64298312a51.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_83366575928d4eb4fc54ae197fca70b1.webp"
width="760"
height="339"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="参考">参考&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.confluent.io/blog/introducing-confluent-platform-7-5/" target="_blank" rel="noopener">Introducing Confluent Platform 7.5 (Confluent Blog)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/7.5/release-notes/index.html" target="_blank" rel="noopener">Confluent Platform 7.5 Release Notes&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/current/kafka-rest/index.html" target="_blank" rel="noopener">REST Proxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/7.5/control-center/security/sso/overview.html#sso-for-c3" target="_blank" rel="noopener">Single Sign-On (SSO) for Confluent Control Center&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#bidirectional-mode" target="_blank" rel="noopener">Cluster Linking - Bidirectional Mode&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>解剖 Kafka Controller Broker</title><link>https://confluent-jp.github.io/community/blog/kafka-controller-broker-explained/</link><pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kafka-controller-broker-explained/</guid><description>&lt;blockquote>
&lt;p>このブログエントリはKafkaコミッタである Stanislav Kozlovski(&lt;a href="https://https://twitter.com/BdKozlovski" target="_blank" rel="noopener">𝕏&lt;/a>|&lt;a href="https://www.linkedin.com/in/stanislavkozlovski/" target="_blank" rel="noopener">Ln&lt;/a>) のサイトで2018/10/31に公開された&lt;a href="https://stanislavkozlovski.medium.com/apache-kafkas-distributed-system-firefighter-the-controller-broker-1afca1eae302" target="_blank" rel="noopener">Apache Kafka’s Distributed System Firefighter — The Controller Broker&lt;/a>の日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。&lt;/p>
&lt;/blockquote>
&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Kafkaは成長を続ける分散ストリーミング基盤です。現時点での業界デファクト技術であり、広がるデータパイプラインの利用に対しても拡張しつつ安定的に稼働することが出来ます。もしKafkaの概要についてもう少し知りたい方は&lt;a href="https://hackernoon.com/thorough-introduction-to-apache-kafka-6fbf2989bbc1" target="_blank" rel="noopener">A Thorough Introduction To Apache Kafka&lt;/a>をご覧ください。&lt;/p>
&lt;p>この記事を書く中で、このKafkaの安定稼働を支える中の仕組みについて書きたいと思うようになりました。&lt;/p>
&lt;p>このエントリではKafkaにおけるControllerの概念 - Kafkaという分散基盤を健康的に稼働し続ける使命を支える機能についてご紹介します。&lt;/p>
&lt;h2 id="controller-broker">Controller Broker&lt;/h2>
&lt;p>分散システムは常に協調の中で稼働し続ける必要があります。何かしらのイベントがクラスタで発生した場合、クラスタ内のコンポーネントは同調してそれに反応しなければいけません。その中で、クラスタとしてどう反応するべきなのか、Brokerは何をすべきなのかを指示する存在が必要です。&lt;/p>
&lt;p>その役割を担うのがControllerです。
Controller自身は複雑な仕組みではありません - ControllerもBrokerであり、通常のBrokerとしての役割と合わせて追加の役割も持つBrokerです。つまりController BrokerもPartitionを制御し、ReadとWriteのリクエストに対応し、裏ではレプリケーションに参加します。&lt;/p>
&lt;p>今追加の役割の中で最も重要なのは、クラスタ内のBrokerノードの管理であり、Brokerが追加、クラスタから離脱、もしくは障害が発生した際に適切にそのメンバーシップを管理することです。これにはPartitionのリバランスや新たなPartion Leaderの特定も含まれます。&lt;/p>
&lt;p>KafkaクラスタにはControllerが常に稼働し、唯一1つのControllerのみ稼働します。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="controllerの役割">Controllerの役割&lt;/h2>
&lt;p>Controller Brokerは複数の複数を担います。Topicの作成/削除、Partitionの追加 (とLeaderの特定)、BrokerがClusterを離脱した際の諸々の制御等様々ありますが、基本的にはクラスタにおける管理者として振る舞います。&lt;/p>
&lt;h3 id="brokerノードの離脱">Brokerノードの離脱&lt;/h3>
&lt;p>エラーや計画的な停止によってBrokerノードがクラスタから離脱した際、そのBrokerノードにLeaderのあったPartitionにはアクセス出来なくなります。 (クライアントはWrite/Readのいずれであっても常にPartition Leaderにのみアクセスします。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>) この為Broker離脱時のダウンタイムを短縮するには、いかに迅速に新たなLeaderを選出するかが重要になります。&lt;/p>
&lt;p>Controller Brokerは他のBrokerノードが離脱した際に対処します。Zookeeperには&lt;a href="https://zookeeper.apache.org/doc/r3.4.8/zookeeperProgrammers.html#ch_zkWatches" target="_blank" rel="noopener">Zookeeper Watch&lt;/a>と呼ばれる特定データの変更時に登録者に対して通知をする機能で、ControllerはこのZookeeper Watchを利用してBrokerの離脱を検知します。Zookeeper WatchはBroker離脱時のトリガーとして働くKafkaにとって非常に重要な機能です。&lt;/p>
&lt;p>ここにおける「特定データ」とはBrokerデータの集合です。&lt;/p>
&lt;p>下にあるのはBroker 2の&lt;a href="https://zookeeper.apache.org/doc/r3.4.8/zookeeperProgrammers.html#ch_zkSessions" target="_blank" rel="noopener">Zookeeper Session&lt;/a>が無効化される事によりBroker 2のIDがリストから削除された場合の図解です。(Kafka BrokerはZookeeperへのハートビートを送り続けるが、遅れなくなるとセッションが無効化する)&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Zookeeper Watch and Controller" srcset="
/community/media/blogs/kafka-controller-broker-explained/zookeeper-watch_hu999b6f38219025080af213f7c0820560_78754_933d8c0d0ca12b3944bf46cc705eee83.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/zookeeper-watch_hu999b6f38219025080af213f7c0820560_78754_55f25aaf2122bf1cb5ca633f5a0880a6.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/zookeeper-watch_hu999b6f38219025080af213f7c0820560_78754_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/zookeeper-watch_hu999b6f38219025080af213f7c0820560_78754_933d8c0d0ca12b3944bf46cc705eee83.webp"
width="760"
height="637"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>ControllerはこのBroker離脱の通知を受け取り作業に取り掛かりますが、まずはBrokerの離脱によって影響を受けたPartitionの新たなLeaderを決定します。この後、クラスタ内の全てのBrokerに対して通知し、このリクエストを受け取った各Partition毎にLeaderになったりFollowerとしてLeaderに&lt;a href="https://kafka.apache.org/protocol#The_Messages_LeaderAndIsr" target="_blank" rel="noopener">LeaderAndIsr&lt;/a>リクエストを送付します。&lt;/p>
&lt;h3 id="brokerノードのクラスタ復帰">Brokerノードのクラスタ復帰&lt;/h3>
&lt;p>適切なPartition Leaderの配置はKafkaクラスタの負荷分散の上で重要な要素です。上記で説明したとおり、Brokerノードがクラスタを離脱した際には他のBrokerが代わって対応する必要があります。この場合Brokerは当初の想定以上のPartitionを各々が担うことになり、クラスタ全体の健全性やパフォーマンスに少なからず影響を及ぼします。当然なるべく早くバランスを取り戻す必要があります。&lt;/p>
&lt;p>Kafkaは元々のPartitionアサインメントが、ある程度「適切」であるという想定を持っています。このアサインメントにおけるPartition Leaderはいわゆる &lt;em>Preferreed Leader(優先リーダー)&lt;/em> として認識され、最初にそのPartitionが追加された時のPartition Leaderを指します。合わせてKafkaは&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-36&amp;#43;Rack&amp;#43;aware&amp;#43;replica&amp;#43;assignment" target="_blank" rel="noopener">インフラ構成としてのラックやAvailability Zoneを意識したPartition配置の機能&lt;/a> (ラック/AZ障害耐性を確保する為にLeaderとFollowerを別のラック/AZに配置する) もサポートしており、Partition Leaderの配置はクラスタの信頼性に大きく寄与しています。&lt;/p>
&lt;p>デフォルトでは&lt;code>auto.leader.rebalance.enabled=true&lt;/code>となっており、KafkaはPreferred Leaderが存在し、かつ実際のPartition Leaderではない場合にはPreferred Leaderを再選出します。&lt;/p>
&lt;p>Brokerノードのクラスタからの離脱も、多くの場合一時的であり、ある一定時間経過後に離脱したBrokerノードは再度クラスタメンバーとして復帰します。この為Brokerノードが離脱した際にも関連するメタデータは即座に削除されず、Follower Partitionも新たにアサインされません。&lt;/p>
&lt;p>注意点として、再参加したBrokerノードも直ぐにPartition Leaderとして再選出される訳ではなく、その候補となる為には別の条件も必要となります。&lt;/p>
&lt;h3 id="in-sync-replicas">In-Sync Replicas&lt;/h3>
&lt;p>In-Sync Replica (ISR) は状態がPartition Leaderと同じ Followerを指します。言い方を変えると、ISRはそのLeaderのレプリケーションが追いついている状態にあります。Partion LeaderはどのFollowerがISRでどのFollowerがそうではないかをトラックする必要があり、その状態はZookeeperに永続化されます。&lt;/p>
&lt;p>Kafkaの障害耐性と可用性の保証はデータのレプリケーションに基づいており、kafkaが機能するには常に十分なISRが確保されているかが極めて重要です。&lt;/p>
&lt;p>FollowerがLeaderに昇格するにはまずISRである必要があります。全てのPartitionにはISRのリストがあり、Partition LeaderとControllerによって管理されています。ISRから新たなPartition Leaderを選出する処理は &lt;em>Clean Leader Election&lt;/em> と呼ばれています。一方ユーザーにはこれとは異なる方法でLeaderを昇格させる事も可能で、Partion Leaderがクラスタを離脱した際にはISRではないFollowerを昇格させる事も可能です。これはLeaderもISRも存在しないという状況において、データ整合性より可用性を優先させる必要がある稀なケースです。&lt;/p>
&lt;p>ここで再度の確認になりますが、クライアントはPartition LeaderからしかConsumeできません。仮にISRではないFollowerをLeaderに昇格した場合には、当然まだLeaderから取得されていなかったメッセージは失うことになります。これはメッセージを失うだけでなく、Consumerから見たイベントのストリーム上の位置 (オフセット) も上書かれます。&lt;/p>
&lt;p>残念ながらClearn Leader Electionの場合にも同様のデータ障害が発生する可能性はあります。ISRも様々な要因によってLeaderと完全に同期が取れていないケースです - 具体的には、Leaderのオフセットが100とした時に、Followerのオフセットが95、99、80となっているような状況です。レプリケーションは非同期に実施される為、最後のメッセージまで完全にFollower側に渡ったと保証する事は困難です。&lt;/p>
&lt;p>FollowerがLeaderに対してin-syncであると判断する条件は以下です：&lt;/p>
&lt;ul>
&lt;li>Partition Leaderから最新のメッセージを &lt;em>X&lt;/em> ミリ秒前に取得している。 (Xは &lt;code>replica.lag.time.max.ms&lt;/code>にて設定可能)&lt;/li>
&lt;li>Zookeeperに対して &lt;em>Y&lt;/em> ミリ秒前にハートビートを送っている。 (Yは&lt;code>zookeeper.session.timeout.ms&lt;/code>にて設定可能)&lt;/li>
&lt;/ul>
&lt;h3 id="データ整合性と耐久性">データ整合性と耐久性&lt;/h3>
&lt;p>Leaderが機能不全に陥った場合、状況によってはISRが新しいLeaderに昇格した場合にも僅かにメッセージを失う可能性がある点について言及しました。具体的にはLeaderがFollowerからのフェッチリクエストを処理し終わった直後に新たにメッセージを受け取ったケースで、この場合新たなメッセージはまだFollowerがメッセージの到着を把握するまでの空白期間が存在し得ます。このタイミングでLeaderが機能不全に陥った場合、メッセージはLeaderにしか存在しないながらもFollowerの一部はISRとして成立します。そしてISRがそのままLeaderに昇格する可能性があります。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="ISR which is really not in-sync sequence" srcset="
/community/media/blogs/kafka-controller-broker-explained/not-in-sync-isr_hu7f8f7a0d1dc18ad510097bfa7ae71f61_47308_adb7d173994b97446bf22bea411ccfcb.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/not-in-sync-isr_hu7f8f7a0d1dc18ad510097bfa7ae71f61_47308_df314272b8d2415dfd6f7a900a96e469.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/not-in-sync-isr_hu7f8f7a0d1dc18ad510097bfa7ae71f61_47308_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/not-in-sync-isr_hu7f8f7a0d1dc18ad510097bfa7ae71f61_47308_adb7d173994b97446bf22bea411ccfcb.webp"
width="760"
height="617"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="produer側のacksの設定">Produer側のAcksの設定&lt;/h3>
&lt;p>上記の例ではLeaderは自身への書き込みが完了した時点でAcksを返す設定 (&lt;code>acks=1&lt;/code>) を想定しています。Broker 1が最後のAcksを返した直後に機能不全となった為、Broker 2はISRではあるものの&lt;code>offset:100&lt;/code>のメッセージは受け取っていない状態でLeaderに昇格しています。&lt;/p>
&lt;p>この事象は&lt;code>acks=all&lt;/code>と設定することにより回避する事は可能で、つまりLeaderは全てのISRへの書き込みが正常終了した時点で初めてacksを返します。残念ながらこの設定の場合クラスタ全体のスループットには影響します。Kafkaのレプリケーションはpullモデルである為、Leaderは全てのISRのフェッチリクエストが届き、またそれが完了するまで待たなければいけません。&lt;/p>
&lt;p>いくつかのユースケースでは、パフォーマンスを優先して&lt;code>acks=1&lt;/code>とする場合もあります。&lt;/p>
&lt;p>&lt;code>acks=all&lt;/code>と設定した場合にメッセージの欠損は回避出来ます。新たにLeaderとなったISRには無いメッセージを既に取得したConsumerが出る可能性もありません。Producerからのacksを元にデータの整合性は保たれます。&lt;/p>
&lt;h3 id="high-watermark-offset">High Watermark Offset&lt;/h3>
&lt;p>Leaderは全てのISRへのレプリケーションが完了しない限りacksを返さないとします。この際Brokerは &lt;em>high watermark offset&lt;/em> と呼ばれる「全てのISRが取得済みの最大のオフセット」を管理しています。Leaderは合わせてConsumerからのリクエストに対してこのhigh watermark offsetを超えないメッセージのみ提供する事により、DBで言うところのNon-Repeatable Readを回避しています。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="High Watermark Offset" srcset="
/community/media/blogs/kafka-controller-broker-explained/high-watermark-offset_hu7ee940ddd7907971145f7d4d7b70115c_34334_7e9284c01e9197a8bb67bcfaa76768b5.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/high-watermark-offset_hu7ee940ddd7907971145f7d4d7b70115c_34334_b5767dba72b37534de661ef436cf0a84.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/high-watermark-offset_hu7ee940ddd7907971145f7d4d7b70115c_34334_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/high-watermark-offset_hu7ee940ddd7907971145f7d4d7b70115c_34334_7e9284c01e9197a8bb67bcfaa76768b5.webp"
width="760"
height="204"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="split-brain">Split Brain&lt;/h3>
&lt;p>Controller Brokerがダウンした場合、メタデータの欠損を回避する為にKafkaは急遽代理のControllerを立てる必要があります。&lt;/p>
&lt;p>ここでの問題は、我々にはController Brokerの応答不能が完全な機能不全によるものなのか、それとも一時的な障害 によるものかの判断が出来ない事です。それでも新たなControllerを選出する必要がありますが、場合によってはZombie Controllerを生み出す危険性もあります。つまり、クラスタからは既に稼働を停止しControllerではないと認識されているにも関わらず、再びアクティブとなりControllerとして振る舞うBrokerです。&lt;/p>
&lt;p>この事象は容易に起こり得ます。例えば一時的な&lt;a href="https://aphyr.com/posts/288-the-network-is-reliable" target="_blank" rel="noopener">ネットワークの分断&lt;/a>が発生した場合や、非常に長いGC Pause(Stop-the-World - 全ての処理がGCの実行完了まで停止される事象)が発生した場合には、ClusterはそのController Brokerが既に停止したと判断し得ます。特にGC Pauseの場合、Controller Brokerの観点では何一つ変わっていないのに時間が経過している状況となります。この為、Controllerが既に選出された後に以前のControllerが復帰する、分散システムにおける&lt;a href="https://techthoughts.typepad.com/managing_computers/2007/10/split-brain-quo.html" target="_blank" rel="noopener">Split Brain&lt;/a>が発生します。&lt;/p>
&lt;p>例に準えて解説します。稼働中のControllerが長いGC Pauseに陥ったとします。ControllerのZookeeper Sessionが無効化され、&lt;code>/controller&lt;/code>znodeは削除されます。クラスタ内の他のBrokerは通知を受けます。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Zombie Controller 1" srcset="
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-1_hu23f36871d72aa03f5abf14da0a4f651a_28874_8234f76cd2ef1f4693fc46419d252975.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-1_hu23f36871d72aa03f5abf14da0a4f651a_28874_ccb5a50a39671ca10d8ef574dba2e1de.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-1_hu23f36871d72aa03f5abf14da0a4f651a_28874_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/zombie-controller-1_hu23f36871d72aa03f5abf14da0a4f651a_28874_8234f76cd2ef1f4693fc46419d252975.webp"
width="760"
height="270"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Controllerの不在状況を回避する為、全てのBrokerがControllerになろうとします。この場合Broker 2が選出され新たなControllerとして&lt;code>/controller&lt;/code>znodeに自身が追加されます。&lt;/p>
&lt;p>全てのBrokerはこの新たなznodeが作成され、Broker 2がControllerである通知を受けます。この際にも唯一GC Pause中のBroker 3だけはこの通知を受けません。ちなみにこの通知がBrokerに到達しない可能性は他にもあります。いずれにせよ最終的にBroker 3には新たなController選出の通知が届きません。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Zombie Controller 2" srcset="
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-2_hu1daff395d8979a57f29a46032a5f58e9_28108_355fbebd342800306f40cf9c793c54b6.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-2_hu1daff395d8979a57f29a46032a5f58e9_28108_303b8045fe641bf13886fe6278809932.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-2_hu1daff395d8979a57f29a46032a5f58e9_28108_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/zombie-controller-2_hu1daff395d8979a57f29a46032a5f58e9_28108_355fbebd342800306f40cf9c793c54b6.webp"
width="760"
height="262"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Broker 3でのGC処理が完了し復帰した際、未だに自身がControllerだと認識しています。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Zombie Controller 3" srcset="
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-3_hu69d3de9c1c781c11547d8d4c73b1ae58_22958_9315415f925ce97da7a83dfc91d27d5d.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-3_hu69d3de9c1c781c11547d8d4c73b1ae58_22958_8650d61272f471ed9e32358aaa70c1d0.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/zombie-controller-3_hu69d3de9c1c781c11547d8d4c73b1ae58_22958_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/zombie-controller-3_hu69d3de9c1c781c11547d8d4c73b1ae58_22958_9315415f925ce97da7a83dfc91d27d5d.webp"
width="760"
height="129"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>結果として2つのControllerが稼働状態となり、異なる指示を並行して送る可能性があります。この状態はクラスタの状態として極めて悪く、適切に対応しなければ重大なデータ不整合を起こし得ます。&lt;/p>
&lt;p>もしBroker 2(新たに選出されたController)がBroker 3から指示を受けた場合、このBroker 3が新たなControllerであるという保証は取れるのでしょうか？もちろんBroker 2も同様にGC Pauseに陥った可能性もあり、自分自身も最新のControllerではない可能性も否定出来ません。&lt;/p>
&lt;p>何かしらの方法で、どのControllerが最新であり現在稼働すべきControllerであるのかを全員が判断出来る方法が必要です。&lt;/p>
&lt;p>その方法は極めて単純に、epoch number&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>の利用により解決しています。epoch numberは単純に1ずつ増加する自然数であり、古いControllerのepoch numberが1の場合、新たに選出されたControllerのepoch numberは2になります。Brokerは単純に、最も大きなepoch numberを持つControllerからの指示を信じる事によりsplit brainを回避出来ます。このepoch numberはZookeeperに保全されます。(Zookeeperの&lt;a href="https://zookeeper.apache.org/doc/current/zookeeperInternals.html#sc_consistency" target="_blank" rel="noopener">Consistency Guarantee&lt;/a>の機能を利用しています。)&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Epoch Number" srcset="
/community/media/blogs/kafka-controller-broker-explained/epoch-number_hu0d56464ab7710eb0c72339108d848be9_45220_60f7d0456161f3cf7749b27aae0caeea.webp 400w,
/community/media/blogs/kafka-controller-broker-explained/epoch-number_hu0d56464ab7710eb0c72339108d848be9_45220_0f8ab2d515879d560894819d31dc3add.webp 760w,
/community/media/blogs/kafka-controller-broker-explained/epoch-number_hu0d56464ab7710eb0c72339108d848be9_45220_1200x1200_fit_q75_h2_lanczos_2.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-controller-broker-explained/epoch-number_hu0d56464ab7710eb0c72339108d848be9_45220_60f7d0456161f3cf7749b27aae0caeea.webp"
width="760"
height="288"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>Broker 1が最も大きい&lt;code>controllerEpoch&lt;/code>をZookeeperに保全する事になり、その他全てのより小さなepoch numberを持つControllerからの指示は無視されます。&lt;/p>
&lt;h3 id="その他の役割">その他の役割&lt;/h3>
&lt;p>Controllerには他にもやや地味な役割を担います：&lt;/p>
&lt;ul>
&lt;li>新しいTopicの作成&lt;/li>
&lt;li>新しいPartitionの作成&lt;/li>
&lt;li>Topicの削除&lt;/li>
&lt;/ul>
&lt;p>これら処理は、以前にはやや乱暴な方法で&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup>処理されていましたが、version 0.11と1.0からはControllerへのリクエストにて処理する方法にと変更されています。この方法は&lt;a href="https://kafka.apache.org/documentation/#adminapi" target="_blank" rel="noopener">Admin Client API&lt;/a>として提供され、Kafkaクラスタへアクセスするアプリや管理者にも容易にアクセスすることが出来ます。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="2 Minutes Streaming" srcset="
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp 400w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_9b81ef5fad55639d712bb44153e40131.webp 760w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp"
width="760"
height="399"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
このエントリの著者である&lt;a href="../../authors/stanislav/">Stanislav Kozlovski&lt;/a> は&lt;a href="https://2minutestreaming.com/" target="_blank" rel="noopener">2 Minute Streaming&lt;/a>というKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>(訳者注)これはZookeeperをクラスタのメタデータ管理に利用する場合の話で、&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-595%3A&amp;#43;A&amp;#43;Raft&amp;#43;Protocol&amp;#43;for&amp;#43;the&amp;#43;Metadata&amp;#43;Quorum" target="_blank" rel="noopener">KRaft&lt;/a>と呼ばれるRaftベースのコンセンサスモデルでは3以上のControllerが存在する必要があります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>(訳者注)Kafka2.4より、最寄りのレプリカからReadする(&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A&amp;#43;Allow&amp;#43;consumers&amp;#43;to&amp;#43;fetch&amp;#43;from&amp;#43;closest&amp;#43;replica" target="_blank" rel="noopener">KIP-392&lt;/a>)機能が提供されています。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>”Fencing Token&amp;quot;とも呼ばれます。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4">
&lt;p>Bashスクリプトによって直接Zookeeperを更新の上、Controllerやその他Brokerがその変更を受け取るのを待つ、という実装でした。&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Confluent Cluster Linkingの仕組みについて</title><link>https://confluent-jp.github.io/community/blog/cluster-linking-demystified/</link><pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/cluster-linking-demystified/</guid><description>&lt;h2 id="クラスタ間のレプリケーション---一般的なアプローチ">クラスタ間のレプリケーション - 一般的なアプローチ&lt;/h2>
&lt;p>クラスタ間でデータのレプリケーションのニーズは古くからあり、DRや組織内のグループ会社間/事業部間の部分的なデータ共有、または&lt;a href="https://www.uber.com/en-JP/blog/kafka/" target="_blank" rel="noopener">UberさんのActive-Active双方向レプリケーション&lt;/a>の様な使い方もあります。いずれにせよ、何かしらの形でKafkaクラスタから他のクラスタにデータをレプリケートするという手法は変わらず、また利用できるツールも (多少の機能差異はありながらも) 基本的に同じアプローチを取っています。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Replicator Mechanism" srcset="
/community/media/blogs/cluster-linking-demystified/replicator-mechanism_hua771e280c70cf025bf445644156bacea_137607_6a7dc20682ffb664106b15d8d7a60f6e.webp 400w,
/community/media/blogs/cluster-linking-demystified/replicator-mechanism_hua771e280c70cf025bf445644156bacea_137607_68b65292a9a164eca0756f26b403592e.webp 760w,
/community/media/blogs/cluster-linking-demystified/replicator-mechanism_hua771e280c70cf025bf445644156bacea_137607_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/cluster-linking-demystified/replicator-mechanism_hua771e280c70cf025bf445644156bacea_137607_6a7dc20682ffb664106b15d8d7a60f6e.webp"
width="760"
height="395"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>基本的なアプローチはどのレプリケーションツールでも同じで、Producer/Consumerの両方を司るKafka Connectコネクタとして稼働します。SourceクラスタのTopicからConsumeし、DestinationクラスタのTopicにProduceする、理解し易いアプローチだと思います。当然SourceとDestinationのTopicは別々のものなのでPartition数を変える事も出来ますし、一般的なコネクタ同様&lt;a href="https://docs.confluent.io/platform/7.4/connect/transforms/overview.html" target="_blank" rel="noopener">SMT&lt;/a>を利用する事も出来ます。&lt;/p>
&lt;p>同時に、Kafkaクラスタの外で双方にアクセス出来るコンポーネントを別途運用する必要性もあります。レプリケーションツールとKafkaブローカー間にはペイロードの圧縮/解凍処理を挟み、独立したConsume/Produce処理となる為レイテンシも比較的高くなります。またKafkaクラスタ同士がお互いを認識している訳ではなく、それぞれのクラスタに存在するTopic同士も機械的な関連性はありません。当然双方のTopicのConsumer Offsetは全く独立して管理されている為、TopicにアクセスするConsumerをクラスタを跨いで移動させる場合には、何かしらの方法でConsumer Offsetを変換する必要性も発生します。&lt;/p>
&lt;h2 id="cluser-linking---クラスタを跨いだreplica-fetching">Cluser Linking - クラスタを跨いだReplica Fetching&lt;/h2>
&lt;p>Confluent Cluster Linkingのアプローチは大きく異なります。結果としてConsumer Offsetを含め全てのTopicに関するメタデータを完全に同期した状態でデータのレプリケーションが可能です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Cluster Linking Mechanism" srcset="
/community/media/blogs/cluster-linking-demystified/cluster-linking-mechanism_hu230bfaae51528d07c36b594b0b4778bf_129114_43868967e287aedf92cc92b6a4d38ff2.webp 400w,
/community/media/blogs/cluster-linking-demystified/cluster-linking-mechanism_hu230bfaae51528d07c36b594b0b4778bf_129114_d74af5d4933c58bf63cfd98a36755bff.webp 760w,
/community/media/blogs/cluster-linking-demystified/cluster-linking-mechanism_hu230bfaae51528d07c36b594b0b4778bf_129114_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/cluster-linking-demystified/cluster-linking-mechanism_hu230bfaae51528d07c36b594b0b4778bf_129114_43868967e287aedf92cc92b6a4d38ff2.webp"
width="760"
height="404"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>仕組みとしては、同一クラスタ内におけるKafkaのレプリケーションの仕組みに近く、&lt;a href="https://www.confluent.io/ja-jp/blog/multi-geo-replication-in-apache-kafka/" target="_blank" rel="noopener">Replica Fetcherと近い形でDestinationクラスタにあるBrokerがクラスタ境界を跨いでフェッチする&lt;/a>形でレプリケーションを行います。処理を仲介するものも、ワークロードの何かしらの受け渡しの様な処理も無いため、スループットも高く、また低レイテンシなレプリケーションが可能です。&lt;/p>
&lt;p>当然仲介用のConnectクラスタ等別途立ち上げる必要はありません。リンクの設置も、SourceもしくはDestinationクラスタであるConfluent CloudもしくはPlatformに対してリンク作成コマンドを実行すれば完了します。&lt;/p>
&lt;h2 id="特徴と注意点">特徴と注意点&lt;/h2>
&lt;p>先にメリットについては記載しましたが、非同期レプリケーションではありながらSourceとDestinationのデータ差 (オフセット) がこれまでのアプローチよりかなり小さく、また安定的に同期出来るので、DR等の適用時において復旧/欠損対象となるデータ量を限定する事が出来ます。メタデータごと完全に同期しているのでクラスタ間のデータギャップやその復旧時の運用負荷も下がります。フェイルオーバーを考えると、Cluster Linkingを利用した場合にはオペレーションをかなり簡素化出来るのが特徴です。&lt;/p>
&lt;h3 id="注意点-1---障害時にデータの欠損は起こり得る">注意点 1 - 障害時にデータの欠損は起こり得る&lt;/h3>
&lt;p>Cluster LinkingはMirrorMaker2等と比べると、確かに低レイテンシでデータの同期が可能です。しかしながらあくまで同期ではなく非同期のレプリケーションである為、RPO (Recovery Point Objective: 目標復旧地点) は0ではありません。Sourceクラスタにおいて、「書き込み完了と判断された後」かつ「その変更がDestinationクラスタ側からフェッチされるまで」にSourceクラスタがダウンしてしまう可能性はあり、この条件に合致する差分はSourceが再度復旧出来るまでアクセス出来ません。&lt;/p>
&lt;h3 id="注意点-2---topicはpartition数を含め完全一致">注意点 2 - TopicはPartition数を含め完全一致&lt;/h3>
&lt;p>DestinationクラスタにレプリケートされたTopicは&lt;code>Mirror Topic&lt;/code>と呼ばれる少し特殊なTopicです。具体的には：&lt;/p>
&lt;ul>
&lt;li>全Partitionのイベント数、イベント順序、各イベントのデータが全てSource Topicと全く同じとなる。&lt;/li>
&lt;li>Read OnlyでありDestinationクラスタ内から書き込み不可。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>
となります。&lt;/li>
&lt;/ul>
&lt;p>この為、例えばSourceクラスタのTopicからSMTを使って特定フィールドをマスキングしたり、Sourceと異なるPartition数をDestinationで指定する事は出来ません。&lt;/p>
&lt;h3 id="注意点-3---フェイルオーバー後の復旧はフェイルフォワードを推奨">注意点 3 - フェイルオーバー後の復旧はフェイルフォワードを推奨&lt;/h3>
&lt;p>Cluster LinkingではDR時にフェイルオーバーした際、基本的にDRであったクラスタを今度は本番と位置付けるようコマンドが整備されています。例えば東京リージョン (Prod) から大阪リージョン (DR) へのフェイルオーバー時に、大阪が本番リージョンとして機能します。その後東京リージョンが復旧した場合、フェイルバックするのではなく今度は東京をDRとして継続オペレーションを実施することを推奨しています。&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>上記に注意点を幾つか並べましたが、どれもCluster Linkingの欠点と言うよりは特性であり、つまりこの特性を充分理解した上でレプリケーション戦略を立てる事が大事です。&lt;/p>
&lt;ul>
&lt;li>注意点 1 - これは非同期レプリケーションである限り避けようがありません。逆に、非同期なのでSourceクラスタに対する書き込みレイテンシには影響を与えないメリットもあります。&lt;/li>
&lt;li>注意点 2 - 通常のReplica Fetcherの仕組みと近いと考えると当然で、バイトレベルで同一のデータをDestinationクラスタ上に持てるというメリットを考えると納得出来る制約だと思います。&lt;/li>
&lt;li>注意点 3 - これは意見が分かれるところかも知れません。データ基盤全体におけるBC戦略はKafkaのみのルールで決めれるものでは無いので、許容出来ないユースケースは多いと思います。ただ作業の手間が増えるだけで、フェイルバックする事は不可能ではありません。&lt;/li>
&lt;/ul>
&lt;p>他にも場合によってはMirrorMaker2やConfluent Replicatorの方が理に適った選択肢であるケースはあり、実際にもCluster LinkingではなくConfluent Replicatorを採用されるユーザーもいます。確かにCluster Linkingは画期的なレプリケーション機能ではありますが、その特性を理解した上で採用を判断する事が (何事に言える事ですが) 重要です。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>当然DR時にはMirror Topicを元にオペレーションを再開するので、その際は&lt;code>kafka-mirrors --failover&lt;/code>コマンドで書き込み出来るよう切り替えます。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Tiered Storageは何故そんなに重要なのか？</title><link>https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/</link><pubDate>Sun, 06 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/</guid><description>&lt;h2 id="tiered-storageとは">Tiered Storageとは&lt;/h2>
&lt;p>今年の後半にリリースが予定されている&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release&amp;#43;Plan&amp;#43;3.6.0" target="_blank" rel="noopener">Apache Kafka 3.6&lt;/a>には、Tiered Storageと呼ばれるKafkaコミュニティが待ち望んだ新機能が含まれる予定です。この機能は&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A&amp;#43;Kafka&amp;#43;Tiered&amp;#43;Storage" target="_blank" rel="noopener">KIP-405&lt;/a>として何年も前に登録されたKIPであり、長い期間をかけてようやくリリース目処が経ちました。&lt;/p>
&lt;p>これまでKafkaのデータは常にBrokerのストレージに格納されていましたが、これを二層化して古いセグメントを自動的に退避するという機能です。Kafkaに格納されたイベントをオブジェクトストレージに退避するというプラクティスは一般的であり、これまではKafka Connectコネクタを使って自分で退避させるアプローチを取っていました。これをKafkaネイティブな機能として提供する、その役割をKafka Brokerが行うというものです。クライアントからはこのオペレーションは隠蔽化されており、新しいイベントも古いイベントも同じアプローチでアクセスする事が出来ます。&lt;/p>
&lt;h2 id="tiered-storageの動き---図解">Tiered Storageの動き - 図解&lt;/h2>
&lt;p>これまで通り、クライアントから送られたイベントはkafka Brokerのストレージにセグメント単位で保存されます。セグメントはログファイルであり、ランダムアクセスではなくアペンドでしかデータを足せない為、最も新しいセグメント (Active Segmentと呼ばれます) 以外のファイルは不可変 (Immutable) です。&lt;/p>
&lt;p>Tiered Storageはこのうち古いセグメントを自動的にオブジェクトストレージに退避します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-1" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_307dc89e1a68d87bc27b49159af2e082.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_0c117106ee083960e7059ed25e9ffecd.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_307dc89e1a68d87bc27b49159af2e082.webp"
width="760"
height="290"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>中では新しくRemoteLogManagerと呼ばれるプロセスが、これまでのLogManagerに近い役割を果たしつつリモートストレージにコピーし、合わせてリモートストレージのインデックス状態のキャッシュを保持します。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-2" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_ed30da300d0b9b691d188362efbc7e4f.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_d4ef38034777db186c40e196ccf45f74.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_ed30da300d0b9b691d188362efbc7e4f.webp"
width="760"
height="277"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>上にあるように、Broker側の保全期間 (Retention Period) を超過しセグメントが削除された後も、リモートストレージにはそのコピーが残ります。ストレージの動きはこれだけで、リモートからローカルにセグメントが戻ってくる様な事はありません。これまでのLog Managerの役割もそのままで、ローカルのログは今まで通り管理されます。&lt;/p>
&lt;p>ほとんどのユースケースでは、クライアントは最新のセグメントに集中してアクセスします。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-3" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_13555c5a91b8f7799d7e3a3c89dd36dd.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_38b70ca4b82c8226d2b8975dc87ab4fb.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_13555c5a91b8f7799d7e3a3c89dd36dd.webp"
width="760"
height="277"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
書き込みは当然最新であるActive Segmentにしか発生しませんが、読み込みも多少のラグはありながらもほぼ最新に近いセグメントへのアクセスとなります。このアクセスはこれまでと何も変わらず、今まで通りBrokerがディスクI/O経由でデータを取得しクライアントに帰します。&lt;/p>
&lt;p>違いは、クライアントが古いセグメントにあるオフセットを指定して読み込みをリクエストした場合です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-4" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_2a2234b74cfe0781c6e5b4a49c707312.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_0641f49b3b2042ca8b889354eab7f534.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_2a2234b74cfe0781c6e5b4a49c707312.webp"
width="760"
height="288"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>既にBrokerのローカルストレージにはセグメントは存在しませんが、リモートストレージに存在する限りBrokerはデータを取得しクライアントに返すことが出来ます。&lt;/p>
&lt;h2 id="メリット-1---拡張性-scalability">メリット 1 - 拡張性 (Scalability)&lt;/h2>
&lt;p>Kafkaは拡張性に極めて優れたストリーミングプラットフォームであり、原則Brokerノードを追加することにより水平スケールする事ができます。一方、拡張には限界があります。一般的に大規模Kafkaクラスタにおけるボトルネックはネットワーク帯域で、次にストレージと言われています。これらを充分確保出来続ける限りKafkaクラスタは相当規模まで拡張出来ます。Tiered Storageによってストレージ容量の削減とより高度なコントロールが可能になります。&lt;/p>
&lt;p>KafkaにとってそれぞれのTopicの保全期間 (Retention Period) と書き込みスループットは基本的にはバランスゲームです - 高書き込みスループットの場合はストレージ容量の増加を加味してより短い保全期間を指定する必要があります。保全期間のデフォルトでは1週間、通常運用では1日という場合も多くありますが、高負荷のクラスタでは数時間程度に留める事も多くあります。&lt;/p>
&lt;p>kafkaは内部でデータのレプリケーションを行なっています。Replication Factorと呼ばれるこの設定のデフォルトは&lt;code>3&lt;/code>であり、稀に金融やストレッチクラスタ (複数のサイトに跨がる大きなクラスタ) では&lt;code>4&lt;/code>を指定する場合もありますが、ほとんどデフォルトのままではないかと思います。いずれにせよ、その指定分だけデータはレプリケートされるので、必要ディスク容量は増えます。&lt;/p>
&lt;p>例えば100MBpsで書き込みがなされる場合、レプリケーションも考慮するとクラスタ内のネットワーク帯域には300MBps、当然ストレージにも300MBpsのスピードで消費します。保全期間を1日とした場合、100 * 3600 * 3 = 1,080,000MB ≒ 1TBのストレージ容量が必要となります。書き込みスループットが倍になればストレージも倍、当然保全期間を倍にしてもストレージは倍必要になります。&lt;/p>
&lt;p>ストレージがボトルネックになった場合、ディスクを足せば解消しますが、それも限界を超えるとBroker自体を追加する必要が出てきます。Tiered Storageを導入すると、Brokerが必要とするストレージの絶対量を制限できます。同一ハード構成におけるキャパシティを上げ、将来的な拡張性も高く出来ます。&lt;/p>
&lt;h2 id="メリット-2---障害耐性-resiliency">メリット 2 - 障害耐性 (Resiliency)&lt;/h2>
&lt;p>ストレージを分離する事によって障害耐性が上がるというのはピンと来ないかも知れませんが、Tiered Stoargeによる効果と期待は障害耐性の向上にも集まっています。&lt;/p>
&lt;p>Kafkaが何事もなく稼働している限り、またデータが適切にパーティションされている限り、Kafkaクラスタは均一にデータを分散配置し管理出来ます。しかしBrokerのシャットダウンと復帰は必ず発生します。時としてハードやソフトの障害によって、他ではBroker/JVM/Guest OS/Host OS/Host Hardwareのアップグレードによって、クラスタ構成は短期/長期的にその構成が変わります - Kafkaは絶えずメンバーシップを変えつつ稼働し続ける分散システムであり、構成が変わる前提の上で成立している技術です。&lt;/p>
&lt;p>Brokerがクラスタメンバーから外れると、それまでそのBrokerで保全していたデータは必ず何かしらの方法で他のBrokerに再配置されなければデータの保全性が保てません。この為クラスタメンバーシップの変更は、大規模なメタデータの更新と、データの移動を意味します。&lt;/p>
&lt;p>Tiered Storageによって管理/移動対象となるセグメントの物理的な数が減れば、その分クラスタ内で移動するデータ量が減少し、また大量メタデータ更新に伴う二次災害の危険性も減少し、結果としてより安全に、より短い期間にクラスタが正常状態に復帰します。Kafkaクラスタ自体が軽量になればなるだけ、例えばコンテナの様により頻繁に刷新されるランタイム上でKafkaを運用する場合にも大きなメリットとなります。&lt;/p>
&lt;h2 id="メリット-3---リソースの有効活用-resource-utilization">メリット 3 - リソースの有効活用 (Resource Utilization)&lt;/h2>
&lt;p>Kafkaとは基本的にディスクI/Oへの負荷が高いプラットフォームです。これは書き込み/読み込みの発生頻度が高く、またディスクI/Oの有効利用が今回の設計思想に織り込まれています。併せて、Kafkaは原則マルチテナントプラットフォームであり、様々なワークロードが共存し易い (各々のワークロードの影響を受けにくい) ストリーミング基盤です。しかしながらKafkaにも物理的な制約は存在し、ワークロードのニーズ的にはクラスタ自体を分ける事も実際には多くあります。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;p>Tiered Storageへのアクセスは、Kafkaでは珍しくディスクI/OではなくネットワークI/Oへの比重が高い処理となります。例えば長期間実行するバッチ処理 (古いデータなのでTiered Storage経由) と、超低レイテンシな処理が求められるオンライン処理 (新しいデータなのでBrokerから) とではKafkaかかるリソース負荷が全く異なります。これら特性を上手く利用すれば、オンライン処理を実行しながら低負荷でバッチ処理を同一クラスタ内で扱う事も出来ます。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>Tiered StorageはApache Pulserの様なコンピュートとストレージを完全に切り離す目的で導入される訳ではありません。Kafkaはある意味意図的に原始的な設計をしている点が長所であり、時として短所となり得る技術です。Tiered StoargeはKafkaが本来持つ高スループットかつ低遅延な処理能力を殺す事なく、短所であるディスク容量やディスクI/Oというボトルネックを軽減させ得る可能性を持った非常に有望な機能です。併せて、よりクラウドネイティブな環境で動く機会の増えたKafkaにとって、その新しい環境により適合性の高い機能であるとも言えます。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>例えば長期実行されるバッチ処理が継続してKafkaにアクセスしている状態で、非常にレイテンシ要件の高いオンライン処理が同居する様な場合です。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>当然、充分なネットワーク帯域が確保されている場合には、という条件は付きます。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Kafka Acks再入門</title><link>https://confluent-jp.github.io/community/blog/kafka-acks-explained/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kafka-acks-explained/</guid><description>&lt;blockquote>
&lt;p>このブログエントリはKafkaコミッタである Stanislav Kozlovski(&lt;a href="https://https://twitter.com/BdKozlovski" target="_blank" rel="noopener">𝕏&lt;/a>|&lt;a href="https://www.linkedin.com/in/stanislavkozlovski/" target="_blank" rel="noopener">Ln&lt;/a>) のサイトで2022/11/06に公開された&lt;a href="https://www.linkedin.com/pulse/kafka-acks-explained-stanislav-kozlovski/" target="_blank" rel="noopener">Kafka Acks Explained&lt;/a>の日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。&lt;/p>
&lt;/blockquote>
&lt;p>Kafkaに関する仕事を始めて4年になりますが、経験上未だに2つの設定について広く誤解されていると感じる事があります。それは&lt;code>acks&lt;/code>と&lt;code>min.insync.replicas&lt;/code>であり、さらにはこの2つの設定がどう影響し合うかについてです。このエントリはこの非常に重要な2つの誤解を解き、適切に理解してもらう事を目的としています。&lt;/p>
&lt;h2 id="replication">Replication&lt;/h2>
&lt;p>この2つの設定を理解するためにはまずKafka Replicationプロトコルについて少しおさらいする必要があります。&lt;/p>
&lt;p>このブログの読者の皆さんはある程度Kafkaについてご存知だと想定しています - もし自信がない場合はぜひ&lt;a href="https://medium.com/hackernoon/thorough-introduction-to-apache-kafka-6fbf2989bbc1" target="_blank" rel="noopener">Thorough Introduction to Apache Kafka&lt;/a>もご参照ください。&lt;/p>
&lt;p>各Partitionには1つのLeader Broker(1)と複数のFollower Broker(N)がアサインされます。この複製の数は&lt;code>replication.factor&lt;/code>で設定する事ができ(1+N)つまり総数を表します。つまりこの設定では「対象となるPartitionに対してクラスタ上で何個の複製が出来るか」を指定します。&lt;/p>
&lt;p>デフォルトであり通常推奨する設定値は&lt;code>3&lt;/code>です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Replication Factor" srcset="
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_0d1ca0052156cf2b9740e68dcdd4c65a.webp 400w,
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_f54bf205681a70abfa295c3277922d09.webp 760w,
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_0d1ca0052156cf2b9740e68dcdd4c65a.webp"
width="760"
height="203"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
ProducerクライアントはLeader Brokerにのみ書き込みに行きます - つまりFollower Brokerへのレプリケーションは非同期に行われます。ここで分散システムとして考慮しないといけないのは、何かしらの方法で「これらレプリケーションされる処理がどのようにLeaderに追従すべきか」を指定する方法です。具体的には「Leaderに書き込まれた更新がFollowerにも反映されているか否か」です。&lt;/p>
&lt;h2 id="in-sync-replicas">In-Sync Replicas&lt;/h2>
&lt;p>in-sync replica(ISR)は対象Partitionの最新状態と同期が取れているBrokerを指します。当然Leaderは常にISRとなり、Followerの場合はLeaderの更新に追い付き同期が取れた状態のもののみISRとなります。仮にFollowerがLeaderに追従できなくなった場合、そのFollowerはISRではなくなります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="In-Sync Replicas" srcset="
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_fce72e1100ff5fc9564552f1283799b8.webp 400w,
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_53b76570ba3a381743ccf6f03feacf22.webp 760w,
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_fce72e1100ff5fc9564552f1283799b8.webp"
width="760"
height="247"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上の図ではBroker 3は同期されていないのでISRではない、つまりout-of-syncとなります。&lt;/p>
&lt;p>ちなみに、厳密にはISRか否かという判断はもう少し複雑で、ここで説明されているようにすんなり「このFollowerは最新の状態か」と判断出来る訳ではありません。ただ厳密な話をし始めるとこのエントリの主旨から外れるので、ここでは上の図にある赤いBrokerは同期が取れていないと、見たまま捉えてください。&lt;/p>
&lt;h2 id="acks">Acks&lt;/h2>
&lt;p>Acksはクライアント (Producer) 側の設定で、「どこまでFollowを含めて書き込みの確認が取れてからクライアントに返答するか」を指定するものです。有効な値は&lt;code>0&lt;/code>、&lt;code>1&lt;/code>、そして&lt;code>all&lt;/code>の3つです。&lt;/p>
&lt;h3 id="acks0">acks=0&lt;/h3>
&lt;p>&lt;code>0&lt;/code>が設定された場合、クライアントはBrokerまで到達したかの確認さえ行いません - メッセージがKafka Brokerに対して送られたタイミングでackを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=0" srcset="
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_3c44fb1f740910333022481170b7baae.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_882b78cb72dd80307fdacbd72dcd1221.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_3c44fb1f740910333022481170b7baae.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
ackと呼びますがBrokerからの返答さえ待ちません。送れたらOKです。&lt;/p>
&lt;h3 id="acks1">acks=1&lt;/h3>
&lt;p>&lt;code>1&lt;/code>が設定された場合、クライアント (Producer) はLeaderにまでメッセージが到達した時点で書き込みの完了と判断します。Leader Brokerはメッセージを受け取った時点でレスポンスを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=0" srcset="
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_3111a28552f0a098342a58fa79fec9da.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_e9144a72afa66fafd760c8736f931a9e.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_3111a28552f0a098342a58fa79fec9da.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
クライアントはレスポンスが返ってくるのを待ちます。Leaderからの返答が到着した時点で完了と判断しackとします。Leaderは受け取り次第レスポンスを返すので、Followerへのレプリケーションはレスポンスとは非同期に処理されます。&lt;/p>
&lt;h3 id="acksall">acks=all&lt;/h3>
&lt;p>&lt;code>all&lt;/code>と設定された場合、クライアントは全てのISRにメッセージが到達した時点で書き込みの完了と判断します。この際Leader BrokerがKafka側の書き込み判定を行なっており、全てのISRへのメッセージ到達の上クライアントにレスポンスを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all incomplete" srcset="
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_d7dcaf69c8cd6d40de1b4c5fa07bce88.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上の図の状態ではBroker 3はまだメッセージを受け取っていません。この為Leaderはレスポンスを返しません。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all completed" srcset="
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_516f5fcece0585c45a349a2c530fc785.webp 400w,
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_95c6e832fba07495adfbb75a5b8d0104.webp 760w,
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_516f5fcece0585c45a349a2c530fc785.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
全てのISRに渡って初めてレスポンスが返されます。&lt;/p>
&lt;h3 id="acksの機能性">acksの機能性&lt;/h3>
&lt;p>この通りacksはパフォーマンスとデータ欠損耐性のバランスを決める非常に有益な設定です。データ保全を優先するのであれば&lt;code>acks=all&lt;/code>の設定が適切です。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> 一方レイテンシやスループットに関する要件が極めて高い場合には&lt;code>0&lt;/code>に設定すれば最も効率が良くなりますが、同時にメッセージロスの可能性は高まります。&lt;/p>
&lt;h2 id="minimum-in-sync-replicas">Minimum In-Sync Replicas&lt;/h2>
&lt;p>&lt;code>acks=all&lt;/code>の設定に関して、もう一つ重要な要素があります。&lt;/p>
&lt;p>例えばLeaderが全てのISRへの書き込み完了した上でレスポンスを返すとして、LeaderのみがISRだった場合、結果として&lt;code>acks=1&lt;/code>と振る舞いは同じとなるのでしょうか？&lt;/p>
&lt;p>ここで&lt;code>min.insync.replicas&lt;/code>の設定が重要になります。&lt;/p>
&lt;p>&lt;code>min.insync.replicas&lt;/code>というBroker側の設定は、&lt;code>acks=all&lt;/code>の際に「最低いくつのISRとなっているか (Leaderを含めて幾つのレプリカが最新状態か) を指定するものです。つまりLeaderは、&lt;code>acks=all&lt;/code>のリクエストに対して指定されたISRに満たないまでは返答せず、またそれが何かしらの理由で達成できない場合にはエラーを返します。データ保全観点でのゲートキーバーの様な役割を果たします。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all and ISR=2" srcset="
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_c68b5a3947a2b0f20bf8ea75ce7a2101.webp 400w,
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_249c85c3d6a5b99c5af7bf892f6e56ab.webp 760w,
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_c68b5a3947a2b0f20bf8ea75ce7a2101.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上記の状態だとBroker 3は同期されていない状態です。しかしながら&lt;code>min.insync.replicas=2&lt;/code>となっている場合には条件を満たす為この時点でレスポンスが返されます。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all and ISR below min.insync.replicas" srcset="
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_49566929a4d489d75f27fe22a6bcec7c.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_924c01716b6e3c2021b34f2f98f42045.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_49566929a4d489d75f27fe22a6bcec7c.webp"
width="760"
height="192"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Broker 2と3が同期されていない状態です。この場合指定された&lt;code>min.insync.replicas&lt;/code>を下回るためLeaderからはエラーレスポンスが返る、つまり書き込みは失敗します。一方同じ状況であっても&lt;code>acks&lt;/code>の設定が&lt;code>0&lt;/code>もしくは&lt;code>1&lt;/code>の場合には正常なレスポンスが返されます。&lt;/p>
&lt;h3 id="注意点">注意点&lt;/h3>
&lt;p>一般的に&lt;code>min.insync.replicas&lt;/code>は「Leaderがクライアントに返答する際に、どれだけレプリケーションが完了しているかを指定する」と解釈されていますが、これは誤りです。正確には「リクエストを処理する為に最低いくつのレプリカが存在するか」を指定する設定です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all incomplete" srcset="
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_d7dcaf69c8cd6d40de1b4c5fa07bce88.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上記の場合、Broker 1から3までが全て同期状態です。この時に新たなリクエスト (ここではメッセージ&lt;code>6&lt;/code>) を受け取った場合、Broker 2への同期が完了してもレスポンスは返しません。この場合、処理時にISRとなっているBroker 3への同期が完了して初めてレスポンスが返されます。&lt;/p>
&lt;h2 id="まとめ">まとめ&lt;/h2>
&lt;p>図で説明したことによって理解が深まったのではないかと思います。&lt;/p>
&lt;p>おさらいすると、&lt;code>acks&lt;/code>と&lt;code>min.insync.replicas&lt;/code>はKafkaへの書き込みにおける欠損体制を指定する事ができます。&lt;/p>
&lt;ul>
&lt;li>&lt;code>acks=0&lt;/code> - 書き込みはクライアントがLeaderにメッセージを送った時点で成功とみなします。Leaderからのレスポンスを待つことはしません。&lt;/li>
&lt;li>&lt;code>acks=1&lt;/code> - 書き込みはLeaderへの書き込みが完了した時点で成功とみなします。&lt;/li>
&lt;li>&lt;code>acks=all&lt;/code> - 書き込みはISR全てへの書き込みが完了した時点で成功とみなします。ISRが&lt;code>min.insync.replicas&lt;/code>を下回る場合には処理されません。&lt;/li>
&lt;/ul>
&lt;h3 id="その他情報">その他情報&lt;/h3>
&lt;p>Kafkaは複雑な分散システムであり、学ばなければいけない事が多いのも事実です。Kafkaの他の重要な要素については以下も参考にしてください。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.confluent.io/blog/apache-kafka-data-access-semantics-consumers-and-membership/" target="_blank" rel="noopener">Kafka consumer data-access semantics&lt;/a> - クライアント (Consumer) における欠損耐性、可用性、データ整合性の確保に関わる詳細。&lt;/li>
&lt;li>&lt;a href="https://medium.com/@stanislavkozlovski/apache-kafkas-distributed-system-firefighter-the-controller-broker-1afca1eae302" target="_blank" rel="noopener">Kafka controller&lt;/a> - Broker間の連携がどの様になされるのかの詳細。特にレプリカが非同期 (Out-of-Sync) となるのはどういう条件下かについて説明しています。&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/blog/configure-kafka-to-minimize-latency/" target="_blank" rel="noopener">“99th Percentile Latency at Scale with Apache Kafka&lt;/a> - Kafkaのパフォーマンスに関するConfluent Blogエントリ。&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/resources/kafka-summit-san-francisco-2019/" target="_blank" rel="noopener">Kafka Summit SF 2019 videos&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/blog/" target="_blank" rel="noopener">Confluent blog&lt;/a> - Kafkaに関する様々なトピックを網羅。&lt;/li>
&lt;li>&lt;a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">Kafka documentation&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Kafkaは継続的かつアクティブに開発されていますが、機能追加や改善は活発なコミュニティにより支えられています。開発の最前線で何が起こっているか興味がある場合はぜひ&lt;a href="https://kafka.apache.org/contact" target="_blank" rel="noopener">メーリングリスト&lt;/a> に参加してください。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="2 Minutes Streaming" srcset="
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp 400w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_9b81ef5fad55639d712bb44153e40131.webp 760w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp"
width="760"
height="399"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
このエントリの著者である&lt;a href="../../authors/stanislav/">Stanislav Kozlovski&lt;/a> は&lt;a href="https://2minutestreaming.com/" target="_blank" rel="noopener">2 Minute Streaming&lt;/a>というKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>(訳者注)ほとんどのユースケースでは&lt;code>acks=all&lt;/code>が適切であり、Kafkaのデフォルトでもあります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Streaming Audio - Kafkaに本当にあった(まだある)ヤバいバグ5選</title><link>https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/</link><pubDate>Sat, 29 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=yFlvWRwRTT8&amp;amp;list=PLa7VYi0yPIH1B0i7mhzVi78TIkKSd-0vE" target="_blank" rel="noopener">Streaming Audio&lt;/a>はConfluentがPodcast&amp;amp;YouTubeシリーズとして提供しています。毎回ゲストを迎え様々なトピックについてフリーにディスカッションするポッドキャストで、Kafka初期開発メンバーのJun RaoやKRaftの開発メンバー、Kafkaのリアルユーザー等様々なゲストスピーカーが参加します。中でも「アナネキ」ことAnna McDonald (Technical Voice of CUstomer @Confluent)登場回は毎回必見で、いつも何か新しい発見があります。&lt;/p>
&lt;p>今回はその彼女の登場回の中でも最も最近の回のご紹介です：お題は「Kafkaに本当にあったヤバいバグ5選&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>」です。(オリジナルの公開は2022/12/21) このトークで紹介されたJIRAバグの一覧を用意しました。結構最近になってようやく入ったものや、まだ直っていないものもあります。Kafkaのバージョンはなるべく追従する事を強くお勧めしていますが、ここにあるのは全体の一部で、なかなかに怖いバグへの修正も入っています。&lt;/p>
&lt;p>あなたのKafkaクラスタはほんとに大丈夫です？&lt;/p>
&lt;h4 id="kafka-10888-sticky-partition-leads-to-uneven-product-msg-resulting-in-abnormal-delays-in-some-partitionshttpsissuesapacheorgjirabrowsekafka-10888">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-10888" target="_blank" rel="noopener">KAFKA-10888: Sticky partition leads to uneven product msg, resulting in abnormal delays in some partitions&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Sticky Partitionerを使用時、Partition間の処理数に大きな偏りが出る様な状況となり特定のPartitionのスループットが極端に下がる事がある: 場合によってはリカバリ不能なほどProducer側のバッチが肥大化する。&lt;/p>
&lt;h4 id="kafka-9648-add-configuration-to-adjust-listen-backlog-size-for-acceptorhttpsissuesapacheorgjirabrowsekafka-9648">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-9648" target="_blank" rel="noopener">KAFKA-9648: Add configuration to adjust listen backlog size for Acceptor&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.2.0)&lt;/p>
&lt;/blockquote>
&lt;p>OSがLinuxの場合に発生。ローリングアップグレード等の際、BrokerからPartition Leaderが他のBrokerに移る、もしくは移ったのちに元のBrokerに戻る (Preferred Leader Election) が発生。この際Partitionに関するメタデータ更新が行われる為これらPartitionを参照するクライアントから一斉に再接続のリクエストが送られる。状況によってはLinuxのSYN cookieの機能が動きTCPバッファーが制限されスループットが大幅に低下する。これは再接続しない限り復旧しない。&lt;/p>
&lt;h4 id="kafka-12686-race-condition-in-alterisr-response-handlinghttpsissuesapacheorgjirabrowsekafka-12686">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-12686" target="_blank" rel="noopener">KAFKA-12686: Race condition in AlterIsr response handling&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Partition.scala内の処理において、AlterIsrResponseとLeaderAndIsrRequestのレースコンディションが起因。クラスタサイズが小さくPartition数が多い場合、Brokerノードの変更時に大量のPartition変更が発生する。この際AlterIsrManagerがペンディング状態のリクエストをクリアしてしまう為、AlterIsrResponseが戻ってきた際に処理中 (in Flight) であるのに処理タスク (Pending) が無いという矛盾状態が発生する。&lt;/p>
&lt;h4 id="kafka-12964-corrupt-segment-recovery-can-delete-new-producer-state-snapshotshttpsissuesapacheorgjirabrowsekafka-12964">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-12964" target="_blank" rel="noopener">KAFKA-12964: Corrupt segment recovery can delete new producer state snapshots&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Brokerの停止時、猶予時間内に終了しない場合には Unclearn Shutdownと判断される。この際Broker復帰時に残っていたセグメントは不要と判断され非同期で削除が実行される。この削除が完了する前に同じオフセットのセグメントが書き込まれる状態となると、新しいProducer Stateスナップショットが誤って削除される事がある。&lt;/p>
&lt;h4 id="kafka-14334-delayedfetch-purgatory-not-completed-when-appending-as-followerhttpsissuesapacheorgjirabrowsekafka-14334">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-14334" target="_blank" rel="noopener">KAFKA-14334: DelayedFetch purgatory not completed when appending as follower&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.4.0, 3.3.2)&lt;/p>
&lt;/blockquote>
&lt;p>ConsumerがPulgatoryからフェッチするケースにおいて、通常通りPartitionリーダーからフェッチする場合には正しくフェッチの完了が認識される。しかしConsumerがフォローワーがフェッチする設定としている(&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A&amp;#43;Allow&amp;#43;consumers&amp;#43;to&amp;#43;fetch&amp;#43;from&amp;#43;closest&amp;#43;replica" target="_blank" rel="noopener">KIP-932&lt;/a>)場合、フォローワーのPartitionはPulgatoryに存在しない為フェッチ出来ずタイムアウトする。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>オリジナルは6選であり、ここではそのうち&lt;a href="https://issues.apache.org/jira/browse/KAFKA-9211" target="_blank" rel="noopener">KAFKA-9211: Kafka upgrade 2.3.0 may cause tcp delay ack(Congestion Control)&lt;/a>も含んでいますが、トークの中ではKafka-9646の中で合わせて語られているので割愛しました。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Kafkaの利用が適さないユースケースとは？</title><link>https://confluent-jp.github.io/community/blog/when-not-to-use-kafka/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/when-not-to-use-kafka/</guid><description>&lt;blockquote>
&lt;p>このブログエントリはConfluent Field CTOである&lt;a href="https://www.kai-waehner.de/" target="_blank" rel="noopener">Kai Waeehner&lt;/a>のサイトで2022/1/4に公開された &lt;a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/" target="_blank" rel="noopener">When NOT to use Apache Kafka?&lt;/a>の日本語訳です。Kai本人の了承を得て翻訳/公開しています。&lt;/p>
&lt;/blockquote>
&lt;p>Apache Kafkaは、Data in Motionにおけるイベントストリーミングのデファクトスタンダードです。あらゆる業界でその採用が大きく伸びているため、私は毎週のように『ではApache Kafkaを使うべきでは無いのはどんな場合？』『ストリーム処理の基盤に重要な要素は？』『kafkaにこの機能性が無いのはなぜ？』『Kafkaを採用しないと判断する為の条件とは？』という質問を受けます。このブログ記事では、Kafkaを使うべき時、Kafkaを使うべきでない時、そしてKafkaを使うべきかもしれない時について順番に説明します。&lt;/p>
&lt;h1 id="市場動向---コネクテッドワールド">市場動向 - コネクテッド・ワールド&lt;/h1>
&lt;p>まずは、なぜKafkaがいたるところで登場するのかを理解することから始めます。このことは、イベントストリーミングに対する市場の大きな需要を明らかにすると同時に、すべての問題を解決する銀の弾丸は存在しないことを示しています。Kafkaは繋がる世界 (コネクテッドワールド) の特効薬ではなく、重要なコンポーネントと捉える必要があります。&lt;/p>
&lt;p>世界はますます繋がりを広げています。膨大な量のデータが生成され、収益増加、コスト削減、リスク軽減のためにリアルタイムに関連付ける必要があります。この動きはどの業界でも進んでいますが、より速い業界もあれば遅い業界もあります。しかしこの繋がりはあらゆるところに届いています。製造業、スマートシティ、ゲーム 、小売、銀行、保険などどこでもです。私の過去のブログには、どの業界にも関連するKafkaの使用事例を見つけることができます。&lt;/p>
&lt;p>私はこのデータの急激な成長を、イノベーションと新しい最先端のユースケースの創出を示す2つのマーケットトレンドとして捉えています。(そしてKafkaの採用が業界を超えて急激である理由も併せて) 。&lt;/p>
&lt;h2 id="コネクテッドカー---膨大な量のテレメトリデータとアフターセールス">コネクテッド・カー - 膨大な量のテレメトリデータとアフターセールス&lt;/h2>
&lt;p>アライドマーケットリサーチの&lt;a href="https://www.alliedmarketresearch.com/connected-car-market" target="_blank" rel="noopener">世界の機会分析と産業予測、2020-2027年&lt;/a> からの引用です:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Allied Market Research" srcset="
/community/media/blogs/why-not-apache-kafka/allied-market-connected-car_hua22a3ec17f28f168e924775b3e52cfd3_1959714_db5b190486f89ca348a11f080b5178d4.webp 400w,
/community/media/blogs/why-not-apache-kafka/allied-market-connected-car_hua22a3ec17f28f168e924775b3e52cfd3_1959714_214ff4fcbcde9c7e6d4427c5caafb625.webp 760w,
/community/media/blogs/why-not-apache-kafka/allied-market-connected-car_hua22a3ec17f28f168e924775b3e52cfd3_1959714_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/allied-market-connected-car_hua22a3ec17f28f168e924775b3e52cfd3_1959714_db5b190486f89ca348a11f080b5178d4.webp"
width="760"
height="440"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
コネクテッドカー市場には、多くの人が考えているよりもはるかに幅広いユースケースと業界が含まれています。いくつか例を挙げると:ネットワークインフラとコネクティビティ、セキュリティ、エンターテインメント、小売、アフターマーケット、自動車保険、サードパーティデータ利用(スマートシティなど)。その他にも様々なユースケースが存在します。&lt;/p>
&lt;h2 id="ゲーミング---数十億人のプレーヤーと巨額の収益">ゲーミング - 数十億人のプレーヤーと巨額の収益&lt;/h2>
&lt;p>ゲーム産業はすでに他のすべてのメディア・カテゴリーを合わせたよりも大きくなっており、&lt;a href="https://www.bitkraft.vc/gaming-industry-market-size/" target="_blank" rel="noopener">Bitkraft&lt;/a>が描くように、これはまだ新しい時代の始まりに過ぎないとも言えます。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Bitkraft Gaming Market" srcset="
/community/media/blogs/why-not-apache-kafka/bitcraft-gaming-market_hu3a27e687e062ea6074bf68a0f9b131e4_136977_a34339b92a2774f788ff9ac6e5fae2c6.webp 400w,
/community/media/blogs/why-not-apache-kafka/bitcraft-gaming-market_hu3a27e687e062ea6074bf68a0f9b131e4_136977_12c81dd125cba30f8d7d7803102d7584.webp 760w,
/community/media/blogs/why-not-apache-kafka/bitcraft-gaming-market_hu3a27e687e062ea6074bf68a0f9b131e4_136977_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/bitcraft-gaming-market_hu3a27e687e062ea6074bf68a0f9b131e4_136977_a34339b92a2774f788ff9ac6e5fae2c6.webp"
width="760"
height="341"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>既に世界中で毎月何百万人もの新規プレイヤーがゲームコミュニティに参加しています。インターネットへの接続性と安価なスマートフォンは、それほど裕福でない国でも広く普及しています。 Play to Earnのような新しいビジネスモデルは、次世代のゲーマーのゲームの遊び方を変えており、5Gのような拡張性の高い低遅延技術が新たなユースケースを可能にしています。更にはブロックチェーンとNFT(Non-Fungible Token)は、マネタイズとコレクター市場を永遠に変えようとしています。&lt;/p>
&lt;p>業界を横断するこうした市場動向は、リアルタイムデータ処理のニーズが四半期ごとに大幅に増加している理由を明らかにしています。Apache Kafkaは分析およびトランザクションデータ ストリームを大規模に処理するためのデファクトスタンダードとしての地位を既に確立しています。しかしながら、Apache Kafkaとその周辺エコシステムの技術をプロジェクトで使用する(しない)タイミングを理解することも併せて非常に重要です。&lt;/p>
&lt;h1 id="apache-kafkaとは何で何では無いのか">Apache Kafkaとは何で、何では無いのか？&lt;/h1>
&lt;p>Kafkaは誤解されやすい技術です。例えばKafkaはメッセージキューだという話をいまだによく耳にします。その理由のひとつは、一部のベンダーが自社製品を売るために特定の問題(データレイクやデータウェアハウスへのデータ取り込みなど)に対してのみKafkaを売り込んでいるからだと思われます。&lt;/p>
&lt;p>Kafkaは：&lt;/p>
&lt;ul>
&lt;li>スケーラブルなリアルタイム・メッセージング・プラットフォームで、毎秒数百万のメッセージを処理する。&lt;/li>
&lt;li>大量のビッグデータ分析から少量のトランザクションデータ処理まで対応するイベント・ストリーミング・プラットフォーム。&lt;/li>
&lt;li>分散ストレージは、背圧処理のための真のデカップリングを提供し、様々な通信プロトコルをサポートし、順序が保証されたイベントの再生可能性を提供する。&lt;/li>
&lt;li>ストリーミングETLのためのデータ統合フレームワーク。&lt;/li>
&lt;li>ステートレスまたはステートフルな連続ストリーム処理のためのデータ処理フレームワーク。&lt;/li>
&lt;/ul>
&lt;p>これら様々なユースケース/利用パターンを一つのプラットフォームで提供出来る点がKafkaの特徴です。&lt;/p>
&lt;p>一方以下はKafkaに当てはまりません：&lt;/p>
&lt;ul>
&lt;li>数百万を超えるクライアントからの直接接続 - Kafkaネイティブのプロキシ(RESTやMQTTなど)、いくつかのユースケースに対応しているが全てではない。&lt;/li>
&lt;li>API管理プラットフォーム - これらのツールは通常補完的であり、Kafka APIの作成、ライフサイクル管理、または収益化のために使用される。&lt;/li>
&lt;li>バッチ分析や複雑なクエリをサポートするDB - トランザクションクエリや比較的単純な集計(特にksqlDBを使用)では充分扱える。&lt;/li>
&lt;li>デバイス管理を行うIoTプラットフォーム - MQTTやOPC-UAなどのIoTプロトコルとKafkaを直接統合することは可能であり、(一部の)ユースケースには適切なアプローチである。&lt;/li>
&lt;li>ミリ秒レイテンシを達成するハード・リアルタイム・アプリケーションのための技術 (セーフティ・クリティカル・システムや決定論的システム) - ただ組み込みソフトウェアを除くと全てのプラットフォームが同様であり、Kafkaもその例外では無いというだけである。&lt;/li>
&lt;/ul>
&lt;p>このような理由から、Kafkaは他のテクノロジーと競合するものではなく、補完するものであると言えます。仕事に適したツールを選び、それらを組み合わせる上でKafkaは全体における重要な要素となり得ます。&lt;/p>
&lt;h1 id="コネクテッドワールドにおけるapache-kafkaのケーススタディ">コネクテッドワールドにおけるApache Kafkaのケーススタディ&lt;/h1>
&lt;p>ここではKafkaを他のテクノロジーと組み合わせることで、ビジネス上の問題を解決した素晴らしいサクセスストーリーの例をいくつか紹介します。エンドツーエンドのデータフローにKafka以上のものを必要とするケーススタディに焦点を当てています。&lt;/p>
&lt;p>私のブログ、Kafka Summitカンファレンス、MediumやDzoneのようなオンラインリソース、その他の技術関連のニュースなど、どれをフォローしても同じです。コネクテッドカー、IoTエッジデバイス、スマートフォンのゲーム/アプリなどからの大量のアナリティクスやトランザクショ・データをApache Kafkaでリアルタイム データストリー ミングする成功例をたくさん見つけることができます。&lt;/p>
&lt;p>業種や使用例をいくつか挙げてみます:&lt;/p>
&lt;ul>
&lt;li>AUDI - コネクテッドカー・プラットフォームが地域とクラウドプロバイダーを横断的に展開。&lt;/li>
&lt;li>BMW - サプライチェーンとロジスティクスの最適化を実現するスマート工場。&lt;/li>
&lt;li>SolarPower - 太陽光発電のソリューションとサービスを世界中で提供。&lt;/li>
&lt;li>Royal Caribbian - エッジサービスとハイブリッド・クラウドの集約によるクルーズ船のエンターテイメント。&lt;/li>
&lt;li>Disney+ Hotstar - インタラクティブなメディアコンテンツとゲーム/ベッティングをスマートフォンで数百万人のファンに提供。&lt;/li>
&lt;/ul>
&lt;p>このような素晴らしいIoTのサクセスストーリーにおいてKafkaは課題はあるかというと、問題無く非常に有機的に機能しています。しかしながら、Apache Kafkaエコシステムでイベントストリーミングを使用するタイミングと、他の補完的なソリューションを利用すべきかの判断について説明するためには、いくつか明確化が必要です。&lt;/p>
&lt;h1 id="apache-kafkaを使うべき場合">Apache Kafkaを使うべき場合&lt;/h1>
&lt;p>Kafkaを使うべきでない場合について説明する前に、Kafkaを使うべき場所を理解し、必要に応じて他のテクノロジーと補完する方法とタイミングをより明確に説明します。ここから実例をユースケースごとに分けていくつかご紹介します。&lt;/p>
&lt;h2 id="kafkaは大量のiotやモバイルデータをリアルタイムかつ大量に扱う事ができる">Kafkaは大量のIoTやモバイルデータをリアルタイムかつ大量に扱う事ができる。&lt;/h2>
&lt;p>Teslaは単なる自動車メーカーではありません。Teslaは、革新的で最先端のソフトウェ アを数多く開発しているハイテク企業です。Teslaは自動車のためのエネルギーインフラも併せて提供しています。スーパーチャージャー、ギガファクトリーでの太陽エネルギー生産等も然りです。&lt;/p>
&lt;p>車両、スマートグリッド、工場からのデータを処理/分析し、残りのITバックエンドサービスとリアルタイムで統合することは、同社の成功に不可欠な要素です。&lt;/p>
&lt;p>Teslaは&lt;a href="https://www.confluent.io/blog/stream-processing-iot-data-best-practices-and-techniques/" target="_blank" rel="noopener">Kafkaベースのデータプラットフォームインフラ&lt;/a>を構築し『1日あたり数百万台のデバイスと数兆のデータポイントをサポート』しています。テスラは2019年のKafka Summitで、&lt;a href="https://www.confluent.io/kafka-summit-san-francisco-2019/0-60-teslas-streaming-data-platform/" target="_blank" rel="noopener">彼らのKafka利用のな歴史とその進化&lt;/a>について登壇しています。&lt;/p>
&lt;p>私はほとんどすべてのブログエントリでこのことを繰り返していますが、Kafkaは単なるメッセージングではないことを改めて強調させてください。Kafkaは分散ストレージレイヤーであり、プロデューサーとコンシューマーを真に分離し、さらにKafka StreamsやksqlDBのようなKafkaネイティブの処理ツールによってリアルタイム処理を可能にします。&lt;/p>
&lt;h2 id="kafkaはiotデータとmesやerpシステムからのトランザクションデータを結び付ける">KafkaはIoTデータとMESやERPシステムからのトランザクションデータを結び付ける&lt;/h2>
&lt;p>規模の大きなリアルタイムでのデータ統合には、アナリティクスやERPやMESシステムのようなトランザクションシステムの利用に密接に関連しています。Kafka Connectやその他非Kafkaミドルウェアは、このタスクのためにイベントストリーミングのコアを補完する役割を果たします。&lt;/p>
&lt;p>BMWは&lt;a href="https://www.youtube.com/watch?v=3cG2ud7TRs4" target="_blank" rel="noopener">エッジ(スマート工場など)とパブリッククラウドでミッションクリティカルなKafkaワークロード&lt;/a>を運用しています。Kafkaはこれらシステムの疎結合性/透明性を高め活用によるイノベーションを可能にします。併せてConfluentの製品と専門知識により安定性を担保しています。後者は製造業での成功に不可欠です - 1分のダウンタイムによって組織に莫大なコストがかかリマス。関連記事&lt;a href="https://www.kai-waehner.de/blog/2020/04/21/apache-kafka-as-data-historian-an-iiot-industry-4-0-real-time-data-lake/" target="_blank" rel="noopener">Apache Kafka as Data Historian - an IIoT / Industry 4.0 Real-Time Data Lake&lt;/a>をご参照ください。Kafkaが製造業の総合設備効率(OEE)をどのように改善出来るか理解頂けると思います。&lt;/p>
&lt;p>BMWはリアルタイムでサプライチェーン管理を最適化しています。このソリューションは、物理的にもBMWのERP(SAP搭載)のようなトランザクションシステムにおいても、 適切な在庫に関する情報を提供します。「Just-in-Time/Just-in-Sequence」は、多くのアプリケーションにとって極めて重要です。KafkaとSAPの統合は、この分野で私が話をする顧客のほぼ半分で必要とされています。また、統合だけでなく&lt;a href="https://www.kai-waehner.de/blog/2020/11/20/postmodern-erp-mes-scm-with-apache-kafka-event-streaming-edge-hybrid-cloud/" target="_blank" rel="noopener">多くの次世代トランザクションERPやMESプラットフォームもKafkaを利用して&lt;/a>います。&lt;/p>
&lt;h2 id="kafkaはエッジやハイブリッドマルチクラウドにおいて企業内のすべての非iot-itと統合する">Kafkaはエッジやハイブリッド/マルチクラウドにおいて、企業内のすべての非IoT ITと統合する&lt;/h2>
&lt;p>Apache Kafkaのマルチクラスタおよびデータセンター間のデプロイは例外ではなく、むしろ一般的なアプローチになりつつあります。マルチクラスタが必要となる可能性のあるいくつかのシナリオについて学び、DR、分析のための集約、クラウドへのマイグレーション、ミッションクリティカルな拡張クラスタの展開、&lt;a href="https://www.kai-waehner.de/blog/2020/01/29/deployment-patterns-distributed-hybrid-edge-global-multi-data-center-kafka-architecture/" target="_blank" rel="noopener">global Kafka&lt;/a>など、具体的な要件とトレードオフの実例をご確認ください。&lt;/p>
&lt;p>異なるインターフェース間の真の疎結合化は、IBM MQやRabbitMQ、MQTTブローカーなどの&lt;a href="https://www.kai-waehner.de/blog/2019/03/07/apache-kafka-middleware-mq-etl-esb-comparison/" target="_blank" rel="noopener">他のメッセージング・プラットフォームに対するKafkaの競争優位&lt;/a>です。この点については、&lt;a href="https://www.confluent.io/blog/microservices-apache-kafka-domain-driven-design/" target="_blank" rel="noopener">Kafkaを使ったドメイン駆動設計(DDD)について&lt;/a>の記事でも詳しく説明しました。Apache Kafkaを使用したインフラの近代化とハイブリッドクラウドアーキテクチャは、業界を問わず一般的です。&lt;/p>
&lt;p>私が好きな例のひとつにUnityの成功例があります。同社はゲームに特化したリアルタイム3D開発プラットフォームで、拡張現実(AR)/仮想現実(VR)機能により製造業など他の産業にも進出しています。&lt;/p>
&lt;p>データ主導型の同社は、2019年にすでにコンテンツが330億回インストールされ、世界中の30億台のデバイスに届いています。併せてUnityは世界最大級のマネタイズネットワークを運営しています。彼らはこのプラットフォームを自己管理のオープンソースKafkaからフルマネージドのConfluent Cloudに移行しました。カットオーバーはダウンタイムやデータ損失なしにUnityのプロジェクトチームによって実施されました。Unityの取り組みはConfluentブログ&lt;a href="https://www.confluent.io/blog/how-unity-uses-confluent-for-real-time-event-streaming-at-scale/" target="_blank" rel="noopener">Using Confluent Platform to Complete a Massive Cloud Provider Migration and Handle Half a Million Events Per Second&lt;/a>でご紹介しています。&lt;/p>
&lt;h2 id="kafkaはモビリティサービスやゲームベッティングプラットフォーム向けのスケーラブルなリアルタイムバックエンドである">Kafkaはモビリティサービスやゲーム/ベッティングプラットフォーム向けのスケーラブルなリアルタイムバックエンドである&lt;/h2>
&lt;p>多くのゲームやモビリティサービスは、インフラのバックボーンとしてイベントストリーミングを活用しています。ユースケースには、遠隔測定データの処理、位置情報サービス、決済、不正検出、ユーザー/プレイヤーの維持、ロイヤリティプラットフォームなど、多くのものが含まれます。この分野のほとんどすべての革新的なアプリケーションは、スケールの大きなリアルタイム データストリーミングを必要とします。&lt;/p>
&lt;p>いくつか例を挙げます：&lt;/p>
&lt;ul>
&lt;li>モビリティサービス - Uber、Lyft、FREE NOW、Grab、Otonomo、Here Technologies
、etc.&lt;/li>
&lt;li>ゲームサービス - Disney+ Hotstar、Sony Playstation、Tencent、Big Fish Games、etc.&lt;/li>
&lt;li>ベッティングサービス - William Hill、Sky Betting、etc.&lt;/li>
&lt;/ul>
&lt;p>これらユーザーが常に公の場でKafkaの使用について話しているわけではありません。しかしモビリティサービスやゲームサービスの求人ポータルを見れば分かりますが、ほとんどの企業がプラットフォームを開発/運用するKafkaのエキスパートを常に探しています。&lt;/p>
&lt;p>これらのユースケースは、コア・バンキング・プラットフォームにおける決済プロセスと同様に重要です - 規制やコンプライアンス、データ損失ゼロという保全要件が同様に当てはまります。Multi Region Cluster(MRC - 米国東部、中部、西部のような地域にまたがるKafkaクラスタ)は、ダウンタイムゼロの高可用性を実現し、災害の場合でもデータ損失はありません。&lt;/p>
&lt;h2 id="車両マシンiotデバイスに単一のkafkaブローカーを組み込む">車両、マシン、IoTデバイスに単一のKafkaブローカーを組み込む&lt;/h2>
&lt;p>エッジにおけるKafkaの利用は一定数の成功を収め、また今後も成長します。一部のユースケースでは、データセンター外にKafkaクラスタまたはシングルブローカーを展開する必要があります。Kafkaインフラをエッジで運用する理由には、低レイテンシー、コスト効率、サイバーセキュリティ、インターネット接続がないことなどがあります。&lt;/p>
&lt;p>エッジKafka特有の用件としては：&lt;/p>
&lt;ul>
&lt;li>Disconnected edge - 物流センターで良好なインターネット接続が利用できるようになるまで、ログ/センサーデータ/画像をオフラインの状態(例えば、路上のトラックや船の周りを飛行するドローン)で保全する。&lt;/li>
&lt;li>小規模なローカルデータセンターにおけるVehicle-to-Everything (V2X) コミュニケーション - AWS Outpostsのようなエリアが広い、車両数が多い、ネットワークが貧弱な場合はMQTTのようなゲートウェイを経由し通信する。またはスマートファクトリーなど数百台のマシンの場合はKafkaクライアントとの直接接続を経由して通信する。&lt;/li>
&lt;li>Offline mobility services - 自動車インフラとゲーム、地図、ある いはレコメンデーション・エンジンとローカルに処理されたパートナーサービス(例えば『あと10マイルでマクドナルドが届きます』『クーポンはこちらです 』)を統合する。&lt;/li>
&lt;/ul>
&lt;p>Royal Caribbeanクルーズラインは、このシナリオの偉大な成功例です。世界で4番目に大きな客船を運航しています。2021年1月現在同社は24隻の客船を運航しており、さらに6隻の客船を発注中です。&lt;/p>
&lt;p>Royal Caribbeanは、Kafkaの最も有名なユースケースの1つをエッジで実装しています。各クルーズ船は、決済処理、ロイヤルティ情報、顧客推奨などのユースケースのために、ローカル(つまり船上)で Kafkaクラスタを運用しています:
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Royal Caribbean Kafka on Ship" srcset="
/community/media/blogs/why-not-apache-kafka/royal-caribbean-edge_hu142929b2a19cace8682461f35ad0e92a_65515_29262cf10737168a3c8d375181f33b8d.webp 400w,
/community/media/blogs/why-not-apache-kafka/royal-caribbean-edge_hu142929b2a19cace8682461f35ad0e92a_65515_38419bb2e4317437de90e09e0b4aceb1.webp 760w,
/community/media/blogs/why-not-apache-kafka/royal-caribbean-edge_hu142929b2a19cace8682461f35ad0e92a_65515_1200x1200_fit_q75_h2_lanczos.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/royal-caribbean-edge_hu142929b2a19cace8682461f35ad0e92a_65515_29262cf10737168a3c8d375181f33b8d.webp"
width="760"
height="428"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>私はこの事例や他のKafkaエッジ展開を様々なブログで取り上げました。&lt;a href="https://www.kai-waehner.de/blog/2020/10/14/use-cases-architectures-apache-kafka-edge-computing-industrial-iot-retail-store-cell-tower-train-factory/" target="_blank" rel="noopener">エッジでのKafkaのユースケース&lt;/a>について話したり、&lt;a href="https://www.kai-waehner.de/blog/2021/02/01/retail-store-apache-kafka-from-edge-to-cloud-hybrid-streaming-architecture/" target="_blank" rel="noopener">エッジでのKafkaのアーキテクチャ&lt;/a>を紹介したり、 &lt;a href="https://www.kai-waehner.de/blog/2021/05/23/apache-kafka-cloud-native-telco-infrastructure-low-latency-data-streaming-5g-aws-wavelength/" target="_blank" rel="noopener">Kafkaを利用した低遅延の5Gデプロイメント&lt;/a>についても説明しています。&lt;/p>
&lt;h1 id="apache-kafkaを使うべきでない場合">Apache Kafkaを使うべきでない場合&lt;/h1>
&lt;p>ようやく主題の話となりますが、まずKafkaを使うアプローチについて理解する事が重要なのでご説明しました。では、Kafkaを使うべきでない場合はその逆なので比較的簡単です。&lt;/p>
&lt;p>このセクションでは、コンセプトの実証のための非現実的な構成ではなく本番利用を前提とします。検証の場合取り急ぎの構成で確認することはありますが、インフラをグロ ーバルに拡張し、コンプライアンスに準拠し、かつデータ欠損を許容しない保証をする場合には妥当ではありません。あくまで本番利用の観点で見る事により、比較的容易にKafkaの採択が妥当ではないという評価も可能です。&lt;/p>
&lt;h2 id="kafkaはハードリアルタイムではない">Kafkaはハードリアルタイムではない&lt;/h2>
&lt;p>『リアルタイム』という言葉の定義は難しく、マーケティング用語であることが多くあります。実際にリアルタイムシステムは、指定された時間の制約の中で応答を保証しなければならない、という条件を満たしたものとなります。&lt;/p>
&lt;p>Kafkaに限らず、同じ文脈で使用されるその他のフレームワーク、製品、クラウドサービスはすべてソフト・リアルタイムのみです。OTやIoTの世界では、レイテンシのスパイクが全くないハードリアルタイムを必要とする場合も多くあります。&lt;/p>
&lt;p>一方ソフトリアルタイムのユースケースは：&lt;/p>
&lt;ul>
&lt;li>ITアプリケーション間のP2Pのメッセージング&lt;/li>
&lt;li>さまざまなデータソースから1つまたは複数のデータシンクへのデータ連携&lt;/li>
&lt;li>データ処理とデータ連携(しばしばイベントストリーム処理と呼ばれるもの)&lt;/li>
&lt;/ul>
&lt;p>であり、ミリ秒以下のレイテンシーを必要とするアプリケーションの場合、Kafkaは適切な選択ではありません。例えば、リアルタイム決済取引は通常、専用の商用ソリューション上に実装されます。&lt;/p>
&lt;p>この点は強調したいのですが、最もレイテンシーが低いのは、メッセージングシステムを一切使わず、共有メモリだけを使うアプローチです。極限まで低レイテンシを求める場合にはKafkaは向きません。一方、監査ログやトランザクションログ、それらの永続化やデータ整合性の担保等が必要な場合にはKafkaは非常に有効な選択肢です。&lt;/p>
&lt;p>リアルタイムのユースケースのほとんどは、ミリ秒から秒単位のデータ処理が必要要件であり、その場合Kafkaは適切なソリューションです。Robinhoodのような多くのFinTech企業は、ミッションクリティカルなトランザクション、さらには金融取引に至るまでKafkaに依存しています。マルチアクセス・エッジコンピューティング(MEC)は、Kafkaとクラウドネイティブな5Gインフラによる低遅延データストリーミングのもう一つの優れた例です。&lt;/p>
&lt;h2 id="kafkaは組込みシステムや安全関連システムには不向き">Kafkaは組込みシステムや安全関連システムには不向き&lt;/h2>
&lt;p>これは前項との補足的な意味合いで、Kafkaは瞬時な対応が必要不可欠な場合には利用すべきではありません。例えば、自動車のエンジン制御システム、 心臓ペースメーカーなどの医療システム、産業用ロボットの異常検知等、全く遅延なくかつ確実に対応が求められるユースケースがそれに該当します。&lt;/p>
&lt;p>これらユースケースの例では：&lt;/p>
&lt;ul>
&lt;li>自動車や車両における安全関連データ処理 - これらはAutosar/MINRA C/アセンブラ等のソリューションが適切です。&lt;/li>
&lt;li>ECU間のCAN Bus通信&lt;/li>
&lt;li>ロボット工学 - C/C++または類似の低レベル言語と、産業用ROS(ロ
ボット・オペレーティング・システム)などのフレームワークを組み合わせたソリューションが適切です。&lt;/li>
&lt;li>安全関連の機械学習/ディープラーニング(自律走行用など)&lt;/li>
&lt;li>車両間(V2V)通信 - Kafkaのような仲介者を介さない5G sidelinkの方が適切です。&lt;/li>
&lt;/ul>
&lt;p>などが挙げられますが、別途&lt;a href="https://www.kai-waehner.de/blog/2021/01/04/apache-kafka-is-not-hard-real-time-industrial-iot-embedded-connected-vehicles-automotive/" target="_blank" rel="noopener">Apache Kafka is NOT Hard Real Time BUT Used Everywhere in Automotive and Industrial IoT&lt;/a>にてより詳細に説明しています。&lt;/p>
&lt;p>TL;DR:
安全関連のデータ処理は、専用の低レベルプログラミング言語とソリューションで実装する必要があります。それはKafkaではなく、また他のITソフトウェアにも同じことが言えます。したがって、KafkaをIBM MQ、Flink、Spark、Snowflake、その他類似のITソフトウェアに置き換えても解決しません。&lt;/p>
&lt;h2 id="不安定なネットワーク上での接続に不向き">不安定なネットワーク上での接続に不向き&lt;/h2>
&lt;p>Kafkaは、KafkaクライアントとKafkaブローカー間の安定したネットワーク接続を必要とします。したがって、ネットワークが不安定でクライアントが常にブローカーに再接続する必要がある場合、運用は困難となり、高SLAを達成するのは難しくなります。&lt;/p>
&lt;p>例外もありますが、基本的な経験則として他のテクノロジーは不安定なネットワークの問題を解決するために特別に設計されています。例えばMQTTが最も顕著な例です。KafkaとMQTTは敵同士ではなく、組み合わせる事によって相互の欠点を補う事ができると考えるべきです。この組み合わせは非常に強力で、業界を問わず多く使われています。この組み合わせは&lt;a href="https://www.kai-waehner.de/blog/2021/03/15/apache-kafka-mqtt-sparkplug-iot-blog-series-part-1-of-5-overview-comparison/" target="_blank" rel="noopener">別のブログシリーズ&lt;/a>として残しています。&lt;/p>
&lt;h2 id="何万ものクライアントからの直接接続には不向き">何万ものクライアントからの直接接続には不向き&lt;/h2>
&lt;p>統合ソリューションとしてKafkaを除外するもう1つの具体的なポイントは、Kafkaは何万ものクライアントに接続できないという点です。コネクテッドカーのインフラやモバイルプレーヤー向けのゲームプラットフォームを構築する必要がある場合、クライアント (車やスマートフォンなど) をKafkaに直接接続することは得策ではありません。&lt;/p>
&lt;p>この場合、HTTPゲートウェイやMQTTブローカーのような専用プロキシとの併用が有効です。リアルタイムのバックエンド処理や、データレイク/データウェアハウス/リアルタイムアプリケーションの様なデータシンクとの統合のために、何万ものクライアントとKafkaの間の適切な仲介役として機能します。&lt;/p>
&lt;p>『ではKafkaクライアント接続数の限界はどのくらいか?』と聞かれますが、これはよくあることですが『ケースバイケースです』としか答えようがありません。.NETやJavaのKafkaクライアントを経由して、工場の現場からKafkaクラスタが稼働しているクラウドに直接接続している顧客を見たことはあります。マシン/PLC/IoTゲートウェイ/IoTデバイスの数が数百台であれば、ハイブリッドの直接接続は比較的上手くいきます。クライアント/アプリケーションの数がこれより多い場合は、a) 中間にプロキシが必要か、b) 低レイテンシでコスト効率の高いワークロードを実現するために、エッジにKafkaを使うか、選択肢はあります。後者はエッジコンピューティングにもKafkaを導入するかどうかを評価する必要が合わせてあります。&lt;/p>
&lt;h1 id="ケースバイケースでapache-kakfaが使える場合">ケースバイケースでApache Kakfaが使える場合&lt;/h1>
&lt;p>これまではKafkaの機能や仕組み上比較的簡単にKafkaがフィットしないユースケースについて説明しました。今度はケースバイケースで採用が可能、評価にはその他複数の検討要件があるユースケースを取り上げます。&lt;/p>
&lt;h2 id="kafkaは一般的なデータベースの置き換えにはならない">Kafkaは(一般的な)データベースの置き換えにはならない&lt;/h2>
&lt;p>ある意味Kafkaはデータベースです。ACID保証を提供し、何百もの企業でミッションクリティカルなワークロードに使用されています。しかし、ほとんどの場合Kafkaは他のデータベースと競合しません。Kafkaは、メッセージング、ストレージ、処理、統合を、ダウンタイムやデータ損失ゼロでリアルタイムに大規模に行うためのイベント・ストリーミング・プラットフォームです。&lt;/p>
&lt;p>Kafkaはこのような特徴を持つストリーミング統合レイヤーの中心として使用される事が多いです。その他のデータベースはその周辺には存在し、リアルタイムの時系列分析、テキスト検索インフラへのリアルタイムの取り込み、データレイクへの長期保存など、特定のユースケースのためにデータをマテリアライズする役割で使用できます。&lt;/p>
&lt;p>『Kafkaをデータベースの代替として利用できるか?』を考える場合：&lt;/p>
&lt;ul>
&lt;li>Kafkaは、ACID保証を提供する耐久性と可用性の高い方法でデータを恒久的に保存することができる。&lt;/li>
&lt;li>Kafkaには履歴データを照会するためのさらなるオプションを提供する。&lt;/li>
&lt;li>ksqlDBやTiered StorageのようなKafkaネイティブなアドオンにより、Kafkaはデータ処理やイベントの長期保存にさらに選択肢が増える。&lt;/li>
&lt;li>Kafkaクライアント (マイクロサービス、業務アプリ) を活用することで、他の外部データベースなしでステートフルなアプリケーションを構築できる。&lt;/li>
&lt;li>MySQL、MongoDB、Elasticsearch、Hadoop、Snowflake、Google BigQueryなど、既存のデータベース、データウェアハウス、データレイクを置き換えるものではない。&lt;/li>
&lt;li>他のデータベースとKafkaは互いに補完し合う。課題に応じて適切なソリューションを選択する必要がある。多くの場合、専用のマテリアライズド・ビューとしてデータベースが利用され、中央のイベントベース・インフラからリアルタイムで更新される。&lt;/li>
&lt;li>Kafkaとデータベース間の双方向のプルおよびプッシュベースの統合には、さまざまなオプションが用意されておりお互いを補完することができます。&lt;/li>
&lt;/ul>
&lt;p>といった観点から評価する必要があります。&lt;a href="https://www.kai-waehner.de/blog/2020/03/12/can-apache-kafka-replace-database-acid-storage-transactions-sql-nosql-data-lake/" target="_blank" rel="noopener">Can Apache Kafka Replace a Database?&lt;/a>ではこのKafkaをデータベースとして利用する場合の考慮点についてさらに深く言及しています。&lt;/p>
&lt;h1 id="apache-kafkaは一般的にサイズの大きなメッセージの処理に向かない">Apache Kafkaは(一般的に)サイズの大きなメッセージの処理に向かない&lt;/h1>
&lt;p>Kafkaは大きなサイズのメッセージを扱う様に設計されていません。&lt;/p>
&lt;p>それにもかかわらず、Kafka経由で1Mb、10Mb、さらにはもっと大きなファイルやその他の大きなペイロードを送信し処理するプロジェクトが増えています。その理由の1つは、Kafka が大容量/スループット向けに設計されており、その特性が大容量メッセージの転送にとって重要だからです。よくある例としては、レガシーシステムからKafkaを使って大きなファイルを取り込み、処理したデータをデータウェアハウスに取り込むというものがあります。&lt;/p>
&lt;p>しかし、すべての大きなメッセージをKafkaで処理する必要性はありません。多くの場合、適切な別のストレージシステムを使い、オーケストレーションにだけKafkaを活用すべきです。参照ベースの同期(つまりファイルを別のストレージシステムに保存し、リンクとメタデータを送信する)の方が良いデザインパターンであることが多いです。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Kafka for large message" srcset="
/community/media/blogs/why-not-apache-kafka/kafka-for-large-message_hu19ae6d4f22c7e640234acf2b7f9f8786_1173475_d636e6c861379594b14e0e411ec0d356.webp 400w,
/community/media/blogs/why-not-apache-kafka/kafka-for-large-message_hu19ae6d4f22c7e640234acf2b7f9f8786_1173475_3101a925fea111a2975b0e48b7776598.webp 760w,
/community/media/blogs/why-not-apache-kafka/kafka-for-large-message_hu19ae6d4f22c7e640234acf2b7f9f8786_1173475_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/kafka-for-large-message_hu19ae6d4f22c7e640234acf2b7f9f8786_1173475_d636e6c861379594b14e0e411ec0d356.webp"
width="760"
height="438"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>いくつかある選択肢のうち、特定の課題に対して適切なソリューションを選択する必要があります。詳しくは&lt;a href="https://www.kai-waehner.de/blog/2020/08/07/apache-kafka-handling-large-messages-and-files-for-image-video-audio-processing/" target="_blank" rel="noopener">Handling Large Messages with Apache Kafka (CSV, XML, Image, Video, Audio, Files)&lt;/a>で詳しく説明しています。&lt;/p>
&lt;h2 id="kafkaは一般的に産業用プロトコルのiotゲートウェイではない">Kafkaは(一般的に)産業用プロトコルのIoTゲートウェイではない&lt;/h2>
&lt;p>IoTインターフェースやモバイルアプリへのエンドポイントの提供はなかなかに難しい課題です。上述したように、Kafkaは何万ものKafkaクライアントに接続することはできません。しかし多くのIoTやモバイルアプリでは、数十から数百の接続しか必要としません。その場合Kafkaネイティブ接続は (地球上のほぼすべてのプログラミング言語で利用可能な) さまざまなKafkaクライアントのいずれかを使用して簡単にできます。&lt;/p>
&lt;p>KafkaクライアントとのTCPレベルでの接続が現実的ではないとします。このような場合、クライアントとKafkaクラスタの仲介役としてRESTプロキシを利用するのが一般的です。クライアントは、ストリーミングプラットフォームと同期HTTP(S) を介して通信します。&lt;/p>
&lt;p>&lt;a href="https://www.confluent.io/blog/http-and-rest-api-use-cases-and-architecture-with-apache-kafka/" target="_blank" rel="noopener">Apache Kafkaを使ったHTTPとREST APIのユースケース&lt;/a>にて言及していますが、Control Plane(=管理)、Data Plane(=メッセージの生成と消費)、自動化(それぞれDevOpsタスク)を含みます。&lt;/p>
&lt;p>ただ実際には、多くのIoTプロジェクトではもっと複雑な統合が必要となります。MQTTやOPC-UAコネクターを介した比較的簡単な統合だけではなく、産業用IoTプロジェクトではさらに以下のような課題があります:&lt;/p>
&lt;ul>
&lt;li>オートメーション業界はオープンスタンダードを使用していないことが多いが、遅 く、安全でなく、拡張性がなく、プロプライエタリである。&lt;/li>
&lt;li>製品のライフサイクルは非常に長く(数十年)、簡単な変更やアップグレードはできな
い。&lt;/li>
&lt;li>IIoT(Industrial IoT)は通常、互換性のないプロトコルを使用しており、通常は特定のベンダーによって独自に構築されている。&lt;/li>
&lt;li>原則拡張性の無い、独自で高価なモノリシックコンポーネントで構成されている。&lt;/li>
&lt;/ul>
&lt;p>多くのIoTプロジェクトでは専用のIoTプラットフォームでKafkaを補完するアプローチを取っています。ほとんどのIoT製品やクラウドサービスはプロプライエタリですが、オープンなインターフェースとアーキテクチャも存在します。この業界ではオープンソースの領域は大きくありません。ただ一部のユースケースでは&lt;a href="https://www.kai-waehner.de/blog/2019/09/02/apache-kafka-ksql-and-apache-plc4x-for-iiot-data-integration-and-processing/" target="_blank" rel="noopener">Apache PLC4X&lt;/a>が素晴らしい選択肢となり得ます。このフレームワークはSiemens S7、Modbus、Allen Bradley、Beckhoff ADSといった多くのプロプライエタリなレガシープロトコルとの統合を可能にします。合わせてPLC4Xはネイティブでスケーラブルな Kafka統合用のKafka Connectコネクタも提供しています。&lt;/p>
&lt;p>モダンなデータヒストリアンのアプローチはオープンかつ柔軟になり得ます。工場ラインとハイブリッドクラウドを繋ぐ様な戦略的IoTプロジェクトの基盤は、イベントストリーミングによって支えられています。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Kafka as Data Historian" srcset="
/community/media/blogs/why-not-apache-kafka/data-histroan_hucac6e8539a7743ac879c9fb1a53242ac_1370489_028a5f2b56940f52a2316b9499064ea1.webp 400w,
/community/media/blogs/why-not-apache-kafka/data-histroan_hucac6e8539a7743ac879c9fb1a53242ac_1370489_4555075586dce86b24f2cb52f3255eea.webp 760w,
/community/media/blogs/why-not-apache-kafka/data-histroan_hucac6e8539a7743ac879c9fb1a53242ac_1370489_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/data-histroan_hucac6e8539a7743ac879c9fb1a53242ac_1370489_028a5f2b56940f52a2316b9499064ea1.webp"
width="760"
height="429"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h2 id="kafkaはブロックチェーンではないただしweb3暗号取引nftオフチェーンサイドチェーンオラクルには関係する">Kafkaはブロックチェーンではない(ただし、web3、暗号取引、NFT、オフチェーン、サイドチェーン、オラクルには関係する)&lt;/h2>
&lt;p>Kafkaは仕組みとしては『分散コミットログ』です。またその概念と基盤はブロックチェーンと非常ににています。これについては&lt;a href="https://www.kai-waehner.de/blog/2020/07/17/apache-kafka-blockchain-dlt-comparison-kafka-native-vs-hyperledger-ethereum-ripple-iota-libra/" target="_blank" rel="noopener">Apache Kafka and Blockchain – Comparison and a Kafka-native Implementation&lt;/a>という投稿で詳しく説明しました。&lt;/p>
&lt;p>ブロックチェーンは、お互いが信頼できない関係者が協力する必要がある場合にのみ使うべき技術です。ほとんどの企業プロジェクトにとって、ブロックチェーンは不必要な複雑さを追加する事にもなります。分散コミットログ(=Kafka)か、改ざん防止の分散台帳(=拡張Kafka)で充分なケースがほとんどです。&lt;/p>
&lt;p>さらに興味深いことに、&lt;a href="https://www.kai-waehner.de/blog/2022/02/04/apache-kafka-as-data-hub-for-crypto-defi-nft-metaverse-beyond-the-buzz/" target="_blank" rel="noopener">暗号取引プラットフォーム、市場取引所、NFTトークン取引マーケ ットプレイスでKafkaを使用する企業&lt;/a>が増えています。&lt;/p>
&lt;p>ここで改めて、Kafkaはこれらのプラットフォームにおけるブロックチェーンとして機能している訳ではないという点を強調しておきます。ブロックチェーンとは、ビットコインのような暗号通貨や、イーサリアムのようなスマートコントラクトを提供するプラットフォームのことで、人々はゲームやアート業界のNFTのような新しい分散アプリケーション(dApps)をその上に構築します。一方Kafkaは、これらのブロックチェーンをCRM、データレイク、データウェア ハウスなどの他のオラクル(=非ブロックチェーンアプリ)と接続するためのストリーミングプラットフォームとして機能します。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Kafka and Blockchain" srcset="
/community/media/blogs/why-not-apache-kafka/kafka-and-blockchain_hu0ac2df983601f2a0a837082a16f7db3b_716012_c19e823a7157eb754eb4d12dbedd027d.webp 400w,
/community/media/blogs/why-not-apache-kafka/kafka-and-blockchain_hu0ac2df983601f2a0a837082a16f7db3b_716012_41fd50496afe73a543d51caf1ee0c799.webp 760w,
/community/media/blogs/why-not-apache-kafka/kafka-and-blockchain_hu0ac2df983601f2a0a837082a16f7db3b_716012_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/why-not-apache-kafka/kafka-and-blockchain_hu0ac2df983601f2a0a837082a16f7db3b_716012_c19e823a7157eb754eb4d12dbedd027d.webp"
width="760"
height="425"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>TokenAnalystは、ビットコインとイーサリアムからの&lt;a href="https://www.confluent.io/en-gb/blog/reliable-fast-access-to-on-chain-data-insights/" target="_blank" rel="noopener">ブロックチェーンデータを分析ツールと統合するためにKafkaを活用している優れた例&lt;/a>です。Kafka Streamsはステートフル・ストリーミング・アプリケーションを提供し、ダウンストリームの集計計算で無効なブロックの使用を防ぎます。例えばTokenAnalystはブロックを一時的に保持することで再編成シナリオを解決し、確認数(そのブロックの子ブロックが採掘される)の閾値に達した場合にのみ伝播する『ブロック・コンファイラー・コンポーネント』を開発しました。&lt;/p>
&lt;p>一部の高度なユースケースでは、オリジナルのブロックチェーンが十分にスケールしない為、サイドチェーンまたはオフチェーンプラットフォームの実装にKafkaが使用されています (ブロックチェーンはオンチェーンデータとして認識)。ビットコインに限らず、1秒間に1桁(!)のトランザクションしか処理できないというスケーラビリティの課題があります。 最新のブロックチェーン・ソリューションのほとんどは、Kafkaがリアルタイムで処理する拡張性に遠く及びません。&lt;/p>
&lt;p>DAO (分散型自律組織) から優良企業に至るまで、ブロックチェーンインフラとIoTコンポーネントの健全性を測定することは分散型ネットワークであっても必要です - ダウンタイムを回避し、インフラを保護し、ブロックチェーンデータにアクセスできるように配慮する必要があります。Kafkaはスケーラブルなデータの供給基盤として、ノードが失われる前に確実に関連システムに伝達する役割を果たします。これはHelium のような最先端のWeb3 IoTプロジェクトや、R3 Cordaのようなシンプルなクローズド分散型台帳(DLT)に関連しています。&lt;/p>
&lt;p>&lt;a href="https://www.kai-waehner.de/blog/2021/12/17/kafka-live-commerce-transform-retail-shopping-metaverse/" target="_blank" rel="noopener">イベントストリーミングとKafkaを活用したライブコマースが小売業のメタバースを変革する&lt;/a>という私の最近の投稿では、小売業とゲーム産業がいかに仮想的なものと物理的なものを結びつけているかの良い事例です。小売業のビジネスプロセスと顧客とのコミュニケーションはリアルタイムで行われ、洋服、スマートフォン、あるいはブロックチェーンベースのNFTトークンを使ったコレクターズアイテムやビデオゲームの販売等々に業界の差なく広く行われています。&lt;/p>
&lt;h1 id="tldr-kafkaとは">TL;DR: Kafkaとは&amp;hellip;&lt;/h1>
&lt;ul>
&lt;li>現行データベースやデータウェアハウスの代替となる。&lt;/li>
&lt;li>安全関連システムや組込みワークロードのためのハードリアルタイムを提供&lt;/li>
&lt;li>不安定なネットワークを経由した何万ものクライアントとの接続&lt;/li>
&lt;li>API管理ソリューション&lt;/li>
&lt;li>IoTゲートウェイ&lt;/li>
&lt;li>ブロックチェーン&lt;/li>
&lt;/ul>
&lt;p>これらユースケースにはKafkaは不向きであり、比較的容易に選択肢から外すことはできます。&lt;/p>
&lt;p>しかし、あらゆる業界の分析ワークロードやトランザクションワークロードがKafkaを使用しています。Kafkaはイベントストリーミングのデファクトスタンダードです。それゆえ、Kafkaはしばしば他のテクノロジーやプラットフォームと組み合わせる事が前提となります。&lt;/p></description></item><item><title>新コース - Event Modeling</title><link>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</guid><description>&lt;p>&lt;a href="developer.confluent.io">developer.confluent.io&lt;/a>にてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。&lt;/p>
&lt;p>UXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto Brandoliniによる&lt;a href="https://www.eventstorming.com/" target="_blank" rel="noopener">Event Sourcing&lt;/a>と近い思想によるデザイン手法の一つです。&lt;/p>
&lt;p>マイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。&lt;/p></description></item><item><title>Exactly Onceとmax.in.flightについて</title><link>https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/</link><pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。&lt;/p>
&lt;p>ただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。&lt;/p>
&lt;h2 id="exactly-once-semantics">Exactly Once Semantics&lt;/h2>
&lt;p>Kafka初期において最も注目を集めたエンハンスメントの一つに&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98&amp;#43;-&amp;#43;Exactly&amp;#43;Once&amp;#43;Delivery&amp;#43;and&amp;#43;Transactional&amp;#43;Messaging" target="_blank" rel="noopener">KIP-98 - Exactly Once Delivery and Transactional Messaging&lt;/a> があります。「メッセージ基盤においてExactly Onceは不可能」という&lt;a href="https://ja.wikipedia.org/wiki/%E4%BA%8C%E4%BA%BA%E3%81%AE%E5%B0%86%E8%BB%8D%E5%95%8F%E9%A1%8C" target="_blank" rel="noopener">二人の将軍問題&lt;/a> 観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして&lt;a href="https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/" target="_blank" rel="noopener">具体的な説明&lt;/a>もたくさんなされています。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;p>実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りは&lt;code>enable.idempotency=true&lt;/code>と設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">ack&lt;/span>&lt;span class="o">=&lt;/span>all
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">retries &amp;gt; &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">max.inflight.requests.per.connection&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。&lt;/p>
&lt;h2 id="kafka-5494">KAFKA-5494&lt;/h2>
&lt;p>&lt;a href="https://github.com/apache/kafka/pull/3743" target="_blank" rel="noopener">KAFKA-5494: enable idempotence with max.in.flight&amp;hellip;&lt;/a> このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>オリジナルのデザイン資料は&lt;a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/" target="_blank" rel="noopener">ここ&lt;/a>にあります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>合わせて&lt;code>OutOfSequenceException&lt;/code>が発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>またこのPRに関する前提情報や設計については別途&lt;a href="https://docs.google.com/document/d/1EBt5rDfsvpK6mAPOOWjxa9vY0hJ0s9Jx9Wpwciy0aVo/edit" target="_blank" rel="noopener">こちら&lt;/a>にまとめられています。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Queues for Kafkaとは何か?</title><link>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</link><pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A&amp;#43;Queues&amp;#43;for&amp;#43;Kafka" target="_blank" rel="noopener">KIP-932 Queues for Kafka&lt;/a> はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。&lt;/p>
&lt;h2 id="consumer-group">Consumer Group&lt;/h2>
&lt;p>Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。&lt;/p>
&lt;p>&lt;a href="https://www.confluent.io/blog/dynamic-vs-static-kafka-consumer-rebalancing/" target="_blank" rel="noopener">Consumer Group&lt;/a>はアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。&lt;/p>
&lt;p>一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。&lt;/p>
&lt;h2 id="これまでのアプローチ">これまでのアプローチ&lt;/h2>
&lt;p>ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。&lt;/p>
&lt;p>&lt;a href="https://github.com/line/decaton" target="_blank" rel="noopener">LINE Decaton&lt;/a> はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。&lt;/p>
&lt;p>&lt;a href="https://github.com/confluentinc/parallel-consumer" target="_blank" rel="noopener">Confluent Parallel Consumer&lt;/a> はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、&lt;a href="https://www.confluent.io/blog/introducing-confluent-parallel-message-processing-client/" target="_blank" rel="noopener">順序保証しない設定を含め柔軟に処理構成を変更&lt;/a>することが出来ます。&lt;/p>
&lt;h2 id="queue-for-kafka---kafka-nativeなアプローチ">Queue for Kafka - Kafka Nativeなアプローチ&lt;/h2>
&lt;p>Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。&lt;/p>
&lt;p>Shared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、&lt;code>group.type&lt;/code>を&lt;code>share&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。&lt;/p>
&lt;p>Consumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;code>group.type&lt;/code>は新しいプロパティ。デフォルトは&lt;code>consumer&lt;/code>であり、この指定だと通常通りConsumer Groupとして機能する。デフォルトは&lt;code>consumer&lt;/code>である為下位互換性あり。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Apache Kafka and the World of Streams</title><link>https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/</guid><description/></item><item><title>Hish SLA Kafka - Kafka Across Multiple DCs</title><link>https://confluent-jp.github.io/community/talk/20221226-kafka-meetup/</link><pubDate>Fri, 16 Dec 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20221226-kafka-meetup/</guid><description/></item><item><title>Cloud Native Kafka - 分散データ基盤がクラウドネイティブを目指すということ</title><link>https://confluent-jp.github.io/community/talk/20221121-cloudnativedays-tokyo/</link><pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20221121-cloudnativedays-tokyo/</guid><description/></item><item><title>Apache Kafka®️ and Modernization - How Old Data Meets New Data</title><link>https://confluent-jp.github.io/community/talk/20221025-yugabytedb-japan-hour/</link><pubDate>Tue, 25 Oct 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20221025-yugabytedb-japan-hour/</guid><description/></item><item><title>Apache Kafka and the World of Streams</title><link>https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/</link><pubDate>Tue, 24 May 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/</guid><description/></item><item><title>Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用</title><link>https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/</link><pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/</guid><description/></item><item><title>KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー</title><link>https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/</link><pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/</guid><description/></item><item><title>マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。</title><link>https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/</link><pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/</guid><description/></item><item><title>ksqlDB Clickstream Workshop</title><link>https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/</link><pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/</guid><description/></item><item><title>カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて</title><link>https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/</link><pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/</guid><description/></item><item><title>Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境</title><link>https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/</guid><description/></item></channel></rss>