<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Announcement | Confluent Japan Community</title><link>https://confluent-jp.github.io/community/category/announcement/</link><atom:link href="https://confluent-jp.github.io/community/category/announcement/index.xml" rel="self" type="application/rss+xml"/><description>Announcement</description><generator>Wowchemy (https://wowchemy.com)</generator><language>ja-jp</language><lastBuildDate>Mon, 30 Oct 2023 00:00:00 +0000</lastBuildDate><image><url>https://confluent-jp.github.io/community/media/icon_hubade5daff97c80353b10ab16b141ee15_5385_512x512_fill_lanczos_center_3.png</url><title>Announcement</title><link>https://confluent-jp.github.io/community/category/announcement/</link></image><item><title>Apache Flink 1.18 アップデート</title><link>https://confluent-jp.github.io/community/blog/apache-flink-1.8/</link><pubDate>Mon, 30 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/apache-flink-1.8/</guid><description>&lt;p>Apache Flinkの新バージョン1.18が公開されました。&lt;a href="https://www.confluent.io/blog/announcing-apache-flink-1-18/" target="_blank" rel="noopener">Conflunet Blog&lt;/a>ではその具体的な改善点をエリア毎に詳しく説明しており、ConfluentだけでなくVerverica、Aiven、Alibaba CloudのFlinkコミッターも共著として参加し、結果としてFlinkの情報発信として非常なものとなっております。&lt;/p>
&lt;p>昨年発表されたAkkaのライセンス変更に伴い、&lt;a href="https://flink.apache.org/2022/09/08/regarding-akkas-licensing-change/" target="_blank" rel="noopener">1年前にAkkaの代替模索に入った&lt;/a>Flinkプロジェクト。ようやくAkkaから&lt;a href="https://pekko.apache.org/" target="_blank" rel="noopener">Apache Pekko&lt;/a>に切り替えた節目のリリースとなりました。一方、ストリーム処理/バッチ処理を含め、Flinkのストリーム処理基盤としての成熟度がさらに増す多くの改善も含まれています。&lt;/p>
&lt;p>本エントリでは、一部ではありますがそのうちの幾つかをご紹介します。&lt;/p>
&lt;h3 id="flip-293-introduce-flink-jdbc-driver-for-sql-gatewayhttpscwikiapacheorgconfluencedisplayflinkflip-2933aintroduceflinkjdbcdriverforsqlgateway">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-293%3A&amp;#43;Introduce&amp;#43;Flink&amp;#43;Jdbc&amp;#43;Driver&amp;#43;For&amp;#43;Sql&amp;#43;Gateway" target="_blank" rel="noopener">FLIP-293: Introduce Flink Jdbc Driver For Sql Gateway&lt;/a>&lt;/h3>
&lt;p>FlinkクラスタへのRESTエンドポイントを提供する&lt;a href="https://github.com/ververica/flink-sql-gateway/blob/master/README.md" target="_blank" rel="noopener">Flink SQL Ga†eway&lt;/a>に、新たに汎用的なJDBC経由で通信できる&lt;a href="https://github.com/ververica/flink-jdbc-driver" target="_blank" rel="noopener">Flink JDBC Driver&lt;/a>が接続出来るようになりました。&lt;/p>
&lt;p>これまでSQL Gatewayにはコンソールベースでのアクセスは可能でしたが、セッションを保持したアプリケーションからのアクセスは出来ませんでした。一方JDBC Driverの基本利用はFlink Jobの登録にあり、インタラクティブなクエリはサポートされていませんでした。本FLIPによりこの2者を繋げ、SQL Gateway経由でJDBC接続が可能な多くのデータベースに対してJDBC Driverから接続出来るようになりました。&lt;/p>
&lt;h3 id="flip-311-support-call-stored-procedurehttpscwikiapacheorgconfluencedisplayflinkflip-3113asupportcallstoredprocedure">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-311%3A&amp;#43;Support&amp;#43;Call&amp;#43;Stored&amp;#43;Procedure" target="_blank" rel="noopener">FLIP-311: Support Call Stored Procedure&lt;/a>&lt;/h3>
&lt;p>これまでFlinkから見たデータソースはSourceでありSinkであり、あくまでデータストアという扱いにおける接続に限られました。本FLIPによってFlinkからStored Procedureの一覧取得と実行が可能となります。&lt;/p>
&lt;p>Stored Procedure実行におけるインターフェース変更に合わせ、&lt;a href="https://nightlies.apache.org/flink/flink-docs-master/api/java/org/apache/flink/table/catalog/Catalog.html" target="_blank" rel="noopener">Catalog Interface&lt;/a>にもStored Procedure用のメソッドが追加されており一覧の取得も可能です。&lt;/p>
&lt;h3 id="flip-308-support-time-travelhttpscwikiapacheorgconfluencedisplayflinkflip-3083asupporttimetravel">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-308%3A&amp;#43;Support&amp;#43;Time&amp;#43;Travel" target="_blank" rel="noopener">FLIP-308: Support Time Travel&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://en.wikipedia.org/wiki/SQL:2011" target="_blank" rel="noopener">SQL:2011 Standard&lt;/a>のTime Travel Queryがサポートされます。どちらもSQL:2011標準であるようタイムスタンプでの指定となりますが、特定時点ならびに期間指定がサポートされます。&lt;/p>
&lt;p>用途としてはデータレイクに長期格納しているデータに対してFlinkからソースアタッチする際に特定の過去時点でのデータも同様の方法で取得可能となります。IcebergやDelta Lake等、Time Travel Queryをサポートしているストレージに限られた機能となり、またConnectorが新しいインターフェースに沿って実装する必要があります。&lt;/p>
&lt;h3 id="flip-292-enhance-compiled-plan-to-support-operator-level-state-ttl-configurationhttpscwikiapacheorgconfluencedisplayflinkflip-2923aenhancecompiledplantosupportoperator-levelstatettlconfiguration">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-292%3A&amp;#43;Enhance&amp;#43;COMPILED&amp;#43;PLAN&amp;#43;to&amp;#43;support&amp;#43;operator-level&amp;#43;state&amp;#43;TTL&amp;#43;configuration" target="_blank" rel="noopener">FLIP-292: Enhance COMPILED PLAN to support operator-level state TTL configuration&lt;/a>&lt;/h3>
&lt;p>Table APIやSQLを利用してステートフルなストリームパイプラインを構築する際の、ステート管理に関わる改善です。JOINをしたり同じTableデータに異なる条件で集約したりする場合に、そのステートのベースとなるイベントの有効期間 (TTL: Time To Live) の制御によっては処理の対象となるイベントが変わります。&lt;/p>
&lt;p>本FLIPでは、それぞれの対象ソースに対して個別のTTLを設定出来るようになります。これにより要件に即したステート管理を行うことができるようになります。より粒度の細かなスコープの指定や、特定ユースケースにおけるステートストアの大幅な削減等が可能です。&lt;/p>
&lt;h3 id="flip-296-extend-watermark-related-features-for-sqlhttpscwikiapacheorgconfluencedisplayflinkflip-2963aextendwatermark-relatedfeaturesforsql">&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-296%3A&amp;#43;Extend&amp;#43;watermark-related&amp;#43;features&amp;#43;for&amp;#43;SQL" target="_blank" rel="noopener">FLIP-296: Extend watermark-related features for SQL&lt;/a>&lt;/h3>
&lt;p>ストリーム処理においてデータの整合性をいかに評価/制御することは極めて重要ですが、Flinkでは&lt;a href="https://www.youtube.com/watch?v=sdhwpUAjqaI" target="_blank" rel="noopener">Event TimeとWatermark&lt;/a>を利用する事により明示的にそれぞれのデータ処理ウィンドウを決定しています。&lt;/p>
&lt;p>Watermarkはその振る舞いを制御する重要な仕組みであり、&lt;a href="https://nightlies.apache.org/flink/flink-docs-release-1.18/docs/dev/datastream/overview/" target="_blank" rel="noopener">DataStream API&lt;/a>であればその&lt;a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/datastream/event-time/generating_watermarks/#watermark-alignment" target="_blank" rel="noopener">関連性の定義を制御(Watermark Alignment)&lt;/a>する事も出来ました。但しWatermarkの制御をする為にはローレベルなDataStream APIを利用する必要がありました。&lt;/p>
&lt;p>本FLIPでは、Flink SQLによってその制御を可能とします。具体的にはTable作成時やクエリにアノテーションを指定する事で：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TABLE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_actions&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">TIMESTAMP&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="mi">3&lt;/span>&lt;span class="p">),&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">WATERMARK&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">FOR&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">user_action_time&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">-&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INTERVAL&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;5&amp;#39;&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SECOND&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;scan.watermark.emit.strategy&amp;#39;&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;on-event&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>とWatermark生成インターバルを指定したり：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">select&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="p">...&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">from&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">source_table&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="cm">/*+ OPTIONS(&amp;#39;scan.watermark.emit.strategy&amp;#39;=&amp;#39;on-event&amp;#39;) */&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>SELECT時にWatermarkの出力タイプを指定できます。&lt;/p>
&lt;h3 id="バッチ処理速度改善">バッチ処理速度改善&lt;/h3>
&lt;p>&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-324%3A&amp;#43;Introduce&amp;#43;Runtime&amp;#43;Filter&amp;#43;for&amp;#43;Flink&amp;#43;Batch&amp;#43;Jobs" target="_blank" rel="noopener">FLIP-324: Introduce Runtime Filter for Flink Batch Jobs&lt;/a>&lt;/p>
&lt;p>&lt;a href="https://cwiki.apache.org/confluence/display/FLINK/FLIP-315&amp;#43;Support&amp;#43;Operator&amp;#43;Fusion&amp;#43;Codegen&amp;#43;for&amp;#43;Flink&amp;#43;SQL" target="_blank" rel="noopener">FLIP-315 Support Operator Fusion Codegen for Flink SQL&lt;/a>&lt;/p>
&lt;p>全バージョン(Flink 1.17)ではバッチ処理におけるスループットが大きく改善しました。その改善は本リリースでも継続して行われており、さらにそのパフォーマンスが向上しています 。今回のリリースにおける主要な改善は：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>FLIP-324&lt;/strong> &lt;a href="https://www.alibabacloud.com/blog/query-performance-optimization-runtime-filter_598126" target="_blank" rel="noopener">Runtime Filter&lt;/a>は集約処理の前段階で対象レコードを絞るアプローチで、これにより集約やJoinにかかるネットワーク通信や必要処理の大規模化を削減する事ができます。このFLIPでは、クエリのプラン中に関連処理の中からローカルでの集約可能な処理を特定し、Runtime Filterとして実行するようになりました。&lt;/li>
&lt;li>&lt;strong>FLIP-315&lt;/strong> 利用可能メモリの増加からCPUの処理能力にボトルネックが移る中、処理プロセスにおける無駄が全体スループットに大きな影響を与えています。幾つかの改善ポイントを評価した結果、ベクター化とコード生成方式のうちコード生成方式の&lt;a href="https://www.vldb.org/pvldb/vol4/p539-neumann.pdf" target="_blank" rel="noopener">Operator Fusion&lt;/a>の実装を導入しました。&lt;/li>
&lt;/ul>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="TPC-DS ベンチマーク結果" srcset="
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_63116ec5b524eace18e376eece97e72f.webp 400w,
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_f70905be7f3875dac26b79cb80bf7b1c.webp 760w,
/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/apache-flink-1.8/tpc-ds-benchmark-on-10t_huae35da9ece75da945f72ec115698b87c_979460_63116ec5b524eace18e376eece97e72f.webp"
width="760"
height="529"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
結果として&lt;a href="https://www.tpc.org/tpcds/" target="_blank" rel="noopener">TPC-DS&lt;/a>のベンチマーク結果がFlink 1.17と比べて13%、1.16とでは35%改善しました。&lt;/p>
&lt;h3 id="おわりに">おわりに&lt;/h3>
&lt;p>今回のご紹介はApache Flink1.18で導入された新機能や改善のごく一部ではありますが、ストリーム処理からバッチ、クラウドネイティブ化に向けた改善等、非常に多岐に渡る改善が含まれています。ksqlDBを知る身としてはFlinkの分散データ処理基盤としての重厚さを感じることにもなりました。是非&lt;a href="https://www.confluent.io/blog/announcing-apache-flink-1-18/" target="_blank" rel="noopener">オリジナルのブログ&lt;/a>もご覧ください。&lt;/p></description></item><item><title>Apache Kafka 3.6 アップデート</title><link>https://confluent-jp.github.io/community/blog/apache-kafka-3.6/</link><pubDate>Thu, 12 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/apache-kafka-3.6/</guid><description>&lt;p>Apache Kafkaの新バージョン3.6が公開されました。
ZookeeperモードからKRaftモードへの移行ではありますが、KRaftの強化だけでなく新たな機能も多く追加されております。詳細は&lt;a href="https://www.confluent.io/blog/introducing-apache-kafka-3-6/" target="_blank" rel="noopener">Confluentのアナウンスメント&lt;/a>と&lt;a href="https://www.youtube.com/watch?v=GW3625sEJyc" target="_blank" rel="noopener">YouTube&lt;/a>で説明されています。より詳細には&lt;a href="https://kafka.apache.org/blog#apache_kafka_360_release_announcement" target="_blank" rel="noopener">本家のリリースノート&lt;/a>には全ての関連kIPのリストが公開されています。&lt;/p>
&lt;p>本エントリでは、中でも重要なKIPについてご紹介します。&lt;/p>
&lt;h3 id="kip-405-kafka-tiered-storage-early-accesshttpscwikiapacheorgconfluencedisplaykafkakip-4053akafkatieredstorage">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A&amp;#43;Kafka&amp;#43;Tiered&amp;#43;Storage" target="_blank" rel="noopener">KIP-405: Kafka Tiered Storage (Early Access)&lt;/a>&lt;/h3>
&lt;p>&lt;a href="../kip405-why-tiered-storage-important/">こちらのブログエントリ&lt;/a>でもご紹介していたTiered Storageがアーリーアクセスとして利用可能となりました。単純に古いセグメントがオブジェクトストレージに退避されるだけでなく、既存のKafkaの設計やパフォーマンスへの影響を与えずに、Kafka自身がよりクラウドネイティブな姿へと変わる上で重要な機能です。&lt;/p>
&lt;p>今回3.6に登場したバージョンはまだ本番環境における利用を想定していない旨にご留意ください。機能の安定性だけでなく、JBODやCompacted Topic等機能制限もあります。既存Topicもバージョンを3.6にアップグレードすればTiered Storageに変更出来ますが、2.8.0より前に作成されたTopicには適用出来ない点もご注意下さい。アーリーアクセス版の制限はこちらの&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka&amp;#43;Tiered&amp;#43;Storage&amp;#43;Early&amp;#43;Access&amp;#43;Release&amp;#43;Notes" target="_blank" rel="noopener">Tiered Storage アーリーアクセスリリースノート&lt;/a>に記載されています。&lt;/p>
&lt;h3 id="kip-868-metadata-transactionshttpscwikiapacheorgconfluencedisplaykafkakip-868metadatatransactions">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-868&amp;#43;Metadata&amp;#43;Transactions" target="_blank" rel="noopener">KIP-868 Metadata Transactions&lt;/a>&lt;/h3>
&lt;p>&lt;a href="https://developer.confluent.io/learn/kraft/" target="_blank" rel="noopener">KRaft&lt;/a>の内部処理に関する改善です。KRaftではメタデータの更新時に関連レコード (例：Topic登録時の全Partitionのレコード) をアトミックに更新する仕様となっています。この為Controllerが処理中に障害に陥った場合でも部分的なメタデータの更新がなされないようになっています。&lt;/p>
&lt;p>一方このバッチサイズはKRaftのフェッチサイズが上限となっており、アップデート前ではこのサイズは8kbとなっています。この為非常に大きなメタデータの更新時にはフェッチ上限を超えるバッチが生成される可能性がありました。&lt;/p>
&lt;p>この改善で新たにメタデータにトランザクションの概念が導入され、トランザクションの開始/終了等のマーカーレコードを挿入するようになります。これによりKRaftのフェッチサイズを超える更新バッチサイズになった場合でも処理が可能となります。&lt;/p>
&lt;h3 id="kip-941-range-queries-to-accept-null-lower-and-upper-boundshttpscwikiapacheorgconfluencedisplaykafkakip-9413arangequeriestoacceptnulllowerandupperbounds">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-941%3A&amp;#43;Range&amp;#43;queries&amp;#43;to&amp;#43;accept&amp;#43;null&amp;#43;lower&amp;#43;and&amp;#43;upper&amp;#43;bounds" target="_blank" rel="noopener">KIP-941: Range queries to accept null lower and upper bounds&lt;/a>&lt;/h3>
&lt;p>Kafka StreamsにてマテリアライズしたState Storeに対してアクセスするには&lt;a href="https://docs.confluent.io/platform/current/streams/developer-guide/interactive-queries.html" target="_blank" rel="noopener">Interactive Query&lt;/a>を利用します。これにより、アクセスするデータが分散配置されているKafka Streamsのどのインスタンスにて保存されているのかを意識せずとも適切なデータを取得する事が出来ます。&lt;/p>
&lt;p>一方内部ではそれぞれのデータはKafka Streamsインスタンスに部分的に保存されている為、レンジ指定をして取得する場合には処理に大きな負荷がかかります。この為レンジ指定のクエリは制限が多く、アップデート前ではnullを指定した取得が出来ませんでした。この為：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="kd">private&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">String&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">ValueAndTimestamp&lt;/span>&lt;span class="o">&amp;lt;&lt;/span>&lt;span class="n">StockTransactionAggregation&lt;/span>&lt;span class="o">&amp;gt;&amp;gt;&lt;/span> &lt;span class="nf">createRangeQuery&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">String&lt;/span> &lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">String&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withNoBounds&lt;/span>&lt;span class="o">();&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(!&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withLowerBound&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="k">if&lt;/span> &lt;span class="o">(&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">)&lt;/span> &lt;span class="o">&amp;amp;&amp;amp;&lt;/span> &lt;span class="o">!&lt;/span>&lt;span class="n">isBlank&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">))&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withUpperBound&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span> &lt;span class="k">else&lt;/span> &lt;span class="o">{&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="k">return&lt;/span> &lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withRange&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> &lt;span class="o">}&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>このような回避的なコーディングが必要でした。&lt;/p>
&lt;p>今回レンジクエリにnull指定が出来るようになった事により：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-java" data-lang="java">&lt;span class="line">&lt;span class="cl">&lt;span class="n">RangeQuery&lt;/span>&lt;span class="o">.&lt;/span>&lt;span class="na">withRange&lt;/span>&lt;span class="o">(&lt;/span>&lt;span class="n">lower&lt;/span>&lt;span class="o">,&lt;/span> &lt;span class="n">upper&lt;/span>&lt;span class="o">);&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>これだけでnullを回避した実装が可能となります。&lt;/p>
&lt;h3 id="kip-875-first-class-offsets-support-in-kafka-connecthttpscwikiapacheorgconfluencedisplaykafkakip-8753afirst-classoffsetssupportinkafkaconnect">&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-875%3A&amp;#43;First-class&amp;#43;offsets&amp;#43;support&amp;#43;in&amp;#43;Kafka&amp;#43;Connect" target="_blank" rel="noopener">KIP-875: First-class offsets support in Kafka Connect&lt;/a>&lt;/h3>
&lt;p>Kafka Connectはその処理状況をKafkaネイティブにオフセットを管理する事により把握/管理しています。Connectorタスクが異常終了した場合でも、コミットされたオフセットを元に継続処理できるので、Connector自身には独自のステート管理のストレージ等が無くとも障害耐性を確保する事が出来ています。&lt;/p>
&lt;p>一方このオフセットはKafka上では参照できるもののKafka Connectとしては外部からアクセス出来るようにはなっていませんでした。何かしらの理由でオフセットを制御したい（特定レコードレンジを飛ばしたい、あるオフセットから再読み込みしたい、etc）場合にはハック的にKafka上のオフセット用Topicをいじる必要がありました。&lt;/p>
&lt;p>この改善によってKafka Connect API経由でオフセットの取得、更新、削除が可能となります。&lt;/p>
&lt;h3 id="おわりに">おわりに&lt;/h3>
&lt;p>Apache Kafka 3.6にはその他多くの改善が含まれています。今回のエントリではその一部しか触れていませんが、是非本家の&lt;a href="https://kafka.apache.org/blog#apache_kafka_360_release_announcement" target="_blank" rel="noopener">リリースノート&lt;/a>も併せてご参照ください。&lt;/p></description></item><item><title>Confluent Cloud Q3'23 Launch</title><link>https://confluent-jp.github.io/community/blog/confluent-cloud-23q3-launch/</link><pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/confluent-cloud-23q3-launch/</guid><description>&lt;p>Confluent Cloudはマネージドのプラットフォーム提供である為、様々な機能追加や改善は自動的に適用されます。これら改善はコアであるApache Kafkaのバージョンアップに限らず、またプラットフォーム製品であるConfluent Platformの機能にも限定されず、Confluent Cloud独自の機能も様々追加されています。&lt;/p>
&lt;p>Quarterly Launchは、そんなConfluent Cloudの新規機能を四半期毎にまとめてご紹介する&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/" target="_blank" rel="noopener">ブログ&lt;/a>と&lt;a href="https://www.youtube.com/watch?v=TS00diWO5Ak" target="_blank" rel="noopener">YouTube&lt;/a>エントリを指します。今回は&lt;a href="https://www.confluent.io/events/current/" target="_blank" rel="noopener">Current 2023&lt;/a>の開催を待った為だいぶ遅くなってしまいましたが、改めてそのハイライトをご紹介します。&lt;/p>
&lt;h3 id="apache-flink-on-confluent-cloud-open-previewhttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesflink-on-cloud">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#flink-on-cloud" target="_blank" rel="noopener">Apache Flink® on Confluent Cloud (Open Preview)&lt;/a>&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Flink on Confluent Cloud" srcset="
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1e22c54f68065fddec3fa2ce7b9ed953.webp 400w,
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_0bffbec27941e3f486699fef8632a7a8.webp 760w,
/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-cloud-23Q3-launch/flink-on-confluent-cloud_hu9a7990cce7b4fd1d129d17a5ccb1fd92_42892_1e22c54f68065fddec3fa2ce7b9ed953.webp"
width="600"
height="315"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
来年サービス提供開始予定のApache Flink on Confluent Cloudがオープンプレビューとして公開されました。提供インターフェースはFlink SQLのみ。現時点では&lt;a href="https://docs.confluent.io/cloud/current/flink/reference/op-supported-features-and-limitations.html#feature-limitations" target="_blank" rel="noopener">既知の機能制限&lt;/a>があり、この為本番利用には向きません。また現時点で&lt;a href="https://docs.confluent.io/cloud/current/flink/reference/op-supported-features-and-limitations.html#cloud-regions" target="_blank" rel="noopener">利用可能なクラウド/リージョン&lt;/a>は限定的ではあります。ただ、今日もうお試しいただけます。&lt;/p>
&lt;h3 id="enterprise-clustershttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesenterprise-clusters">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#enterprise-clusters" target="_blank" rel="noopener">Enterprise clusters&lt;/a>&lt;/h3>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Enterprise Clusters" srcset="
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2d533c3cc14f04ebba6beda84afd4b62.webp 400w,
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2108090c6b8fd26c6bbd9d7601804391.webp 760w,
/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-cloud-23Q3-launch/enterprise-clusters_hudcb5501b6a71e95e8db9e97022c961b4_156794_2d533c3cc14f04ebba6beda84afd4b62.webp"
width="760"
height="380"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Confluent Cloudのサーバーレスなクラスタ提供に新たにEnterpriseというオプションが追加されました。Basic、Standardといった既存のサーバーレスクラスタと異なり閉塞ネットワーク接続&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>を可能としており、併せて標準でSLA 99.99%、最大1GBpsのスループット(Ingress/Egress合算)をサポートしています。&lt;/p>
&lt;p>残念ながらローンチ時点ではサポートされているリージョンは限定的&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>ですが、以降継続して拡張予定となっています。&lt;/p>
&lt;h3 id="confluent-terraform-provider-updateshttpswwwconfluentioblogbuild-deploy-consume-data-pipelinesconfluent-terraform-provider">&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/#confluent-terraform-provider" target="_blank" rel="noopener">Confluent Terraform provider updates&lt;/a>&lt;/h3>
&lt;p>Confluent Terraform ProviderがHashiCorp Sentinel統合をサポートしました。これによりPolicy-as-Codeによる運用にConfluent Cloudを統合することが可能となります。&lt;/p>
&lt;p>また、新たにResource Importer機能を提供開始しました。これにより既存のConfluent CloudからTerraformの構成 (main.tf) ならびに状態 (terraform.tfstate) を逆生成する事が可能となります。&lt;/p>
&lt;h3 id="その他">その他&lt;/h3>
&lt;ul>
&lt;li>先日発表した&lt;a href="../confluent-platform-7.5-announcement/">Confluent Platform 7.5&lt;/a>でもご紹介した双方向Cluster LinkingがConfluent Cloudでもサポートされております。&lt;/li>
&lt;li>PrivateLink接続のConfluent Cloudクラスタ同士を&lt;a href="https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/private-networking.html" target="_blank" rel="noopener">直接Cluster Linkingで接続可能&lt;/a>することが可能となりました。&lt;/li>
&lt;/ul>
&lt;p>その他にも新たな機能が追加されておりますが、その全貌ならびに個々の詳細につきましては&lt;a href="https://www.confluent.io/blog/build-deploy-consume-data-pipelines/" target="_blank" rel="noopener">Confluentブログのアナウンスメント&lt;/a>をご覧ください。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>2023年9月ローンチ時点では、AWS PrivateLink経由の接続のみサポートしております。その他クラウドの接続形態は後日提供となります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>2023年9月ローンチ時点では、AWSのus-east-2(Ohio)、us-west-2(Oregon)、ap-southeast-1(Singapore)等8リージョンでのみ提供開始となっています。日本リージョンでの利用開始は現時点では未定です。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Confluent Platform 7.5リリース</title><link>https://confluent-jp.github.io/community/blog/confluent-platform-7.5-announcement/</link><pubDate>Thu, 31 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/confluent-platform-7.5-announcement/</guid><description>&lt;p>Confluent Platform 7.5がリリースされました。 &lt;a href="https://www.confluent.io/blog/introducing-confluent-platform-7-5/" target="_blank" rel="noopener">Confluent Blog&lt;/a> 内包されるApache Kafkaのバージョンは&lt;a href="https://www.youtube.com/watch?v=BVxDFL5iTx8" target="_blank" rel="noopener">3.5&lt;/a>となります。&lt;/p>
&lt;p>コアエンジンであるApache Kafkaのアップグレードだけでなく、エンタープライズ ソリューションとしてのConfluent Platformとしての機能追加や改善も含まれています。&lt;/p>
&lt;h3 id="sso-for-control-center-c3-for-confluent-platform">SSO for Control Center (C3) for Confluent Platform&lt;/h3>
&lt;p>Confluent Control CenterはConfluent Platformにおける管理ポータルとしての役割から、ごく一部のSREメンバーからのみアクセスされるという特殊なコンポーネントです。この為これまではアクセス制御のアプローチについては少し限定的でしたが、Broker等と同様OAuth2ベースの認証/認可の方法でアクセスする事が可能となりました。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="OIDC SSO to Conntrol Center" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_003085067e9660f4d2a75d91d83a2c4c.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_1ba41c13ea805b6d452f9ea265a8d6d8.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/sso_hu67db87b51405a1db647394d2cb092ba4_138944_003085067e9660f4d2a75d91d83a2c4c.webp"
width="760"
height="349"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="confluent-rest-proxy-produce-api-v3">Confluent REST Proxy Produce API v3&lt;/h3>
&lt;p>Confluent REST ProxyはKafka BrokerへのRESTベースのアクセスを可能としており、Confluent Platform/Cloudの双方で幅広く活用されています。一方、通常のKafkaプロトコルベースのアクセスに比べると制限もあり、これまでも段階的に改善がなされています。今回のProduce API v3では：&lt;/p>
&lt;ul>
&lt;li>カスタムヘッダーの追加 (トレーシングID、等)&lt;/li>
&lt;li>KeyとValueで異なるシリアライザの設定&lt;/li>
&lt;/ul>
&lt;p>が可能となります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="REST Proxy Produce API v3" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_83989a5797af7fe63286be6fe5bcda60.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_a2df8c6c08019d4a0d21e3f2b3a29d54.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/rest-proxy-produce-v3_hue84c4db39461140502f9bf10a6ad3c39_107527_83989a5797af7fe63286be6fe5bcda60.webp"
width="760"
height="333"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="bidirectional-cluster-linking">Bidirectional Cluster Linking&lt;/h3>
&lt;p>双方向のCluster Linkingの設定が可能となりました。これまでも一方向のリンクを2本貼れば実際のレプリケーションを双方向にすることは可能でした。Consuemr観点ではローカルのTopicとMirror Topicそれぞれ個別のTopicを同時にConsumeするモデルであり、それぞれへのOffset Commitを実行します。この際、Mirror TopicへのOffset CommitはソースとなるTopicには反映されないので、障害時には部分的なConsumer Offset情報しか連携されていない状況となります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="2 Unidirectional Cluster Linking" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_a7ec30fb3db45ac5c6af35290b9d3c04.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_034036236e3424798a84919e80a03245.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/uni-directional-cluster-linking-offset_huc479c2906f04f32b878c3e28e716f33e_62357_a7ec30fb3db45ac5c6af35290b9d3c04.webp"
width="760"
height="420"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
双方向のCluster Linkingは双方向へのリンクが1セットとして扱われる為、双方のクラスタでのOffset Commit情報も合わせて同期されます。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Bidirectional Cluster Linking" srcset="
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_83366575928d4eb4fc54ae197fca70b1.webp 400w,
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_bf7aca812d06fb55ea4bd64298312a51.webp 760w,
/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/confluent-platform-7.5-announcement/bidirectional-cluster-linking-cp-7-5_hu3a52438f693c3a662eb31fd1fd393da7_114667_83366575928d4eb4fc54ae197fca70b1.webp"
width="760"
height="339"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;h3 id="参考">参考&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://www.confluent.io/blog/introducing-confluent-platform-7-5/" target="_blank" rel="noopener">Introducing Confluent Platform 7.5 (Confluent Blog)&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/7.5/release-notes/index.html" target="_blank" rel="noopener">Confluent Platform 7.5 Release Notes&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/current/kafka-rest/index.html" target="_blank" rel="noopener">REST Proxy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/platform/7.5/control-center/security/sso/overview.html#sso-for-c3" target="_blank" rel="noopener">Single Sign-On (SSO) for Confluent Control Center&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.confluent.io/cloud/current/multi-cloud/cluster-linking/cluster-links-cc.html#bidirectional-mode" target="_blank" rel="noopener">Cluster Linking - Bidirectional Mode&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>新コース - Event Modeling</title><link>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</guid><description>&lt;p>&lt;a href="developer.confluent.io">developer.confluent.io&lt;/a>にてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。&lt;/p>
&lt;p>UXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto Brandoliniによる&lt;a href="https://www.eventstorming.com/" target="_blank" rel="noopener">Event Sourcing&lt;/a>と近い思想によるデザイン手法の一つです。&lt;/p>
&lt;p>マイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。&lt;/p></description></item></channel></rss>