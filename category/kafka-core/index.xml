<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Kafka Core | Confluent Japan Community</title><link>https://confluent-jp.github.io/community/category/kafka-core/</link><atom:link href="https://confluent-jp.github.io/community/category/kafka-core/index.xml" rel="self" type="application/rss+xml"/><description>Kafka Core</description><generator>Wowchemy (https://wowchemy.com)</generator><language>ja-jp</language><lastBuildDate>Sun, 06 Aug 2023 00:00:00 +0000</lastBuildDate><image><url>https://confluent-jp.github.io/community/media/icon_hubade5daff97c80353b10ab16b141ee15_5385_512x512_fill_lanczos_center_3.png</url><title>Kafka Core</title><link>https://confluent-jp.github.io/community/category/kafka-core/</link></image><item><title>Tiered Storageは何故そんなに重要なのか？</title><link>https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/</link><pubDate>Sun, 06 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/</guid><description>&lt;h2 id="tiered-storageとは">Tiered Storageとは&lt;/h2>
&lt;p>今年の後半にリリースが予定されている&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release&amp;#43;Plan&amp;#43;3.6.0" target="_blank" rel="noopener">Apache Kafka 3.6&lt;/a>には、Tiered Storageと呼ばれるKafkaコミュニティが待ち望んだ新機能が含まれる予定です。この機能は&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A&amp;#43;Kafka&amp;#43;Tiered&amp;#43;Storage" target="_blank" rel="noopener">KIP-405&lt;/a>として何年も前に登録されたKIPであり、長い期間をかけてようやくリリース目処が経ちました。&lt;/p>
&lt;p>これまでKafkaのデータは常にBrokerのストレージに格納されていましたが、これを二層化して古いセグメントを自動的に退避するという機能です。Kafkaに格納されたイベントをオブジェクトストレージに退避するというプラクティスは一般的であり、これまではKafka Connectコネクタを使って自分で退避させるアプローチを取っていました。これをKafkaネイティブな機能として提供する、その役割をKafka Brokerが行うというものです。クライアントからはこのオペレーションは隠蔽化されており、新しいイベントも古いイベントも同じアプローチでアクセスする事が出来ます。&lt;/p>
&lt;h2 id="tiered-storageの動き---図解">Tiered Storageの動き - 図解&lt;/h2>
&lt;p>これまで通り、クライアントから送られたイベントはkafka Brokerのストレージにセグメント単位で保存されます。セグメントはログファイルであり、ランダムアクセスではなくアペンドでしかデータを足せない為、最も新しいセグメント (Active Segmentと呼ばれます) 以外のファイルは不可変 (Immutable) です。&lt;/p>
&lt;p>Tiered Storageはこのうち古いセグメントを自動的にオブジェクトストレージに退避します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-1" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_307dc89e1a68d87bc27b49159af2e082.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_0c117106ee083960e7059ed25e9ffecd.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-1_hu2024f9fb0e264eb23f1f5629f1888bef_131836_307dc89e1a68d87bc27b49159af2e082.webp"
width="760"
height="290"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>中では新しくRemoteLogManagerと呼ばれるプロセスが、これまでのLogManagerに近い役割を果たしつつリモートストレージにコピーし、合わせてリモートストレージのインデックス状態のキャッシュを保持します。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-2" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_ed30da300d0b9b691d188362efbc7e4f.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_d4ef38034777db186c40e196ccf45f74.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-2_hu86fab6f33ca7c672a829674acdc1ce76_168812_ed30da300d0b9b691d188362efbc7e4f.webp"
width="760"
height="277"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>上にあるように、Broker側の保全期間 (Retention Period) を超過しセグメントが削除された後も、リモートストレージにはそのコピーが残ります。ストレージの動きはこれだけで、リモートからローカルにセグメントが戻ってくる様な事はありません。これまでのLog Managerの役割もそのままで、ローカルのログは今まで通り管理されます。&lt;/p>
&lt;p>ほとんどのユースケースでは、クライアントは最新のセグメントに集中してアクセスします。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-3" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_13555c5a91b8f7799d7e3a3c89dd36dd.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_38b70ca4b82c8226d2b8975dc87ab4fb.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-3_hufec61c00674d614f5445ee3899763482_184498_13555c5a91b8f7799d7e3a3c89dd36dd.webp"
width="760"
height="277"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
書き込みは当然最新であるActive Segmentにしか発生しませんが、読み込みも多少のラグはありながらもほぼ最新に近いセグメントへのアクセスとなります。このアクセスはこれまでと何も変わらず、今まで通りBrokerがディスクI/O経由でデータを取得しクライアントに帰します。&lt;/p>
&lt;p>違いは、クライアントが古いセグメントにあるオフセットを指定して読み込みをリクエストした場合です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Storage phase-4" srcset="
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_2a2234b74cfe0781c6e5b4a49c707312.webp 400w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_0641f49b3b2042ca8b889354eab7f534.webp 760w,
/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kip405-why-tiered-storage-important/storage-phase-4_hu82aa3a1a927fb65a627ff1f8047c21f4_204292_2a2234b74cfe0781c6e5b4a49c707312.webp"
width="760"
height="288"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;/p>
&lt;p>既にBrokerのローカルストレージにはセグメントは存在しませんが、リモートストレージに存在する限りBrokerはデータを取得しクライアントに返すことが出来ます。&lt;/p>
&lt;h2 id="メリット-1---拡張性-scalability">メリット 1 - 拡張性 (Scalability)&lt;/h2>
&lt;p>Kafkaは拡張性に極めて優れたストリーミングプラットフォームであり、原則Brokerノードを追加することにより水平スケールする事ができます。一方、拡張には限界があります。一般的に大規模Kafkaクラスタにおけるボトルネックはネットワーク帯域で、次にストレージと言われています。これらを充分確保出来続ける限りKafkaクラスタは相当規模まで拡張出来ます。Tiered Storageによってストレージ容量の削減とより高度なコントロールが可能になります。&lt;/p>
&lt;p>KafkaにとってそれぞれのTopicの保全期間 (Retention Period) と書き込みスループットは基本的にはバランスゲームです - 高書き込みスループットの場合はストレージ容量の増加を加味してより短い保全期間を指定する必要があります。保全期間のデフォルトでは1週間、通常運用では1日という場合も多くありますが、高負荷のクラスタでは数時間程度に留める事も多くあります。&lt;/p>
&lt;p>kafkaは内部でデータのレプリケーションを行なっています。Replication Factorと呼ばれるこの設定のデフォルトは&lt;code>3&lt;/code>であり、稀に金融やストレッチクラスタ (複数のサイトに跨がる大きなクラスタ) では&lt;code>4&lt;/code>を指定する場合もありますが、ほとんどデフォルトのままではないかと思います。いずれにせよ、その指定分だけデータはレプリケートされるので、必要ディスク容量は増えます。&lt;/p>
&lt;p>例えば100MBpsで書き込みがなされる場合、レプリケーションも考慮するとクラスタ内のネットワーク帯域には300MBps、当然ストレージにも300MBpsのスピードで消費します。保全期間を1日とした場合、100 * 3600 * 3 = 1,080,000MB ≒ 1TBのストレージ容量が必要となります。書き込みスループットが倍になればストレージも倍、当然保全期間を倍にしてもストレージは倍必要になります。&lt;/p>
&lt;p>ストレージがボトルネックになった場合、ディスクを足せば解消しますが、それも限界を超えるとBroker自体を追加する必要が出てきます。Tiered Storageを導入すると、Brokerが必要とするストレージの絶対量を制限できます。同一ハード構成におけるキャパシティを上げ、将来的な拡張性も高く出来ます。&lt;/p>
&lt;h2 id="メリット-2---障害耐性-resiliency">メリット 2 - 障害耐性 (Resiliency)&lt;/h2>
&lt;p>ストレージを分離する事によって障害耐性が上がるというのはピンと来ないかも知れませんが、Tiered Stoargeによる効果と期待は障害耐性の向上にも集まっています。&lt;/p>
&lt;p>Kafkaが何事もなく稼働している限り、またデータが適切にパーティションされている限り、Kafkaクラスタは均一にデータを分散配置し管理出来ます。しかしBrokerのシャットダウンと復帰は必ず発生します。時としてハードやソフトの障害によって、他ではBroker/JVM/Guest OS/Host OS/Host Hardwareのアップグレードによって、クラスタ構成は短期/長期的にその構成が変わります - Kafkaは絶えずメンバーシップを変えつつ稼働し続ける分散システムであり、構成が変わる前提の上で成立している技術です。&lt;/p>
&lt;p>Brokerがクラスタメンバーから外れると、それまでそのBrokerで保全していたデータは必ず何かしらの方法で他のBrokerに再配置されなければデータの保全性が保てません。この為クラスタメンバーシップの変更は、大規模なメタデータの更新と、データの移動を意味します。&lt;/p>
&lt;p>Tiered Storageによって管理/移動対象となるセグメントの物理的な数が減れば、その分クラスタ内で移動するデータ量が減少し、また大量メタデータ更新に伴う二次災害の危険性も減少し、結果としてより安全に、より短い期間にクラスタが正常状態に復帰します。Kafkaクラスタ自体が軽量になればなるだけ、例えばコンテナの様により頻繁に刷新されるランタイム上でKafkaを運用する場合にも大きなメリットとなります。&lt;/p>
&lt;h2 id="メリット-3---リソースの有効活用-resource-utilization">メリット 3 - リソースの有効活用 (Resource Utilization)&lt;/h2>
&lt;p>Kafkaとは基本的にディスクI/Oへの負荷が高いプラットフォームです。これは書き込み/読み込みの発生頻度が高く、またディスクI/Oの有効利用が今回の設計思想に織り込まれています。併せて、Kafkaは原則マルチテナントプラットフォームであり、様々なワークロードが共存し易い (各々のワークロードの影響を受けにくい) ストリーミング基盤です。しかしながらKafkaにも物理的な制約は存在し、ワークロードのニーズ的にはクラスタ自体を分ける事も実際には多くあります。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;p>Tiered Storageへのアクセスは、Kafkaでは珍しくディスクI/OではなくネットワークI/Oへの比重が高い処理となります。例えば長期間実行するバッチ処理 (古いデータなのでTiered Storage経由) と、超低レイテンシな処理が求められるオンライン処理 (新しいデータなのでBrokerから) とではKafkaかかるリソース負荷が全く異なります。これら特性を上手く利用すれば、オンライン処理を実行しながら低負荷でバッチ処理を同一クラスタ内で扱う事も出来ます。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>Tiered StorageはApache Pulserの様なコンピュートとストレージを完全に切り離す目的で導入される訳ではありません。Kafkaはある意味意図的に原始的な設計をしている点が長所であり、時として短所となり得る技術です。Tiered StoargeはKafkaが本来持つ高スループットかつ低遅延な処理能力を殺す事なく、短所であるディスク容量やディスクI/Oというボトルネックを軽減させ得る可能性を持った非常に有望な機能です。併せて、よりクラウドネイティブな環境で動く機会の増えたKafkaにとって、その新しい環境により適合性の高い機能であるとも言えます。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>例えば長期実行されるバッチ処理が継続してKafkaにアクセスしている状態で、非常にレイテンシ要件の高いオンライン処理が同居する様な場合です。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>当然、充分なネットワーク帯域が確保されている場合には、という条件は付きます。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Kafka Acks再入門</title><link>https://confluent-jp.github.io/community/blog/kafka-acks-explained/</link><pubDate>Tue, 01 Aug 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kafka-acks-explained/</guid><description>&lt;blockquote>
&lt;p>このブログエントリはKafkaコミッタである Stanislav Kozlovski(&lt;a href="https://https://twitter.com/BdKozlovski" target="_blank" rel="noopener">𝕏&lt;/a>|&lt;a href="https://www.linkedin.com/in/stanislavkozlovski/" target="_blank" rel="noopener">Ln&lt;/a>) のサイトで2022/11/06に公開された&lt;a href="https://www.linkedin.com/pulse/kafka-acks-explained-stanislav-kozlovski/" target="_blank" rel="noopener">Kafka Acks Explained&lt;/a>の日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。&lt;/p>
&lt;/blockquote>
&lt;p>Kafkaに関する仕事を始めて4年になりますが、経験上未だに2つの設定について広く誤解されていると感じる事があります。それは&lt;code>acks&lt;/code>と&lt;code>min.insync.replicas&lt;/code>であり、さらにはこの2つの設定がどう影響し合うかについてです。このエントリはこの非常に重要な2つの誤解を解き、適切に理解してもらう事を目的としています。&lt;/p>
&lt;h2 id="replication">Replication&lt;/h2>
&lt;p>この2つの設定を理解するためにはまずKafka Replicationプロトコルについて少しおさらいする必要があります。&lt;/p>
&lt;p>このブログの読者の皆さんはある程度Kafkaについてご存知だと想定しています - もし自信がない場合はぜひ&lt;a href="https://medium.com/hackernoon/thorough-introduction-to-apache-kafka-6fbf2989bbc1" target="_blank" rel="noopener">Thorough Introduction to Apache Kafka&lt;/a>もご参照ください。&lt;/p>
&lt;p>各Partitionには1つのLeader Broker(1)と複数のFollower Broker(N)がアサインされます。この複製の数は&lt;code>replication.factor&lt;/code>で設定する事ができ(1+N)つまり総数を表します。つまりこの設定では「対象となるPartitionに対してクラスタ上で何個の複製が出来るか」を指定します。&lt;/p>
&lt;p>デフォルトであり通常推奨する設定値は&lt;code>3&lt;/code>です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="Replication Factor" srcset="
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_0d1ca0052156cf2b9740e68dcdd4c65a.webp 400w,
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_f54bf205681a70abfa295c3277922d09.webp 760w,
/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/replication-factor_hu30e3aabf839789c5bf75a3316f94b6c4_21497_0d1ca0052156cf2b9740e68dcdd4c65a.webp"
width="760"
height="203"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
ProducerクライアントはLeader Brokerにのみ書き込みに行きます - つまりFollower Brokerへのレプリケーションは非同期に行われます。ここで分散システムとして考慮しないといけないのは、何かしらの方法で「これらレプリケーションされる処理がどのようにLeaderに追従すべきか」を指定する方法です。具体的には「Leaderに書き込まれた更新がFollowerにも反映されているか否か」です。&lt;/p>
&lt;h2 id="in-sync-replicas">In-Sync Replicas&lt;/h2>
&lt;p>in-sync replica(ISR)は対象Partitionの最新状態と同期が取れているBrokerを指します。当然Leaderは常にISRとなり、Followerの場合はLeaderの更新に追い付き同期が取れた状態のもののみISRとなります。仮にFollowerがLeaderに追従できなくなった場合、そのFollowerはISRではなくなります。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="In-Sync Replicas" srcset="
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_fce72e1100ff5fc9564552f1283799b8.webp 400w,
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_53b76570ba3a381743ccf6f03feacf22.webp 760w,
/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/in-sync-replicas_hu976122a385339436764fa5a7b293f0d1_30553_fce72e1100ff5fc9564552f1283799b8.webp"
width="760"
height="247"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上の図ではBroker 3は同期されていないのでISRではない、つまりout-of-syncとなります。&lt;/p>
&lt;p>ちなみに、厳密にはISRか否かという判断はもう少し複雑で、ここで説明されているようにすんなり「このFollowerは最新の状態か」と判断出来る訳ではありません。ただ厳密な話をし始めるとこのエントリの主旨から外れるので、ここでは上の図にある赤いBrokerは同期が取れていないと、見たまま捉えてください。&lt;/p>
&lt;h2 id="acks">Acks&lt;/h2>
&lt;p>Acksはクライアント (Producer) 側の設定で、「どこまでFollowを含めて書き込みの確認が取れてからクライアントに返答するか」を指定するものです。有効な値は&lt;code>0&lt;/code>、&lt;code>1&lt;/code>、そして&lt;code>all&lt;/code>の3つです。&lt;/p>
&lt;h3 id="acks0">acks=0&lt;/h3>
&lt;p>&lt;code>0&lt;/code>が設定された場合、クライアントはBrokerまで到達したかの確認さえ行いません - メッセージがKafka Brokerに対して送られたタイミングでackを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=0" srcset="
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_3c44fb1f740910333022481170b7baae.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_882b78cb72dd80307fdacbd72dcd1221.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-0_hu0550e2dc4172b509b74ba25178351429_24893_3c44fb1f740910333022481170b7baae.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
ackと呼びますがBrokerからの返答さえ待ちません。送れたらOKです。&lt;/p>
&lt;h3 id="acks1">acks=1&lt;/h3>
&lt;p>&lt;code>1&lt;/code>が設定された場合、クライアント (Producer) はLeaderにまでメッセージが到達した時点で書き込みの完了と判断します。Leader Brokerはメッセージを受け取った時点でレスポンスを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=0" srcset="
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_3111a28552f0a098342a58fa79fec9da.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_e9144a72afa66fafd760c8736f931a9e.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-1_hufbb81d13ec3e2d13fe50ef9ee9b16565_25528_3111a28552f0a098342a58fa79fec9da.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
クライアントはレスポンスが返ってくるのを待ちます。Leaderからの返答が到着した時点で完了と判断しackとします。Leaderは受け取り次第レスポンスを返すので、Followerへのレプリケーションはレスポンスとは非同期に処理されます。&lt;/p>
&lt;h3 id="acksall">acks=all&lt;/h3>
&lt;p>&lt;code>all&lt;/code>と設定された場合、クライアントは全てのISRにメッセージが到達した時点で書き込みの完了と判断します。この際Leader BrokerがKafka側の書き込み判定を行なっており、全てのISRへのメッセージ到達の上クライアントにレスポンスを返します。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all incomplete" srcset="
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_d7dcaf69c8cd6d40de1b4c5fa07bce88.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上の図の状態ではBroker 3はまだメッセージを受け取っていません。この為Leaderはレスポンスを返しません。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all completed" srcset="
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_516f5fcece0585c45a349a2c530fc785.webp 400w,
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_95c6e832fba07495adfbb75a5b8d0104.webp 760w,
/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/acs-all-completed_hu40e2b48bcec98f93fca3863ace2b1192_26398_516f5fcece0585c45a349a2c530fc785.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
全てのISRに渡って初めてレスポンスが返されます。&lt;/p>
&lt;h3 id="acksの機能性">acksの機能性&lt;/h3>
&lt;p>この通りacksはパフォーマンスとデータ欠損耐性のバランスを決める非常に有益な設定です。データ保全を優先するのであれば&lt;code>acks=all&lt;/code>の設定が適切です。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> 一方レイテンシやスループットに関する要件が極めて高い場合には&lt;code>0&lt;/code>に設定すれば最も効率が良くなりますが、同時にメッセージロスの可能性は高まります。&lt;/p>
&lt;h2 id="minimum-in-sync-replicas">Minimum In-Sync Replicas&lt;/h2>
&lt;p>&lt;code>acks=all&lt;/code>の設定に関して、もう一つ重要な要素があります。&lt;/p>
&lt;p>例えばLeaderが全てのISRへの書き込み完了した上でレスポンスを返すとして、LeaderのみがISRだった場合、結果として&lt;code>acks=1&lt;/code>と振る舞いは同じとなるのでしょうか？&lt;/p>
&lt;p>ここで&lt;code>min.insync.replicas&lt;/code>の設定が重要になります。&lt;/p>
&lt;p>&lt;code>min.insync.replicas&lt;/code>というBroker側の設定は、&lt;code>acks=all&lt;/code>の際に「最低いくつのISRとなっているか (Leaderを含めて幾つのレプリカが最新状態か) を指定するものです。つまりLeaderは、&lt;code>acks=all&lt;/code>のリクエストに対して指定されたISRに満たないまでは返答せず、またそれが何かしらの理由で達成できない場合にはエラーを返します。データ保全観点でのゲートキーバーの様な役割を果たします。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all and ISR=2" srcset="
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_c68b5a3947a2b0f20bf8ea75ce7a2101.webp 400w,
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_249c85c3d6a5b99c5af7bf892f6e56ab.webp 760w,
/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/acks-all-isr-2_hub8eff15aeeef74355ae44643b51e51f5_28460_c68b5a3947a2b0f20bf8ea75ce7a2101.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上記の状態だとBroker 3は同期されていない状態です。しかしながら&lt;code>min.insync.replicas=2&lt;/code>となっている場合には条件を満たす為この時点でレスポンスが返されます。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all and ISR below min.insync.replicas" srcset="
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_49566929a4d489d75f27fe22a6bcec7c.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_924c01716b6e3c2021b34f2f98f42045.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all-error_hu2fd9c2a4aa3141a871510012387c44d9_34884_49566929a4d489d75f27fe22a6bcec7c.webp"
width="760"
height="192"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
Broker 2と3が同期されていない状態です。この場合指定された&lt;code>min.insync.replicas&lt;/code>を下回るためLeaderからはエラーレスポンスが返る、つまり書き込みは失敗します。一方同じ状況であっても&lt;code>acks&lt;/code>の設定が&lt;code>0&lt;/code>もしくは&lt;code>1&lt;/code>の場合には正常なレスポンスが返されます。&lt;/p>
&lt;h3 id="注意点">注意点&lt;/h3>
&lt;p>一般的に&lt;code>min.insync.replicas&lt;/code>は「Leaderがクライアントに返答する際に、どれだけレプリケーションが完了しているかを指定する」と解釈されていますが、これは誤りです。正確には「リクエストを処理する為に最低いくつのレプリカが存在するか」を指定する設定です。
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="acks=all incomplete" srcset="
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp 400w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_d7dcaf69c8cd6d40de1b4c5fa07bce88.webp 760w,
/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/ack-all_hubb3072fc779981dffa72d32676766abf_24119_c0ae40d167ec22fd1a697d124a14ea8d.webp"
width="760"
height="201"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
上記の場合、Broker 1から3までが全て同期状態です。この時に新たなリクエスト (ここではメッセージ&lt;code>6&lt;/code>) を受け取った場合、Broker 2への同期が完了してもレスポンスは返しません。この場合、処理時にISRとなっているBroker 3への同期が完了して初めてレスポンスが返されます。&lt;/p>
&lt;h2 id="まとめ">まとめ&lt;/h2>
&lt;p>図で説明したことによって理解が深まったのではないかと思います。&lt;/p>
&lt;p>おさらいすると、&lt;code>acks&lt;/code>と&lt;code>min.insync.replicas&lt;/code>はKafkaへの書き込みにおける欠損体制を指定する事ができます。&lt;/p>
&lt;ul>
&lt;li>&lt;code>acks=0&lt;/code> - 書き込みはクライアントがLeaderにメッセージを送った時点で成功とみなします。Leaderからのレスポンスを待つことはしません。&lt;/li>
&lt;li>&lt;code>acks=1&lt;/code> - 書き込みはLeaderへの書き込みが完了した時点で成功とみなします。&lt;/li>
&lt;li>&lt;code>acks=all&lt;/code> - 書き込みはISR全てへの書き込みが完了した時点で成功とみなします。ISRが&lt;code>min.insync.replicas&lt;/code>を下回る場合には処理されません。&lt;/li>
&lt;/ul>
&lt;h3 id="その他情報">その他情報&lt;/h3>
&lt;p>Kafkaは複雑な分散システムであり、学ばなければいけない事が多いのも事実です。Kafkaの他の重要な要素については以下も参考にしてください。&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.confluent.io/blog/apache-kafka-data-access-semantics-consumers-and-membership/" target="_blank" rel="noopener">Kafka consumer data-access semantics&lt;/a> - クライアント (Consumer) における欠損耐性、可用性、データ整合性の確保に関わる詳細。&lt;/li>
&lt;li>&lt;a href="https://medium.com/@stanislavkozlovski/apache-kafkas-distributed-system-firefighter-the-controller-broker-1afca1eae302" target="_blank" rel="noopener">Kafka controller&lt;/a> - Broker間の連携がどの様になされるのかの詳細。特にレプリカが非同期 (Out-of-Sync) となるのはどういう条件下かについて説明しています。&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/blog/configure-kafka-to-minimize-latency/" target="_blank" rel="noopener">“99th Percentile Latency at Scale with Apache Kafka&lt;/a> - Kafkaのパフォーマンスに関するConfluent Blogエントリ。&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/resources/kafka-summit-san-francisco-2019/" target="_blank" rel="noopener">Kafka Summit SF 2019 videos&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.confluent.io/blog/" target="_blank" rel="noopener">Confluent blog&lt;/a> - Kafkaに関する様々なトピックを網羅。&lt;/li>
&lt;li>&lt;a href="https://kafka.apache.org/documentation/" target="_blank" rel="noopener">Kafka documentation&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Kafkaは継続的かつアクティブに開発されていますが、機能追加や改善は活発なコミュニティにより支えられています。開発の最前線で何が起こっているか興味がある場合はぜひ&lt;a href="https://kafka.apache.org/contact" target="_blank" rel="noopener">メーリングリスト&lt;/a> に参加してください。&lt;/p>
&lt;p>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="2 Minutes Streaming" srcset="
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp 400w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_9b81ef5fad55639d712bb44153e40131.webp 760w,
/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/kafka-acks-explained/two-minites-streaming_hue3ec6dcfa348a79b62ae3c8b92373579_136684_69bf0270813a154536ca6866d0eebe28.webp"
width="760"
height="399"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
このエントリの著者である&lt;a href="../../authors/stanislav/">Stanislav Kozlovski&lt;/a> は&lt;a href="https://2minutestreaming.com/" target="_blank" rel="noopener">2 Minute Streaming&lt;/a>というKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>(訳者注)ほとんどのユースケースでは&lt;code>acks=all&lt;/code>が適切であり、Kafkaのデフォルトでもあります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Streaming Audio - Kafkaに本当にあった(まだある)ヤバいバグ5選</title><link>https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/</link><pubDate>Sat, 29 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=yFlvWRwRTT8&amp;amp;list=PLa7VYi0yPIH1B0i7mhzVi78TIkKSd-0vE" target="_blank" rel="noopener">Streaming Audio&lt;/a>はConfluentがPodcast&amp;amp;YouTubeシリーズとして提供しています。毎回ゲストを迎え様々なトピックについてフリーにディスカッションするポッドキャストで、Kafka初期開発メンバーのJun RaoやKRaftの開発メンバー、Kafkaのリアルユーザー等様々なゲストスピーカーが参加します。中でも「アナネキ」ことAnna McDonald (Technical Voice of CUstomer @Confluent)登場回は毎回必見で、いつも何か新しい発見があります。&lt;/p>
&lt;p>今回はその彼女の登場回の中でも最も最近の回のご紹介です：お題は「Kafkaに本当にあったヤバいバグ5選&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>」です。(オリジナルの公開は2022/12/21) このトークで紹介されたJIRAバグの一覧を用意しました。結構最近になってようやく入ったものや、まだ直っていないものもあります。Kafkaのバージョンはなるべく追従する事を強くお勧めしていますが、ここにあるのは全体の一部で、なかなかに怖いバグへの修正も入っています。&lt;/p>
&lt;p>あなたのKafkaクラスタはほんとに大丈夫です？&lt;/p>
&lt;h4 id="kafka-10888-sticky-partition-leads-to-uneven-product-msg-resulting-in-abnormal-delays-in-some-partitionshttpsissuesapacheorgjirabrowsekafka-10888">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-10888" target="_blank" rel="noopener">KAFKA-10888: Sticky partition leads to uneven product msg, resulting in abnormal delays in some partitions&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Sticky Partitionerを使用時、Partition間の処理数に大きな偏りが出る様な状況となり特定のPartitionのスループットが極端に下がる事がある: 場合によってはリカバリ不能なほどProducer側のバッチが肥大化する。&lt;/p>
&lt;h4 id="kafka-9648-add-configuration-to-adjust-listen-backlog-size-for-acceptorhttpsissuesapacheorgjirabrowsekafka-9648">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-9648" target="_blank" rel="noopener">KAFKA-9648: Add configuration to adjust listen backlog size for Acceptor&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.2.0)&lt;/p>
&lt;/blockquote>
&lt;p>OSがLinuxの場合に発生。ローリングアップグレード等の際、BrokerからPartition Leaderが他のBrokerに移る、もしくは移ったのちに元のBrokerに戻る (Preferred Leader Election) が発生。この際Partitionに関するメタデータ更新が行われる為これらPartitionを参照するクライアントから一斉に再接続のリクエストが送られる。状況によってはLinuxのSYN cookieの機能が動きTCPバッファーが制限されスループットが大幅に低下する。これは再接続しない限り復旧しない。&lt;/p>
&lt;h4 id="kafka-12686-race-condition-in-alterisr-response-handlinghttpsissuesapacheorgjirabrowsekafka-12686">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-12686" target="_blank" rel="noopener">KAFKA-12686: Race condition in AlterIsr response handling&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Partition.scala内の処理において、AlterIsrResponseとLeaderAndIsrRequestのレースコンディションが起因。クラスタサイズが小さくPartition数が多い場合、Brokerノードの変更時に大量のPartition変更が発生する。この際AlterIsrManagerがペンディング状態のリクエストをクリアしてしまう為、AlterIsrResponseが戻ってきた際に処理中 (in Flight) であるのに処理タスク (Pending) が無いという矛盾状態が発生する。&lt;/p>
&lt;h4 id="kafka-12964-corrupt-segment-recovery-can-delete-new-producer-state-snapshotshttpsissuesapacheorgjirabrowsekafka-12964">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-12964" target="_blank" rel="noopener">KAFKA-12964: Corrupt segment recovery can delete new producer state snapshots&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.0.0)&lt;/p>
&lt;/blockquote>
&lt;p>Brokerの停止時、猶予時間内に終了しない場合には Unclearn Shutdownと判断される。この際Broker復帰時に残っていたセグメントは不要と判断され非同期で削除が実行される。この削除が完了する前に同じオフセットのセグメントが書き込まれる状態となると、新しいProducer Stateスナップショットが誤って削除される事がある。&lt;/p>
&lt;h4 id="kafka-14334-delayedfetch-purgatory-not-completed-when-appending-as-followerhttpsissuesapacheorgjirabrowsekafka-14334">&lt;a href="https://issues.apache.org/jira/browse/KAFKA-14334" target="_blank" rel="noopener">KAFKA-14334: DelayedFetch purgatory not completed when appending as follower&lt;/a>&lt;/h4>
&lt;blockquote>
&lt;p>Status: Resolved (3.4.0, 3.3.2)&lt;/p>
&lt;/blockquote>
&lt;p>ConsumerがPulgatoryからフェッチするケースにおいて、通常通りPartitionリーダーからフェッチする場合には正しくフェッチの完了が認識される。しかしConsumerがフォローワーがフェッチする設定としている(&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A&amp;#43;Allow&amp;#43;consumers&amp;#43;to&amp;#43;fetch&amp;#43;from&amp;#43;closest&amp;#43;replica" target="_blank" rel="noopener">KIP-932&lt;/a>)場合、フォローワーのPartitionはPulgatoryに存在しない為フェッチ出来ずタイムアウトする。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>オリジナルは6選であり、ここではそのうち&lt;a href="https://issues.apache.org/jira/browse/KAFKA-9211" target="_blank" rel="noopener">KAFKA-9211: Kafka upgrade 2.3.0 may cause tcp delay ack(Congestion Control)&lt;/a>も含んでいますが、トークの中ではKafka-9646の中で合わせて語られているので割愛しました。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Exactly Onceとmax.in.flightについて</title><link>https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/</link><pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。&lt;/p>
&lt;p>ただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。&lt;/p>
&lt;h2 id="exactly-once-semantics">Exactly Once Semantics&lt;/h2>
&lt;p>Kafka初期において最も注目を集めたエンハンスメントの一つに&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-98&amp;#43;-&amp;#43;Exactly&amp;#43;Once&amp;#43;Delivery&amp;#43;and&amp;#43;Transactional&amp;#43;Messaging" target="_blank" rel="noopener">KIP-98 - Exactly Once Delivery and Transactional Messaging&lt;/a> があります。「メッセージ基盤においてExactly Onceは不可能」という&lt;a href="https://ja.wikipedia.org/wiki/%E3%83%93%E3%82%B6%E3%83%B3%E3%83%81%E3%83%B3%E5%B0%86%E8%BB%8D%E5%95%8F%E9%A1%8C" target="_blank" rel="noopener">ビザンチン将軍問題&lt;/a>観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして&lt;a href="https://www.confluent.io/blog/exactly-once-semantics-are-possible-heres-how-apache-kafka-does-it/" target="_blank" rel="noopener">具体的な説明&lt;/a>もたくさんなされています。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;p>実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りは&lt;code>enable.idempotency=true&lt;/code>と設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-bash" data-lang="bash">&lt;span class="line">&lt;span class="cl">&lt;span class="nv">ack&lt;/span>&lt;span class="o">=&lt;/span>all
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">retries &amp;gt; &lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">max.inflight.requests.per.connection&lt;span class="o">=&lt;/span>&lt;span class="m">1&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。&lt;/p>
&lt;h2 id="kafka-5494">KAFKA-5494&lt;/h2>
&lt;p>&lt;a href="https://github.com/apache/kafka/pull/3743" target="_blank" rel="noopener">KAFKA-5494: enable idempotence with max.in.flight&amp;hellip;&lt;/a> このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>オリジナルのデザイン資料は&lt;a href="https://docs.google.com/document/d/11Jqy_GjUGtdXJK94XGsEIK7CP1SnQGdp2eF0wSw9ra8/" target="_blank" rel="noopener">ここ&lt;/a>にあります。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>合わせて&lt;code>OutOfSequenceException&lt;/code>が発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3">
&lt;p>またこのPRに関する前提情報や設計については別途&lt;a href="https://docs.google.com/document/d/1EBt5rDfsvpK6mAPOOWjxa9vY0hJ0s9Jx9Wpwciy0aVo/edit" target="_blank" rel="noopener">こちら&lt;/a>にまとめられています。&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Queues for Kafkaとは何か?</title><link>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</link><pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A&amp;#43;Queues&amp;#43;for&amp;#43;Kafka" target="_blank" rel="noopener">KIP-932 Queues for Kafka&lt;/a> はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。&lt;/p>
&lt;h2 id="consumer-group">Consumer Group&lt;/h2>
&lt;p>Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。&lt;/p>
&lt;p>&lt;a href="https://www.confluent.io/blog/dynamic-vs-static-kafka-consumer-rebalancing/" target="_blank" rel="noopener">Consumer Group&lt;/a>はアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。&lt;/p>
&lt;p>一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。&lt;/p>
&lt;h2 id="これまでのアプローチ">これまでのアプローチ&lt;/h2>
&lt;p>ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。&lt;/p>
&lt;p>&lt;a href="https://github.com/line/decaton" target="_blank" rel="noopener">LINE Decaton&lt;/a> はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。&lt;/p>
&lt;p>&lt;a href="https://github.com/confluentinc/parallel-consumer" target="_blank" rel="noopener">Confluent Parallel Consumer&lt;/a> はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、&lt;a href="https://www.confluent.io/blog/introducing-confluent-parallel-message-processing-client/" target="_blank" rel="noopener">順序保証しない設定を含め柔軟に処理構成を変更&lt;/a>することが出来ます。&lt;/p>
&lt;h2 id="queue-for-kafka---kafka-nativeなアプローチ">Queue for Kafka - Kafka Nativeなアプローチ&lt;/h2>
&lt;p>Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。&lt;/p>
&lt;p>Shared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、&lt;code>group.type&lt;/code>を&lt;code>share&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。&lt;/p>
&lt;p>Consumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;code>group.type&lt;/code>は新しいプロパティ。デフォルトは&lt;code>consumer&lt;/code>であり、この指定だと通常通りConsumer Groupとして機能する。デフォルトは&lt;code>consumer&lt;/code>である為下位互換性あり。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item></channel></rss>