[{"authors":null,"categories":null,"content":"","date":1698883200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1698883200,"objectID":"6c0805fdbd7621e3bbd425457215404c","permalink":"https://confluent-jp.github.io/community/authors/hashi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/hashi/","section":"authors","summary":"","tags":null,"title":"hashi","type":"authors"},{"authors":null,"categories":null,"content":"","date":1692576e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692576e3,"objectID":"7be59ae0d196dc1bbfb6c60c097b09ad","permalink":"https://confluent-jp.github.io/community/authors/stanislav/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/stanislav/","section":"authors","summary":"","tags":null,"title":"stanislav","type":"authors"},{"authors":null,"categories":null,"content":"","date":1689552e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1689552e3,"objectID":"d4ccb66a26bf2330497507875f5c9105","permalink":"https://confluent-jp.github.io/community/authors/kai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/kai/","section":"authors","summary":"","tags":null,"title":"kai","type":"authors"},{"authors":null,"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686614400,"objectID":"b0bc5dc322acaf3a4abf9d1fd4e8ac36","permalink":"https://confluent-jp.github.io/community/authors/akio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/akio/","section":"authors","summary":"","tags":null,"title":"akio","type":"authors"},{"authors":null,"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1522540800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://confluent-jp.github.io/community/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/admin/","section":"authors","summary":"","tags":null,"title":"admin","type":"authors"},{"authors":["hashi"],"categories":["Blog","ksqDB"],"content":"はじめに Kafkaをベースとしたストリーム処理では、Kafka Topicに流れるイベントを取り込み、処理後に別のTopicに書き込む事を繋げる事によりパイプラインを構築します。ksqlDBの様なストリーム処理基盤はこの処理を開発者から隠蔽化し、SQLを用いてそのロジックのみに注力できるよう補助してくれます。\n一方、この隠蔽化によってksqlDBが行なっている内部処理の多くは開発者にはタッチする事が出来ず、出来た場合でも直感的に扱えない事も多くあります。Kafka TopicのKeyもその一つです。\n今回はksqlDBにおけるStreamの概念と、Topic Keyを扱う方法について説明します。\nStreamとTable ksqlDBのストリーム処理では、Topicと紐付けるデータモデルを定義しそのモデルに対してクエリを実行する形でデータにアクセスします。具体的にはStreamとTableで：\nSTREAM - Topicを流れるイベントを、時系列を維持したデータの流れとして体現。ステートレス。 TABLE - Topicを流れるイベントからKey単位でデータの最新状態をマテリアライズ。ステートフル。 同じKafka上で扱うデータですが、モデルによってksqlDBにおける扱いも、そしてそれを支える内部の仕組みも異なります。1 ただksqlDBのクエリ上はどちらもCREATE構文を利用してSQL同様の手順で作成します。例としてStreamの定義のサンプルは以下の様になります。\nCREATE STREAM Clickstream ( IP VARCHAR, USERID INT, REMOTE_USER VARCHAR, TIME VARCHAR, _TIME INT, REQUEST VARCHAR, STATUS VARCHAR, BYTES VARCHAR, REFERRER VARCHAR, AGENT VARCHAR ) WITH ( KAFKA_TOPIC=\u0026#39;datagen-topic\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;); ここではdatagen-topicというJSONでシリアライズされたTopicに対してClickstreamという名前のStreamデータモデルを定義しています。\nCSASとCTAS Topicをモデル化したStreamやTableを定義したとして、今度はそのモデルに対して処理をする必要性が出てきます。一般的なデータフロープログラミングのモデルではプログラム内で処理をチェイニングした結果を別Topicに出力しますが、SQLにはそのような構文モデルはありません。一方リレーショナルDBではストアドプロシージャを利用しますが、DB毎にその仕様は異なります。\nksqlDBではもっと汎用的なSELECTとCREATE STREAMを組み合わせる事により処理とストアを結びつけます。具体的にはCREATE STREAM AS SELECT構文を利用します。\nCREATE STREAM EventsWithoutKey WITH (KAFKA_TOPIC=\u0026#39;404events\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;) AS SELECT IP, USERID, _TIME TIME_IN_INT, STATUS, BYTES FROM Clickstream WHERE STATUS = \u0026#39;404\u0026#39; EMIT CHANGES; ここでは前述したClickstreamというStreamから必要なカラムを指定してSELECTした結果を新たなStreamとして定義する処理です。ここではWHERE句を利用してフィルタリングした結果のみ抽出し、かつ新たに404eventsというTopicに対して出力しています。物理的にはClickstreamに紐付くdatagen-topic Topicにあるデータが変換/加工され404eventsという新たなTopicに登録されます。\n当然この構文はksqlDBでのストリーム処理には頻出構文であり、CSAS (CREATE STREAM AS SELECT)、CTAS (CREATE TABLE AS SELECT)と呼ばれます。\nKeyとデータモデル CREATE STREAMとCREATE TABLEではTopicのKeyの扱い方が異なります。\n以前のバージョンではStreamでもTableでもROWKEYという名称でTopicのKeyに紐づくフィールドをモデルに追加します。このROWKEYは物理的にはTopicのKeyでありながら、Valueを扱うksqlDBから参照出来るという、他のフィールドとは扱いも振る舞いも異なります。また、コミュニティではこの勝手に追加されるROWKEYというフィールドの扱い方に関して多くの混乱を招きました。ストリーム処理をSQLで処理をする上では直感的では無いという判断でした。\nこのKeyの扱い方はksqlDB 0.10で大きく変わりました。これは一律ではなくStreamとTableで定義を変える事で：\nCREATE TABLE - 明示的にKeyを指定する必要があり、それにはPRIMARY KEYと指定するフィールドが必要。 CREATE STREAM - キーをそもそも指定しない。 このアプローチはTABLEの構文としても自然であり、かつSTREAMを扱う際にはKeyが存在すらしないという潔いものです。結果としてこの変更と思想が以降のksqlDBのコミュニティに広がりました。\nStreamとKey それでもStreamでKeyを扱いたいというのが本エントリの主旨です。\n実際にStreamでKeyを指定する必要性がある場合は存在し、具体的にはJOINの際にはKey指定したものしかJOIN出来ません。この為StreamでもKeyを指定する事は可能になっています。\n具体的にはフィールドにKeyと指定する事により、そのフィールドをValueの一部ではなくKeyとして扱います。先程のCREATE STREAMを例に取ると：\nCREATE STREAM ClickstreamWithKey ( IP VARCHAR Key, USERID INT, REMOTE_USER VARCHAR, TIME VARCHAR, _TIME INT, REQUEST VARCHAR, STATUS VARCHAR, BYTES VARCHAR, REFERRER VARCHAR, AGENT VARCHAR ) WITH ( KAFKA_TOPIC=\u0026#39;datagen-topic\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;); 同じTopicを参照していますが、ここで生成されるStreamにはレコードKeyにIPが指定され、と言うよりValueからKeyに移動します。\nこの振る舞いを実際に確認するにはCSASで再定義したものに新たなTopicを割り当て、その結果を比較する必要があります。これら2つのStreamに以下のCSASを適用すると：\nCREATE STREAM TransformedEvents WITH (KAFKA_TOPIC=\u0026#39;events\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;) AS SELECT IP, USERID, _TIME TIME_IN_INT, STATUS, BYTES FROM Clickstream -- Keyがある方はClickstreamWithKeyと指定 EMIT CHANGES; 通常のCREATE STREAMで生成した場合、Topicには となり、Keyを指定したStreamに対するCSASの結果は となります。IPがTopicのKeyに移っている事が確認できます。\nKeyをValueの中にも持つ 先述した通り、StreamにおいてKeyを扱う事は混乱を招く恐れがある為、JOIN等明確な利用がある場合のみに利用する事が推奨されます。それでもJoinもするがValueの中でもKeyを参照する、つまりksqlDB内でKeyを参照したいというユースケースも存在します。\nこの場合、KeyのコピーをValue内に持たせるする必要がありますが、ハックに近い対応が必要となります。\nKeyをValueにコピーする関数は存在し、AS_VALUE関数を利用すればコピー出来ます。\nしかしながら、AS_VALUEはTableを前提とした関数であり、Tableには明示的に PRIMARYKEYを指定するのでKeyとそのフィールド名も参照出来ますが、Streamの場合にはKeyは必須ではありません。また、先程のKeyを利用したCREATE STREAMの結果にあるように、Keyには値のみ、ここではIPで指定した値のみが入っています。なのでAS_VALUEをROWKEYに対して実行したいのですが：\nCREATE STREAM TransformedEventsWithKey WITH (KAFKA_TOPIC=\u0026#39;events-with-key\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;) AS SELECT AS_VALUE(ROWKEY) AS IP, USERID, _TIME TIME_IN_INT, STATUS, BYTES FROM ClickstreamWithKey EMIT CHANGES; このクエリは構文エラーとなります。AS_VALUEはTableのPRIMARY KEYは引数として受け付けますが、値だけのROWKEYは受け付けません。つまりAS_VALUEは通常の使用法ではStreamに対しては利用出来ません。2\nハックとしての解答は以下になります：\nCREATE STREAM TransformedEventsWithKey WITH (KAFKA_TOPIC=\u0026#39;events-with-key\u0026#39;, VALUE_FORMAT=\u0026#39;JSON\u0026#39;) AS SELECT IP AS ROWKEY, AS_VALUE(IP) AS IP, USERID, _TIME TIME_IN_INT, STATUS, BYTES FROM ClickstreamWithKey EMIT CHANGES; ROWKEYに対してIPというフィールド名を割り当て、そのフィールドをAS_VALUEで利用する方法になります。上記クエリを分解解釈すると以下となります：\nStreamにはないPrimary KeyのフィールドをIPとして明示的に指定。 そのフィールドをAS_VALUEで参照。この際元々あるフィールドと同名で定義。 妙な構文になりますが、結果は： と期待通りの結果となります。\nおわりに このハック的なアプローチを見ると「ksqlDBは面倒くさい。直感的ではない。」と思うかも知れません。確かにハックだけを見るとその通りで、無意味な制約のようにも思えます。しかしながらこれには背景があり、より直感的なデータモデル定義へと変更した事による副作用である事を理解して頂ければと思います。また、ksqlDB、というよりデータフロー処理内でKeyを参照するというのは特殊な要件です。このハックを怪しい要件/ロジックのスメルと捉える事もできます。\n何より、やや面倒くさいksqlDBにおけるKeyの扱いを理解すると、ksqlDBの仕組みやデータモデルへの理解が深まります。ksqlDBの裏側を少し垣間見る機会と思って頂ければ幸いです。\n実際のステート管理はksqlDBが内部で利用するKafka Streamsの仕組みを利用している。 ↩︎\nこれはStreamの構文だからエラーではなく、そもそもAS_VALUEにROWKEYを指定出来ないという仕様によるもの。 ↩︎\n","date":1698883200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698883200,"objectID":"86d518847ed4151c3b4eedfa73a290c8","permalink":"https://confluent-jp.github.io/community/blog/handling-keys-in-ksql/","publishdate":"2023-11-02T00:00:00Z","relpermalink":"/community/blog/handling-keys-in-ksql/","section":"blog","summary":"ksqlDBにおけるストリーム処理の概念と、ストリーム処理でTopicのKeyを扱う方法について。","tags":["Stream Processing","Topic"],"title":"ストリーム処理でKafka TopicのKeyを扱う in KSQL","type":"blog"},{"authors":["hashi"],"categories":null,"content":"","date":1698796800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698796800,"objectID":"9c3443b4eafc8d4787ffb84da4715f9c","permalink":"https://confluent-jp.github.io/community/demo/demo-cc-ksqldb-handling-keys/","publishdate":"2023-11-01T00:00:00Z","relpermalink":"/community/demo/demo-cc-ksqldb-handling-keys/","section":"demo","summary":"ksqlDBにおいてTopicのKeyの扱い方やそのパターンについてのハンズオンです。","tags":["Confluent Cloud","ksqlDB","Stream Processing","DataGen Connector"],"title":"Handling Keys in ksqlDB","type":"demo"},{"authors":["hashi"],"categories":["Announcement","Flink"],"content":"Apache Flinkの新バージョン1.18が公開されました。Conflunet Blogではその具体的な改善点をエリア毎に詳しく説明しており、ConfluentだけでなくVerverica、Aiven、Alibaba CloudのFlinkコミッターも共著として参加し、結果としてFlinkの情報発信として非常に有益なものとなっています。\n昨年発表されたAkkaのライセンス変更に伴い、1年前にAkkaの代替模索に入ったFlinkプロジェクト。ようやくAkkaからApache Pekkoに切り替えた節目のリリースとなりました。\n併せて、ストリーム処理/バッチ処理改善等Flinkのストリーム処理基盤としての成熟度がさらに増す多くの改善も含まれています。本エントリでは、一部ではありますがそのうちの幾つかをご紹介します。\nFLIP-293: Introduce Flink Jdbc Driver For Sql Gateway FlinkクラスタへのRESTエンドポイントを提供するFlink SQL Ga†ewayに、新たに汎用的なJDBC経由で通信できるFlink JDBC Driverが接続出来るようになりました。\nこれまでSQL Gatewayにはコンソールベースでのアクセスは可能でしたが、セッションを保持したアプリケーションからのアクセスは出来ませんでした。一方JDBC Driverの基本利用はFlink Jobの登録にあり、インタラクティブなクエリはサポートされていませんでした。本FLIPによりこの2者を繋げ、SQL Gateway経由でJDBC接続が可能な多くのデータベースに対してJDBC Driverから接続出来るようになりました。\nFLIP-311: Support Call Stored Procedure これまでFlinkから見たデータソースはSourceでありSinkであり、あくまでデータストアという扱いにおける接続に限られました。本FLIPによってFlinkからStored Procedureの一覧取得と実行が可能となります。\nStored Procedure実行におけるインターフェース変更に合わせ、Catalog InterfaceにもStored Procedure用のメソッドが追加されており一覧の取得も可能です。\nFLIP-308: Support Time Travel SQL:2011 StandardのTime Travel Queryがサポートされます。どちらもSQL:2011標準であるようタイムスタンプでの指定となりますが、特定時点ならびに期間指定がサポートされます。\n用途としてはデータレイクに長期格納しているデータに対してFlinkからソースアタッチする際に特定の過去時点でのデータも同様の方法で取得可能となります。IcebergやDelta Lake等、Time Travel Queryをサポートしているストレージに限られた機能となり、またConnectorが新しいインターフェースに沿って実装する必要があります。\nFLIP-292: Enhance COMPILED PLAN to support operator-level state TTL configuration Table APIやSQLを利用してステートフルなストリームパイプラインを構築する際の、ステート管理に関わる改善です。JOINをしたり同じTableデータに異なる条件で集約したりする場合に、そのステートのベースとなるイベントの有効期間 (TTL: Time To Live) の制御によっては処理の対象となるイベントが変わります。\n本FLIPでは、それぞれの対象ソースに対して個別のTTLを設定出来るようになります。これにより要件に即したステート管理を行うことができるようになります。より粒度の細かなスコープの指定や、特定ユースケースにおけるステートストアの大幅な削減等が可能です。\nFLIP-296: Extend watermark-related features for SQL ストリーム処理においてデータの整合性をいかに評価/制御することは極めて重要ですが、FlinkではEvent TimeとWatermarkを利用する事により明示的にそれぞれのデータ処理ウィンドウを決定しています。\nWatermarkはその振る舞いを制御する重要な仕組みであり、DataStream APIであればその関連性の定義を制御(Watermark Alignment)する事も出来ました。但しWatermarkの制御をする為にはローレベルなDataStream APIを利用する必要がありました。\n本FLIPでは、Flink SQLによってその制御を可能とします。具体的にはTable作成時やクエリにアノテーションを指定する事で：\nCREATE TABLE user_actions ( ... user_action_time TIMESTAMP(3), WATERMARK FOR user_action_time AS user_action_time - INTERVAL \u0026#39;5\u0026#39; SECOND ) WITH ( \u0026#39;scan.watermark.emit.strategy\u0026#39;=\u0026#39;on-event\u0026#39;, ... ); とWatermark生成インターバルを指定したり：\nselect ... from source_table /*+ OPTIONS(\u0026#39;scan.watermark.emit.strategy\u0026#39;=\u0026#39;on-event\u0026#39;) */ SELECT時にWatermarkの出力タイプを指定できます。\nバッチ処理速度改善 FLIP-324: Introduce Runtime Filter for Flink Batch Jobs\nFLIP-315 Support Operator Fusion Codegen for Flink SQL\n全バージョン(Flink 1.17)ではバッチ処理におけるスループットが大きく改善しました。その改善は本リリースでも継続して行われており、さらにそのパフォーマンスが向上しています 。今回のリリースにおける主要な改善は：\nFLIP-324 Runtime Filterは集約処理の前段階で対象レコードを絞るアプローチで、これにより集約やJoinにかかるネットワーク通信や必要処理の大規模化を削減する事ができます。このFLIPでは、クエリのプラン中に関連処理の中からローカルでの集約可能な処理を特定し、Runtime Filterとして実行するようになりました。 FLIP-315 利用可能メモリの増加からCPUの処理能力にボトルネックが移る中、処理プロセスにおける無駄が全体スループットに大きな影響を与えています。幾つかの改善ポイントを評価した結果、ベクター化とコード生成方式のうちコード生成方式のOperator Fusionの実装を導入しました。 結果としてTPC-DSのベンチマーク結果がFlink 1.17と比べて13%、1.16とでは35%改善しました。\nおわりに 今回のご紹介はApache Flink1.18で導入された新機能や改善のごく一部ではありますが、ストリーム処理からバッチ、クラウドネイティブ化に向けた改善等、非常に多岐に渡る改善が含まれています。ksqlDBを知る身としてはFlinkの分散データ処理基盤としての重厚さを感じることにもなりました。是非オリジナルのブログもご覧ください。\n","date":1698624e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1698624e3,"objectID":"a080726b64a76322ed9b18db7c26ca64","permalink":"https://confluent-jp.github.io/community/blog/apache-flink-1.8/","publishdate":"2023-10-30T00:00:00Z","relpermalink":"/community/blog/apache-flink-1.8/","section":"blog","summary":"Apache Flinkの最新バージョンが公開されました。ようやくAkkaへの依存が解消されたFlinkですが、それ以外にもストリーム処理/バッチ処理、その他様々な改善を含んだリリースとなりました。","tags":["Performance","Watermark","Operator Fusion"],"title":"Apache Flink 1.18 アップデート","type":"blog"},{"authors":["hashi"],"categories":["Announcement","Kafka Core"],"content":"Apache Kafkaの新バージョン3.6が公開されました。 ZookeeperモードからKRaftモードへの移行ではありますが、KRaftの強化だけでなく新たな機能も多く追加されております。詳細はConfluentのアナウンスメントとYouTubeで説明されています。より詳細には本家のリリースノートには全ての関連kIPのリストが公開されています。\n本エントリでは、中でも重要なKIPについてご紹介します。\nKIP-405: Kafka Tiered Storage (Early Access) こちらのブログエントリでもご紹介していたTiered Storageがアーリーアクセスとして利用可能となりました。単純に古いセグメントがオブジェクトストレージに退避されるだけでなく、既存のKafkaの設計やパフォーマンスへの影響を与えずに、Kafka自身がよりクラウドネイティブな姿へと変わる上で重要な機能です。\n今回3.6に登場したバージョンはまだ本番環境における利用を想定していない旨にご留意ください。機能の安定性だけでなく、JBODやCompacted Topic等機能制限もあります。既存Topicもバージョンを3.6にアップグレードすればTiered Storageに変更出来ますが、2.8.0より前に作成されたTopicには適用出来ない点もご注意下さい。アーリーアクセス版の制限はこちらのTiered Storage アーリーアクセスリリースノートに記載されています。\nKIP-868 Metadata Transactions KRaftの内部処理に関する改善です。KRaftではメタデータの更新時に関連レコード (例：Topic登録時の全Partitionのレコード) をアトミックに更新する仕様となっています。この為Controllerが処理中に障害に陥った場合でも部分的なメタデータの更新がなされないようになっています。\n一方このバッチサイズはKRaftのフェッチサイズが上限となっており、アップデート前ではこのサイズは8kbとなっています。この為非常に大きなメタデータの更新時にはフェッチ上限を超えるバッチが生成される可能性がありました。\nこの改善で新たにメタデータにトランザクションの概念が導入され、トランザクションの開始/終了等のマーカーレコードを挿入するようになります。これによりKRaftのフェッチサイズを超える更新バッチサイズになった場合でも処理が可能となります。\nKIP-941: Range queries to accept null lower and upper bounds Kafka StreamsにてマテリアライズしたState Storeに対してアクセスするにはInteractive Queryを利用します。これにより、アクセスするデータが分散配置されているKafka Streamsのどのインスタンスにて保存されているのかを意識せずとも適切なデータを取得する事が出来ます。\n一方内部ではそれぞれのデータはKafka Streamsインスタンスに部分的に保存されている為、レンジ指定をして取得する場合には処理に大きな負荷がかかります。この為レンジ指定のクエリは制限が多く、アップデート前ではnullを指定した取得が出来ませんでした。この為：\nprivate RangeQuery\u0026lt;String, ValueAndTimestamp\u0026lt;StockTransactionAggregation\u0026gt;\u0026gt; createRangeQuery(String lower, String upper) { if (isBlank(lower) \u0026amp;\u0026amp; isBlank(upper)) { return RangeQuery.withNoBounds(); } else if (!isBlank(lower) \u0026amp;\u0026amp; isBlank(upper)) { return RangeQuery.withLowerBound(lower); } else if (isBlank(lower) \u0026amp;\u0026amp; !isBlank(upper)) { return RangeQuery.withUpperBound(upper); } else { return RangeQuery.withRange(lower, upper); } } このような回避的なコーディングが必要でした。\n今回レンジクエリにnull指定が出来るようになった事により：\nRangeQuery.withRange(lower, upper); これだけでnullを回避した実装が可能となります。\nKIP-875: First-class offsets support in Kafka Connect Kafka Connectはその処理状況をKafkaネイティブにオフセットを管理する事により把握/管理しています。Connectorタスクが異常終了した場合でも、コミットされたオフセットを元に継続処理できるので、Connector自身には独自のステート管理のストレージ等が無くとも障害耐性を確保する事が出来ています。\n一方このオフセットはKafka上では参照できるもののKafka Connectとしては外部からアクセス出来るようにはなっていませんでした。何かしらの理由でオフセットを制御したい（特定レコードレンジを飛ばしたい、あるオフセットから再読み込みしたい、etc）場合にはハック的にKafka上のオフセット用Topicをいじる必要がありました。\nこの改善によってKafka Connect API経由でオフセットの取得、更新、削除が可能となります。\nおわりに Apache Kafka 3.6にはその他多くの改善が含まれています。今回のエントリではその一部しか触れていませんが、是非本家のリリースノートも併せてご参照ください。\n","date":1697068800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697068800,"objectID":"ea58cc5ea760fabf701355cf3657cc8d","permalink":"https://confluent-jp.github.io/community/blog/apache-kafka-3.6/","publishdate":"2023-10-12T00:00:00Z","relpermalink":"/community/blog/apache-kafka-3.6/","section":"blog","summary":"Apache Kafkaの最新バージョンが公開されました。Tiered Storageがアーリーアクセスとして登場した他、Zookeeperのアップデート、KRaft Metadata Transaction等様々な新機能が追加されました。","tags":["Tiered Storage","KRaft","Kafka Streams","Kafka Connect"],"title":"Apache Kafka 3.6 アップデート","type":"blog"},{"authors":["hashi"],"categories":["Announcement","Confluent Cloud"],"content":"Confluent Cloudはマネージドのプラットフォーム提供である為、様々な機能追加や改善は自動的に適用されます。これら改善はコアであるApache Kafkaのバージョンアップに限らず、またプラットフォーム製品であるConfluent Platformの機能にも限定されず、Confluent Cloud独自の機能も様々追加されています。\nQuarterly Launchは、そんなConfluent Cloudの新規機能を四半期毎にまとめてご紹介するブログとYouTubeエントリを指します。今回はCurrent 2023の開催を待った為だいぶ遅くなってしまいましたが、改めてそのハイライトをご紹介します。\nApache Flink® on Confluent Cloud (Open Preview) 来年サービス提供開始予定のApache Flink on Confluent Cloudがオープンプレビューとして公開されました。提供インターフェースはFlink SQLのみ。現時点では既知の機能制限があり、この為本番利用には向きません。また現時点で利用可能なクラウド/リージョンは限定的ではあります。ただ、今日もうお試しいただけます。\nEnterprise clusters Confluent Cloudのサーバーレスなクラスタ提供に新たにEnterpriseというオプションが追加されました。Basic、Standardといった既存のサーバーレスクラスタと異なり閉塞ネットワーク接続1を可能としており、併せて標準でSLA 99.99%、最大1GBpsのスループット(Ingress/Egress合算)をサポートしています。\n残念ながらローンチ時点ではサポートされているリージョンは限定的2ですが、以降継続して拡張予定となっています。\nConfluent Terraform provider updates Confluent Terraform ProviderがHashiCorp Sentinel統合をサポートしました。これによりPolicy-as-Codeによる運用にConfluent Cloudを統合することが可能となります。\nまた、新たにResource Importer機能を提供開始しました。これにより既存のConfluent CloudからTerraformの構成 (main.tf) ならびに状態 (terraform.tfstate) を逆生成する事が可能となります。\nその他 先日発表したConfluent Platform 7.5でもご紹介した双方向Cluster LinkingがConfluent Cloudでもサポートされております。 PrivateLink接続のConfluent Cloudクラスタ同士を直接Cluster Linkingで接続可能することが可能となりました。 その他にも新たな機能が追加されておりますが、その全貌ならびに個々の詳細につきましてはConfluentブログのアナウンスメントをご覧ください。\n2023年9月ローンチ時点では、AWS PrivateLink経由の接続のみサポートしております。その他クラウドの接続形態は後日提供となります。 ↩︎\n2023年9月ローンチ時点では、AWSのus-east-2(Ohio)、us-west-2(Oregon)、ap-southeast-1(Singapore)等8リージョンでのみ提供開始となっています。日本リージョンでの利用開始は現時点では未定です。 ↩︎\n","date":1696118400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696118400,"objectID":"fd9749cc69fae196212070573f0f71d3","permalink":"https://confluent-jp.github.io/community/blog/confluent-cloud-23q3-launch/","publishdate":"2023-10-01T00:00:00Z","relpermalink":"/community/blog/confluent-cloud-23q3-launch/","section":"blog","summary":"2023年第3四半期、Confluent Cloud新機能のご紹介です。","tags":["Apache Flink","Enterprise Clusters","Terraform Provider","Cluster Linking"],"title":"Confluent Cloud Q3'23 Launch","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Kafkaの利用は結果整合性の概念の浸透とその実践的な活用ユースケースの登場によって飛躍的に広がりました。それまでのリレーショナルモデルに見られるACID特性を前提とした整合性の管理ではなく、Change Data Captureによって整合性を整理するという大きく異なるアプローチであり、既存の概念に挑戦するものでした。\nリレーショナルモデルにおけるトランザクションではない「今ではない近い将来にはデータは整合性を保った状態で連携先に届く」というアプローチである為、Change Data Captureを活用したソリューションにトランザクションの概念が登場すると混乱を招く事も多くあります。\nKafkaもトランザクションをサポートしており、データを整合性を保ったままリアルタイムに扱う上で非常に重要な概念です。しかしながら、Kafkaのトランザクションの目的はリレーショナルモデルのそれとは大きく異なります。\nこのエントリは、Kafkaにおけるトランザクションがどういうものであるかの説明と、トランザクションにまつわる様々な誤解を解く事を目的としています。\nトランザクションとExactly Once メッセージングの世界では「確実に1度だけメッセージをデリバリーする」という事が極めて難しいとされてきました。1 一方、メッセージを (最低1回以上) 確実にデリバリーする手法は論理的にも実装的にも比較的容易である為、ほとんどのメッセージング基盤はこの手法を主に採用しています。OSSとして公開された当時のKafkaもその一つでした。データを送る側 (Producer) で1回だけ送るというのが難しい為、受け取り側 (Consumer) 側で重複メッセージの処理を行う必要があります。 2\nKafkaがExactly Once Delivery機能をサポートしたのはバージョン0.11です。この頃より、結果整合性を前提としたソリューションの土台となり得るKafkaの利用が飛躍的に広がりました。\nExactly Once Deliveryに関するKIPの正式名はExactly Once Delivery and Transactional Messagingであり、Idempotent Producerとトランザクションの双方を纏めて1つのKIPで定義しています。この為、Exactly Once Deliveryを達成する為には必ずトランザクションの導入が必要なよう誤解されている事も多いと思います。当然これら2つには強い関連性がある為同じKIP内で説明されていますが、それぞれ異なる機能であり、分解して理解する必要があります。\nIdempotent Producerについてはこちらのブログエントリでご紹介していますが、具体的にはProducerがKafkaに対してExactly Onceでメッセージを送る為に必要な機能であり、Kafkaトランザクション機能とは異なります。つまり明示的にトランザクションを使用しなくても、ProducerからKafkaへの書き込みはExactly Onceに指定できます。\nKafka Transaction Kafkaトランザクション自体はリレーショナルDBにおけるトランザクションと近い思想を持つもので、異なるエンティティへの書き込み処理をアトミックに扱える機能ですが、Kafkaの世界では対象がTopicとなります。つまり、異なるTopicへの書き込みをCommit/Abortする事ができる機能です。利用方法もリレーショナルDB APIへのプログラムアクセスと似ており：\nvoid initTransactions() throws IllegalStateException; void beginTransaction() throws ProducerFencedException; void commitTransaction() throws ProducerFencedException; void abortTransaction() throws ProducerFencedException; void sendOffsetsToTransaction(Map\u0026lt;TopicPartition, OffsetAndMetadata\u0026gt; offsets, String consumerGroupId) throws ProducerFencedException; これらメソッドを扱いプログラムコード内でアトミック処理の制御を行う事が出来ます。当然、Topic AとTopic Bへの書き込みをトランザクションで括ることも出来ます。しかしながら、リレーショナルモデル同様のトランザクションの使い方では、Kafkaへのトランザクション処理の導入が高い優先度で扱われたのも、この機能がExactly Once Deliveryと関連づけられ同一のKIP内で設計されていることも説明できません。\n上記には一般的なトランザクション処理では見られないメソッドも含まれていますが\nvoid sendOffsetsToTransaction(Map\u0026lt;TopicPartition, OffsetAndMetadata\u0026gt; offsets, String consumerGroupId) throws ProducerFencedException; このメソッドがExactly Once Deliveryとトランザクションを関連付ける重要な役割を担っています。\nsendOffsetsToTransaction このメソッドが何をするかは名前からもある程度推測できますが、「処理した一連のConsumer OffsetをConsumer Group Coordinatorに送りつつ、 現在のトランザクションに関連付ける 」メソッドです。少々アクロバティックな処理ですが、この処理をトランザクションAPIに定義するには必要性があります。\nこのメソッドは、全く異なる2つの処理を1メソッドに纏めるというタブーに近いメソッドです。さらに注意すべきなのは、トランザクションはProducerに関わる機能であり、Consumer OffsetはConsumerに関わる機能です。つまりこのメソッドはProducerでもありConsumerでもある処理でしか存在意義が無いメソッドです。\n一般的なメッセージングモデルではあまり検討しないこの処理ですが、Kafkaのエコシステムではストリーム処理における根本的かつ重要な要件となります。\nストリーム処理とExactly Once ストリーム処理 ストリーム処理とは、一般的なバッチ処理同様にInputとOutputを持つデータ処理を、中間的なストレージを経由する事により一連のデータフローとして形成するアプローチです。バッチとの違いは、その中間的なストレージがcsvファイルやDBの中間テーブルではなくKafka Topicを利用する事であり、これによりバッチ同様のデータフローをリアルタイム3に実行する事が出来る点です。\nこの例ではSourceから発行されたイベントを、エンリッチしてアプリやDBに格納するフローと、集約した後ダッシュボードに転送するフローを表現しています。イベントはKafkaに発行されてから、Kafka内で変更/加工された後にSinkへとリアルタイムに繋げるデータフローとなっています。\nこれはあくまで論理的なフローですが、実際にはデータフロー内の処理は全てKafkaとの通信で成り立っています。\nSourceはProducerとして機能し、DBやダッシュボードへの転送はSink Connectorを利用しています。これらデータフローの両端はProducerもしくはConsumerのいずれかの役割を果たします。\nその他の処理はイベントを受け取り、加工の上次の処理に渡す為、ProducerでありConsumerである必要があります。より具体的には「前処理がProducerでイベント送ったTopicを、その次の処理がConsumeする」、この繰り返しでデータフローのトポロジーを形成します。このトポロジーをTopicも含めたフローで表現すると：\nこのように分解できます。ここではProduceを点線、Consumeを実線で表現しています。処理自体はKafkaのTopicを境に完全に分離された構成となっており、バッチ処理における中間ストレージと同じ役割を果たしています。\nExactly Once この処理のEnd-to-EndでExactly Onceを達成するには？という命題の為にKafka Transactionは定義されています。\nKafka Consumerは、メッセージの処理後にConsumer OffsetをcommitSync/commitAsyncというメソッドを使って更新します。このオフセットコミットが行われる事により、仮に処理後にConsumerのプロセスが落ちたとしても、新しいプロセスが引き継いで処理を継続する事が出来ます。\nしかしながら、処理後 (ストリーム処理ではConsumeし、データの処理を実行し、別のTopicにProduce前) に何らかの障害によってプロセスを失った場合、引き継いだプロセスはコミットされる前のオフセットをもとに処理、つまり同じメッセージを消費し再処理することとなります。これではProduceに関してはIdempotent Producerの設定によってExactly OnceでKafkaに書き込めても、End-to-EndのフローではExcatly Onceを保証出来ません。\nKafkaにおけるトランザクション、そして中でも先ほど言及したsendOffsetsToTransactionはまさしくこのProduceとConsumer Offsetのコミットをアトミックな処理としてに定義する事ができます。これにより、どのタイミングで障害が発生してもEnd-to-EndでExactly Once Deliveryを達成する事が出来ます。4\nまとめ Kafka TransactionとIdempotent Producerは同じKIP内で定義されており、また併せて説明される事が多い機能ではありますが、使われる場所と用途は全く異なります。ただこれらはKafkaにおけるExactly Once Deliveryにおいてお互いを補完するものであり、双方が揃って初めてEnd-to-EndのExactly Once Deliveryが達成出来る事が分かります。\n分散システムにおける二人の将軍問題等を用いて言及されています。 ↩︎\nこの為Consumer側で冪等性を確保した処理が求められます。 ↩︎\n一般的に「リアルタイム処理」とは数ミリ秒誤差のものを指す為、厳密には準リアルタイムと呼ぶのが相応しいかも知れません。Kafkaのストリーム処理におけるEnd-to-Endのレイテンシは、処理にもよりますが数百ミリ秒から数秒程度のレイテンシとなります。 ↩︎\n図にもありますが、Consumerも未コミット状態のデータにアクセスしてはいけないので、分離レベルをRead Committedに指定する必要があります。ここはリレーショナルモデルの概念をそのまま踏襲しています。 ↩︎\n","date":1694217600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1694217600,"objectID":"a0ebb474d2fdb08a54b08a94c7218d0b","permalink":"https://confluent-jp.github.io/community/blog/kafka-transaction-how-it-works/","publishdate":"2023-09-09T00:00:00Z","relpermalink":"/community/blog/kafka-transaction-how-it-works/","section":"blog","summary":"KafkaにおけるトランザクションはリレーショナルDBにおけるそれとどう違うのか？KafkaトランザクションとExactly Onceとの関係は？","tags":["Kafka Producer","Exactly Once Semantics","Transaction"],"title":"KafkaとトランザクションとExactly Once","type":"blog"},{"authors":["hashi"],"categories":["Announcement","Confluent Platform"],"content":"Confluent Platform 7.5がリリースされました。 Confluent Blog 内包されるApache Kafkaのバージョンは3.5となります。\nコアエンジンであるApache Kafkaのアップグレードだけでなく、エンタープライズ ソリューションとしてのConfluent Platformとしての機能追加や改善も含まれています。\nSSO for Control Center (C3) for Confluent Platform Confluent Control CenterはConfluent Platformにおける管理ポータルとしての役割から、ごく一部のSREメンバーからのみアクセスされるという特殊なコンポーネントです。この為これまではアクセス制御のアプローチについては少し限定的でしたが、Broker等と同様OAuth2ベースの認証/認可の方法でアクセスする事が可能となりました。 Confluent REST Proxy Produce API v3 Confluent REST ProxyはKafka BrokerへのRESTベースのアクセスを可能としており、Confluent Platform/Cloudの双方で幅広く活用されています。一方、通常のKafkaプロトコルベースのアクセスに比べると制限もあり、これまでも段階的に改善がなされています。今回のProduce API v3では：\nカスタムヘッダーの追加 (トレーシングID、等) KeyとValueで異なるシリアライザの設定 が可能となります。 Bidirectional Cluster Linking 双方向のCluster Linkingの設定が可能となりました。これまでも一方向のリンクを2本貼れば実際のレプリケーションを双方向にすることは可能でした。Consuemr観点ではローカルのTopicとMirror Topicそれぞれ個別のTopicを同時にConsumeするモデルであり、それぞれへのOffset Commitを実行します。この際、Mirror TopicへのOffset CommitはソースとなるTopicには反映されないので、障害時には部分的なConsumer Offset情報しか連携されていない状況となります。 双方向のCluster Linkingは双方向へのリンクが1セットとして扱われる為、双方のクラスタでのOffset Commit情報も合わせて同期されます。 参考 Introducing Confluent Platform 7.5 (Confluent Blog) Confluent Platform 7.5 Release Notes REST Proxy Single Sign-On (SSO) for Confluent Control Center Cluster Linking - Bidirectional Mode ","date":169344e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":169344e4,"objectID":"5d6bcee8993895824dff6252a9be1f8f","permalink":"https://confluent-jp.github.io/community/blog/confluent-platform-7.5-announcement/","publishdate":"2023-08-31T00:00:00Z","relpermalink":"/community/blog/confluent-platform-7.5-announcement/","section":"blog","summary":"Apache Kafka 3.5、双方向Cluster Linking、REST Proxy Producer API v3、Control CenterのOpenID Connectアクセス、などなど。","tags":["Cluster Linking","Control Cluster","OpenID Connect","REST Proxy"],"title":"Confluent Platform 7.5リリース","type":"blog"},{"authors":["stanislav","hashi"],"categories":["Kafka Core","Blog"],"content":" このブログエントリはKafkaコミッタである Stanislav Kozlovski(𝕏|Ln) のサイトで2018/10/31に公開されたApache Kafka’s Distributed System Firefighter — The Controller Brokerの日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。\nはじめに Kafkaは成長を続ける分散ストリーミング基盤です。現時点での業界デファクト技術であり、広がるデータパイプラインの利用に対しても拡張しつつ安定的に稼働することが出来ます。もしKafkaの概要についてもう少し知りたい方はA Thorough Introduction To Apache Kafkaをご覧ください。\nこの記事を書く中で、このKafkaの安定稼働を支える中の仕組みについて書きたいと思うようになりました。\nこのエントリではKafkaにおけるControllerの概念 - Kafkaという分散基盤を健康的に稼働し続ける使命を支える機能についてご紹介します。\nController Broker 分散システムは常に協調の中で稼働し続ける必要があります。何かしらのイベントがクラスタで発生した場合、クラスタ内のコンポーネントは同調してそれに反応しなければいけません。その中で、クラスタとしてどう反応するべきなのか、Brokerは何をすべきなのかを指示する存在が必要です。\nその役割を担うのがControllerです。 Controller自身は複雑な仕組みではありません - ControllerもBrokerであり、通常のBrokerとしての役割と合わせて追加の役割も持つBrokerです。つまりController BrokerもPartitionを制御し、ReadとWriteのリクエストに対応し、裏ではレプリケーションに参加します。\n今追加の役割の中で最も重要なのは、クラスタ内のBrokerノードの管理であり、Brokerが追加、クラスタから離脱、もしくは障害が発生した際に適切にそのメンバーシップを管理することです。これにはPartitionのリバランスや新たなPartion Leaderの特定も含まれます。\nKafkaクラスタにはControllerが常に稼働し、唯一1つのControllerのみ稼働します。1\nControllerの役割 Controller Brokerは複数の複数を担います。Topicの作成/削除、Partitionの追加 (とLeaderの特定)、BrokerがClusterを離脱した際の諸々の制御等様々ありますが、基本的にはクラスタにおける管理者として振る舞います。\nBrokerノードの離脱 エラーや計画的な停止によってBrokerノードがクラスタから離脱した際、そのBrokerノードにLeaderのあったPartitionにはアクセス出来なくなります。 (クライアントはWrite/Readのいずれであっても常にPartition Leaderにのみアクセスします。2) この為Broker離脱時のダウンタイムを短縮するには、いかに迅速に新たなLeaderを選出するかが重要になります。\nController Brokerは他のBrokerノードが離脱した際に対処します。ZookeeperにはZookeeper Watchと呼ばれる特定データの変更時に登録者に対して通知をする機能で、ControllerはこのZookeeper Watchを利用してBrokerの離脱を検知します。Zookeeper WatchはBroker離脱時のトリガーとして働くKafkaにとって非常に重要な機能です。\nここにおける「特定データ」とはBrokerデータの集合です。\n下にあるのはBroker 2のZookeeper Sessionが無効化される事によりBroker 2のIDがリストから削除された場合の図解です。(Kafka BrokerはZookeeperへのハートビートを送り続けるが、遅れなくなるとセッションが無効化する)\nControllerはこのBroker離脱の通知を受け取り作業に取り掛かりますが、まずはBrokerの離脱によって影響を受けたPartitionの新たなLeaderを決定します。この後、クラスタ内の全てのBrokerに対して通知し、このリクエストを受け取った各Partition毎にLeaderになったりFollowerとしてLeaderにLeaderAndIsrリクエストを送付します。\nBrokerノードのクラスタ復帰 適切なPartition Leaderの配置はKafkaクラスタの負荷分散の上で重要な要素です。上記で説明したとおり、Brokerノードがクラスタを離脱した際には他のBrokerが代わって対応する必要があります。この場合Brokerは当初の想定以上のPartitionを各々が担うことになり、クラスタ全体の健全性やパフォーマンスに少なからず影響を及ぼします。当然なるべく早くバランスを取り戻す必要があります。\nKafkaは元々のPartitionアサインメントが、ある程度「適切」であるという想定を持っています。このアサインメントにおけるPartition Leaderはいわゆる Preferreed Leader(優先リーダー) として認識され、最初にそのPartitionが追加された時のPartition Leaderを指します。合わせてKafkaはインフラ構成としてのラックやAvailability Zoneを意識したPartition配置の機能 (ラック/AZ障害耐性を確保する為にLeaderとFollowerを別のラック/AZに配置する) もサポートしており、Partition Leaderの配置はクラスタの信頼性に大きく寄与しています。\nデフォルトではauto.leader.rebalance.enabled=trueとなっており、KafkaはPreferred Leaderが存在し、かつ実際のPartition Leaderではない場合にはPreferred Leaderを再選出します。\nBrokerノードのクラスタからの離脱も、多くの場合一時的であり、ある一定時間経過後に離脱したBrokerノードは再度クラスタメンバーとして復帰します。この為Brokerノードが離脱した際にも関連するメタデータは即座に削除されず、Follower Partitionも新たにアサインされません。\n注意点として、再参加したBrokerノードも直ぐにPartition Leaderとして再選出される訳ではなく、その候補となる為には別の条件も必要となります。\nIn-Sync Replicas In-Sync Replica (ISR) は状態がPartition Leaderと同じ Followerを指します。言い方を変えると、ISRはそのLeaderのレプリケーションが追いついている状態にあります。Partion LeaderはどのFollowerがISRでどのFollowerがそうではないかをトラックする必要があり、その状態はZookeeperに永続化されます。\nKafkaの障害耐性と可用性の保証はデータのレプリケーションに基づいており、kafkaが機能するには常に十分なISRが確保されているかが極めて重要です。\nFollowerがLeaderに昇格するにはまずISRである必要があります。全てのPartitionにはISRのリストがあり、Partition LeaderとControllerによって管理されています。ISRから新たなPartition Leaderを選出する処理は Clean Leader Election と呼ばれています。一方ユーザーにはこれとは異なる方法でLeaderを昇格させる事も可能で、Partion Leaderがクラスタを離脱した際にはISRではないFollowerを昇格させる事も可能です。これはLeaderもISRも存在しないという状況において、データ整合性より可用性を優先させる必要がある稀なケースです。\nここで再度の確認になりますが、クライアントはPartition LeaderからしかConsumeできません。仮にISRではないFollowerをLeaderに昇格した場合には、当然まだLeaderから取得されていなかったメッセージは失うことになります。これはメッセージを失うだけでなく、Consumerから見たイベントのストリーム上の位置 (オフセット) も上書かれます。\n残念ながらClearn Leader Electionの場合にも同様のデータ障害が発生する可能性はあります。ISRも様々な要因によってLeaderと完全に同期が取れていないケースです - 具体的には、Leaderのオフセットが100とした時に、Followerのオフセットが95、99、80となっているような状況です。レプリケーションは非同期に実施される為、最後のメッセージまで完全にFollower側に渡ったと保証する事は困難です。\nFollowerがLeaderに対してin-syncであると判断する条件は以下です：\nPartition Leaderから最新のメッセージを X ミリ秒前に取得している。 (Xは replica.lag.time.max.msにて設定可能) Zookeeperに対して Y ミリ秒前にハートビートを送っている。 (Yはzookeeper.session.timeout.msにて設定可能) データ整合性と耐久性 Leaderが機能不全に陥った場合、状況によってはISRが新しいLeaderに昇格した場合にも僅かにメッセージを失う可能性がある点について言及しました。具体的にはLeaderがFollowerからのフェッチリクエストを処理し終わった直後に新たにメッセージを受け取ったケースで、この場合新たなメッセージはまだFollowerがメッセージの到着を把握するまでの空白期間が存在し得ます。このタイミングでLeaderが機能不全に陥った場合、メッセージはLeaderにしか存在しないながらもFollowerの一部はISRとして成立します。そしてISRがそのままLeaderに昇格する可能性があります。\nProduer側のAcksの設定 上記の例ではLeaderは自身への書き込みが完了した時点でAcksを返す設定 (acks=1) を想定しています。Broker 1が最後のAcksを返した直後に機能不全となった為、Broker 2はISRではあるもののoffset:100のメッセージは受け取っていない状態でLeaderに昇格しています。\nこの事象はacks=allと設定することにより回避する事は可能で、つまりLeaderは全てのISRへの書き込みが正常終了した時点で初めてacksを返します。残念ながらこの設定の場合クラスタ全体のスループットには影響します。Kafkaのレプリケーションはpullモデルである為、Leaderは全てのISRのフェッチリクエストが届き、またそれが完了するまで待たなければいけません。\nいくつかのユースケースでは、パフォーマンスを優先してacks=1とする場合もあります。\nacks=allと設定した場合にメッセージの欠損は回避出来ます。新たにLeaderとなったISRには無いメッセージを既に取得したConsumerが出る可能性もありません。Producerからのacksを元にデータの整合性は保たれます。\nHigh Watermark Offset Leaderは全てのISRへのレプリケーションが完了しない限りacksを返さないとします。この際Brokerは high watermark offset と呼ばれる「全てのISRが取得済みの最大のオフセット」を管理しています。Leaderは合わ …","date":1692576e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692576e3,"objectID":"7e5a028347961b52f3ddea7ae7ee9f12","permalink":"https://confluent-jp.github.io/community/blog/kafka-controller-broker-explained/","publishdate":"2023-08-21T00:00:00Z","relpermalink":"/community/blog/kafka-controller-broker-explained/","section":"blog","summary":"分散ストリーミング基盤に起こるカオスを水際で抑えるController Brokerの仕組み by Kafkaコミッタ。","tags":["Translated"],"title":"解剖 Kafka Controller Broker","type":"blog"},{"authors":["hashi"],"categories":["Blog","Cluster Linking"],"content":"クラスタ間のレプリケーション - 一般的なアプローチ クラスタ間でデータのレプリケーションのニーズは古くからあり、DRや組織内のグループ会社間/事業部間の部分的なデータ共有、またはUberさんのActive-Active双方向レプリケーションの様な使い方もあります。いずれにせよ、何かしらの形でKafkaクラスタから他のクラスタにデータをレプリケートするという手法は変わらず、また利用できるツールも (多少の機能差異はありながらも) 基本的に同じアプローチを取っています。 基本的なアプローチはどのレプリケーションツールでも同じで、Producer/Consumerの両方を司るKafka Connectコネクタとして稼働します。SourceクラスタのTopicからConsumeし、DestinationクラスタのTopicにProduceする、理解し易いアプローチだと思います。当然SourceとDestinationのTopicは別々のものなのでPartition数を変える事も出来ますし、一般的なコネクタ同様SMTを利用する事も出来ます。\n同時に、Kafkaクラスタの外で双方にアクセス出来るコンポーネントを別途運用する必要性もあります。レプリケーションツールとKafkaブローカー間にはペイロードの圧縮/解凍処理を挟み、独立したConsume/Produce処理となる為レイテンシも比較的高くなります。またKafkaクラスタ同士がお互いを認識している訳ではなく、それぞれのクラスタに存在するTopic同士も機械的な関連性はありません。当然双方のTopicのConsumer Offsetは全く独立して管理されている為、TopicにアクセスするConsumerをクラスタを跨いで移動させる場合には、何かしらの方法でConsumer Offsetを変換する必要性も発生します。\nCluser Linking - クラスタを跨いだReplica Fetching Confluent Cluster Linkingのアプローチは大きく異なります。結果としてConsumer Offsetを含め全てのTopicに関するメタデータを完全に同期した状態でデータのレプリケーションが可能です。 仕組みとしては、同一クラスタ内におけるKafkaのレプリケーションの仕組みに近く、Replica Fetcherと近い形でDestinationクラスタにあるBrokerがクラスタ境界を跨いでフェッチする形でレプリケーションを行います。処理を仲介するものも、ワークロードの何かしらの受け渡しの様な処理も無いため、スループットも高く、また低レイテンシなレプリケーションが可能です。\n当然仲介用のConnectクラスタ等別途立ち上げる必要はありません。リンクの設置も、SourceもしくはDestinationクラスタであるConfluent CloudもしくはPlatformに対してリンク作成コマンドを実行すれば完了します。\n特徴と注意点 先にメリットについては記載しましたが、非同期レプリケーションではありながらSourceとDestinationのデータ差 (オフセット) がこれまでのアプローチよりかなり小さく、また安定的に同期出来るので、DR等の適用時において復旧/欠損対象となるデータ量を限定する事が出来ます。メタデータごと完全に同期しているのでクラスタ間のデータギャップやその復旧時の運用負荷も下がります。フェイルオーバーを考えると、Cluster Linkingを利用した場合にはオペレーションをかなり簡素化出来るのが特徴です。\n注意点 1 - 障害時にデータの欠損は起こり得る Cluster LinkingはMirrorMaker2等と比べると、確かに低レイテンシでデータの同期が可能です。しかしながらあくまで同期ではなく非同期のレプリケーションである為、RPO (Recovery Point Objective: 目標復旧地点) は0ではありません。Sourceクラスタにおいて、「書き込み完了と判断された後」かつ「その変更がDestinationクラスタ側からフェッチされるまで」にSourceクラスタがダウンしてしまう可能性はあり、この条件に合致する差分はSourceが再度復旧出来るまでアクセス出来ません。\n注意点 2 - TopicはPartition数を含め完全一致 DestinationクラスタにレプリケートされたTopicはMirror Topicと呼ばれる少し特殊なTopicです。具体的には：\n全Partitionのイベント数、イベント順序、各イベントのデータが全てSource Topicと全く同じとなる。 Read OnlyでありDestinationクラスタ内から書き込み不可。1 となります。 この為、例えばSourceクラスタのTopicからSMTを使って特定フィールドをマスキングしたり、Sourceと異なるPartition数をDestinationで指定する事は出来ません。\n注意点 3 - フェイルオーバー後の復旧はフェイルフォワードを推奨 Cluster LinkingではDR時にフェイルオーバーした際、基本的にDRであったクラスタを今度は本番と位置付けるようコマンドが整備されています。例えば東京リージョン (Prod) から大阪リージョン (DR) へのフェイルオーバー時に、大阪が本番リージョンとして機能します。その後東京リージョンが復旧した場合、フェイルバックするのではなく今度は東京をDRとして継続オペレーションを実施することを推奨しています。\nおわりに 上記に注意点を幾つか並べましたが、どれもCluster Linkingの欠点と言うよりは特性であり、つまりこの特性を充分理解した上でレプリケーション戦略を立てる事が大事です。\n注意点 1 - これは非同期レプリケーションである限り避けようがありません。逆に、非同期なのでSourceクラスタに対する書き込みレイテンシには影響を与えないメリットもあります。 注意点 2 - 通常のReplica Fetcherの仕組みと近いと考えると当然で、バイトレベルで同一のデータをDestinationクラスタ上に持てるというメリットを考えると納得出来る制約だと思います。 注意点 3 - これは意見が分かれるところかも知れません。データ基盤全体におけるBC戦略はKafkaのみのルールで決めれるものでは無いので、許容出来ないユースケースは多いと思います。ただ作業の手間が増えるだけで、フェイルバックする事は不可能ではありません。 他にも場合によってはMirrorMaker2やConfluent Replicatorの方が理に適った選択肢であるケースはあり、実際にもCluster LinkingではなくConfluent Replicatorを採用されるユーザーもいます。確かにCluster Linkingは画期的なレプリケーション機能ではありますが、その特性を理解した上で採用を判断する事が (何事に言える事ですが) 重要です。\n当然DR時にはMirror Topicを元にオペレーションを再開するので、その際はkafka-mirrors --failoverコマンドで書き込み出来るよう切り替えます。 ↩︎\n","date":1692057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692057600,"objectID":"d38329ae8f04fbf37cf3251d02b60473","permalink":"https://confluent-jp.github.io/community/blog/cluster-linking-demystified/","publishdate":"2023-08-15T00:00:00Z","relpermalink":"/community/blog/cluster-linking-demystified/","section":"blog","summary":"クラスタ間レプリケーションの新たなアプローチとその有効性について。","tags":["Replication","High Availability"],"title":"Confluent Cluster Linkingの仕組みについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"Tiered Storageとは 今年の後半にリリースが予定されているApache Kafka 3.6には、Tiered Storageと呼ばれるKafkaコミュニティが待ち望んだ新機能が含まれる予定です。この機能はKIP-405として何年も前に登録されたKIPであり、長い期間をかけてようやくリリース目処が経ちました。\nこれまでKafkaのデータは常にBrokerのストレージに格納されていましたが、これを二層化して古いセグメントを自動的に退避するという機能です。Kafkaに格納されたイベントをオブジェクトストレージに退避するというプラクティスは一般的であり、これまではKafka Connectコネクタを使って自分で退避させるアプローチを取っていました。これをKafkaネイティブな機能として提供する、その役割をKafka Brokerが行うというものです。クライアントからはこのオペレーションは隠蔽化されており、新しいイベントも古いイベントも同じアプローチでアクセスする事が出来ます。\nTiered Storageの動き - 図解 これまで通り、クライアントから送られたイベントはkafka Brokerのストレージにセグメント単位で保存されます。セグメントはログファイルであり、ランダムアクセスではなくアペンドでしかデータを足せない為、最も新しいセグメント (Active Segmentと呼ばれます) 以外のファイルは不可変 (Immutable) です。\nTiered Storageはこのうち古いセグメントを自動的にオブジェクトストレージに退避します。 中では新しくRemoteLogManagerと呼ばれるプロセスが、これまでのLogManagerに近い役割を果たしつつリモートストレージにコピーし、合わせてリモートストレージのインデックス状態のキャッシュを保持します。\n上にあるように、Broker側の保全期間 (Retention Period) を超過しセグメントが削除された後も、リモートストレージにはそのコピーが残ります。ストレージの動きはこれだけで、リモートからローカルにセグメントが戻ってくる様な事はありません。これまでのLog Managerの役割もそのままで、ローカルのログは今まで通り管理されます。\nほとんどのユースケースでは、クライアントは最新のセグメントに集中してアクセスします。 書き込みは当然最新であるActive Segmentにしか発生しませんが、読み込みも多少のラグはありながらもほぼ最新に近いセグメントへのアクセスとなります。このアクセスはこれまでと何も変わらず、今まで通りBrokerがディスクI/O経由でデータを取得しクライアントに帰します。\n違いは、クライアントが古いセグメントにあるオフセットを指定して読み込みをリクエストした場合です。 既にBrokerのローカルストレージにはセグメントは存在しませんが、リモートストレージに存在する限りBrokerはデータを取得しクライアントに返すことが出来ます。\nメリット 1 - 拡張性 (Scalability) Kafkaは拡張性に極めて優れたストリーミングプラットフォームであり、原則Brokerノードを追加することにより水平スケールする事ができます。一方、拡張には限界があります。一般的に大規模Kafkaクラスタにおけるボトルネックはネットワーク帯域で、次にストレージと言われています。これらを充分確保出来続ける限りKafkaクラスタは相当規模まで拡張出来ます。Tiered Storageによってストレージ容量の削減とより高度なコントロールが可能になります。\nKafkaにとってそれぞれのTopicの保全期間 (Retention Period) と書き込みスループットは基本的にはバランスゲームです - 高書き込みスループットの場合はストレージ容量の増加を加味してより短い保全期間を指定する必要があります。保全期間のデフォルトでは1週間、通常運用では1日という場合も多くありますが、高負荷のクラスタでは数時間程度に留める事も多くあります。\nkafkaは内部でデータのレプリケーションを行なっています。Replication Factorと呼ばれるこの設定のデフォルトは3であり、稀に金融やストレッチクラスタ (複数のサイトに跨がる大きなクラスタ) では4を指定する場合もありますが、ほとんどデフォルトのままではないかと思います。いずれにせよ、その指定分だけデータはレプリケートされるので、必要ディスク容量は増えます。\n例えば100MBpsで書き込みがなされる場合、レプリケーションも考慮するとクラスタ内のネットワーク帯域には300MBps、当然ストレージにも300MBpsのスピードで消費します。保全期間を1日とした場合、100 * 3600 * 3 = 1,080,000MB ≒ 1TBのストレージ容量が必要となります。書き込みスループットが倍になればストレージも倍、当然保全期間を倍にしてもストレージは倍必要になります。\nストレージがボトルネックになった場合、ディスクを足せば解消しますが、それも限界を超えるとBroker自体を追加する必要が出てきます。Tiered Storageを導入すると、Brokerが必要とするストレージの絶対量を制限できます。同一ハード構成におけるキャパシティを上げ、将来的な拡張性も高く出来ます。\nメリット 2 - 障害耐性 (Resiliency) ストレージを分離する事によって障害耐性が上がるというのはピンと来ないかも知れませんが、Tiered Stoargeによる効果と期待は障害耐性の向上にも集まっています。\nKafkaが何事もなく稼働している限り、またデータが適切にパーティションされている限り、Kafkaクラスタは均一にデータを分散配置し管理出来ます。しかしBrokerのシャットダウンと復帰は必ず発生します。時としてハードやソフトの障害によって、他ではBroker/JVM/Guest OS/Host OS/Host Hardwareのアップグレードによって、クラスタ構成は短期/長期的にその構成が変わります - Kafkaは絶えずメンバーシップを変えつつ稼働し続ける分散システムであり、構成が変わる前提の上で成立している技術です。\nBrokerがクラスタメンバーから外れると、それまでそのBrokerで保全していたデータは必ず何かしらの方法で他のBrokerに再配置されなければデータの保全性が保てません。この為クラスタメンバーシップの変更は、大規模なメタデータの更新と、データの移動を意味します。\nTiered Storageによって管理/移動対象となるセグメントの物理的な数が減れば、その分クラスタ内で移動するデータ量が減少し、また大量メタデータ更新に伴う二次災害の危険性も減少し、結果としてより安全に、より短い期間にクラスタが正常状態に復帰します。Kafkaクラスタ自体が軽量になればなるだけ、例えばコンテナの様により頻繁に刷新されるランタイム上でKafkaを運用する場合にも大きなメリットとなります。\nメリット 3 - リソースの有効活用 (Resource Utilization) Kafkaとは基本的にディスクI/Oへの負荷が高いプラットフォームです。これは書き込み/読み込みの発生頻度が高く、またディスクI/Oの有効利用が今回の設計思想に織り込まれています。併せて、Kafkaは原則マルチテナントプラットフォームであり、様々なワークロードが共存し易い (各々のワークロードの影響を受けにくい) ストリーミング基盤です。しかしながらKafkaにも物理的な制約は存在し、ワークロードのニーズ的にはクラスタ自体を分ける事も実際には多くあります。1\nTiered Storageへのアクセスは、Kafkaでは珍しくディスクI/OではなくネットワークI/Oへの比重が高い処理となります。例えば長期間実行するバッチ処理 (古いデータなのでTiered Storage経由) と、超低レイテンシな処理が求められるオンライン処理 (新しいデータなのでBrokerから) とではKafkaかかるリソース負荷が全く異なります。これら特性を上手く利用すれば、オンライン処理を実行しながら低負荷でバッチ処理を同一クラスタ内で扱う事も出来ます。2\nおわりに Tiered StorageはApache Pulserの様なコンピュートとストレージを完全に切り離す目的で導入される訳ではありません。Kafkaはある意味意図的に原始的な設計をしている点が長所であり、時として短所となり得る技術です。Tiered StoargeはKafkaが本来持つ高スループットかつ低遅延な処理能力を殺す事なく、短所であるディスク容量やディスクI/Oというボトルネックを軽減させ得る可能性を持った非常に有望な機能です。併せて、よりクラウドネイティブな環境で動く機会の増えたKafkaにとって、その新しい環境により適合性の高い機能であるとも言えます。\n例えば長期実行されるバッチ処理が継続してKafkaにアクセスしている状態で、非常にレイテンシ要件の高いオンライン処理が同居する様な場合です。 ↩︎\n当然、充分なネットワーク帯域が確保されている場合には、という条件は付きます。 ↩︎\n","date":169128e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":169128e4,"objectID":"68408a092777b66631fb8e9e96356bf1","permalink":"https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/","publishdate":"2023-08-06T00:00:00Z","relpermalink":"/community/blog/kip405-why-tiered-storage-important/","section":"blog","summary":"単純にストレージを分割するだけでない、Tiered Storageが見据える新しいKafkaと将来について。","tags":["Storage","High Availability","KIP"],"title":"Tiered Storageは何故そんなに重要なのか？","type":"blog"},{"authors":["stanislav","hashi"],"categories":["Kafka Core","Blog"],"content":" このブログエントリはKafkaコミッタである Stanislav Kozlovski(𝕏|Ln) のサイトで2022/11/06に公開されたKafka Acks Explainedの日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。\nKafkaに関する仕事を始めて4年になりますが、経験上未だに2つの設定について広く誤解されていると感じる事があります。それはacksとmin.insync.replicasであり、さらにはこの2つの設定がどう影響し合うかについてです。このエントリはこの非常に重要な2つの誤解を解き、適切に理解してもらう事を目的としています。\nReplication この2つの設定を理解するためにはまずKafka Replicationプロトコルについて少しおさらいする必要があります。\nこのブログの読者の皆さんはある程度Kafkaについてご存知だと想定しています - もし自信がない場合はぜひThorough Introduction to Apache Kafkaもご参照ください。\n各Partitionには1つのLeader Broker(1)と複数のFollower Broker(N)がアサインされます。この複製の数はreplication.factorで設定する事ができ(1+N)つまり総数を表します。つまりこの設定では「対象となるPartitionに対してクラスタ上で何個の複製が出来るか」を指定します。\nデフォルトであり通常推奨する設定値は3です。 ProducerクライアントはLeader Brokerにのみ書き込みに行きます - つまりFollower Brokerへのレプリケーションは非同期に行われます。ここで分散システムとして考慮しないといけないのは、何かしらの方法で「これらレプリケーションされる処理がどのようにLeaderに追従すべきか」を指定する方法です。具体的には「Leaderに書き込まれた更新がFollowerにも反映されているか否か」です。\nIn-Sync Replicas in-sync replica(ISR)は対象Partitionの最新状態と同期が取れているBrokerを指します。当然Leaderは常にISRとなり、Followerの場合はLeaderの更新に追い付き同期が取れた状態のもののみISRとなります。仮にFollowerがLeaderに追従できなくなった場合、そのFollowerはISRではなくなります。 上の図ではBroker 3は同期されていないのでISRではない、つまりout-of-syncとなります。\nちなみに、厳密にはISRか否かという判断はもう少し複雑で、ここで説明されているようにすんなり「このFollowerは最新の状態か」と判断出来る訳ではありません。ただ厳密な話をし始めるとこのエントリの主旨から外れるので、ここでは上の図にある赤いBrokerは同期が取れていないと、見たまま捉えてください。\nAcks Acksはクライアント (Producer) 側の設定で、「どこまでFollowを含めて書き込みの確認が取れてからクライアントに返答するか」を指定するものです。有効な値は0、1、そしてallの3つです。\nacks=0 0が設定された場合、クライアントはBrokerまで到達したかの確認さえ行いません - メッセージがKafka Brokerに対して送られたタイミングでackを返します。 ackと呼びますがBrokerからの返答さえ待ちません。送れたらOKです。\nacks=1 1が設定された場合、クライアント (Producer) はLeaderにまでメッセージが到達した時点で書き込みの完了と判断します。Leader Brokerはメッセージを受け取った時点でレスポンスを返します。 クライアントはレスポンスが返ってくるのを待ちます。Leaderからの返答が到着した時点で完了と判断しackとします。Leaderは受け取り次第レスポンスを返すので、Followerへのレプリケーションはレスポンスとは非同期に処理されます。\nacks=all allと設定された場合、クライアントは全てのISRにメッセージが到達した時点で書き込みの完了と判断します。この際Leader BrokerがKafka側の書き込み判定を行なっており、全てのISRへのメッセージ到達の上クライアントにレスポンスを返します。 上の図の状態ではBroker 3はまだメッセージを受け取っていません。この為Leaderはレスポンスを返しません。 全てのISRに渡って初めてレスポンスが返されます。\nacksの機能性 この通りacksはパフォーマンスとデータ欠損耐性のバランスを決める非常に有益な設定です。データ保全を優先するのであればacks=allの設定が適切です。1 一方レイテンシやスループットに関する要件が極めて高い場合には0に設定すれば最も効率が良くなりますが、同時にメッセージロスの可能性は高まります。\nMinimum In-Sync Replicas acks=allの設定に関して、もう一つ重要な要素があります。\n例えばLeaderが全てのISRへの書き込み完了した上でレスポンスを返すとして、LeaderのみがISRだった場合、結果としてacks=1と振る舞いは同じとなるのでしょうか？\nここでmin.insync.replicasの設定が重要になります。\nmin.insync.replicasというBroker側の設定は、acks=allの際に「最低いくつのISRとなっているか (Leaderを含めて幾つのレプリカが最新状態か) を指定するものです。つまりLeaderは、acks=allのリクエストに対して指定されたISRに満たないまでは返答せず、またそれが何かしらの理由で達成できない場合にはエラーを返します。データ保全観点でのゲートキーバーの様な役割を果たします。\n上記の状態だとBroker 3は同期されていない状態です。しかしながらmin.insync.replicas=2となっている場合には条件を満たす為この時点でレスポンスが返されます。\nBroker 2と3が同期されていない状態です。この場合指定されたmin.insync.replicasを下回るためLeaderからはエラーレスポンスが返る、つまり書き込みは失敗します。一方同じ状況であってもacksの設定が0もしくは1の場合には正常なレスポンスが返されます。\n注意点 一般的にmin.insync.replicasは「Leaderがクライアントに返答する際に、どれだけレプリケーションが完了しているかを指定する」と解釈されていますが、これは誤りです。正確には「リクエストを処理する為に最低いくつのレプリカが存在するか」を指定する設定です。 上記の場合、Broker 1から3までが全て同期状態です。この時に新たなリクエスト (ここではメッセージ6) を受け取った場合、Broker 2への同期が完了してもレスポンスは返しません。この場合、処理時にISRとなっているBroker 3への同期が完了して初めてレスポンスが返されます。\nまとめ 図で説明したことによって理解が深まったのではないかと思います。\nおさらいすると、acksとmin.insync.replicasはKafkaへの書き込みにおける欠損体制を指定する事ができます。\nacks=0 - 書き込みはクライアントがLeaderにメッセージを送った時点で成功とみなします。Leaderからのレスポンスを待つことはしません。 acks=1 - 書き込みはLeaderへの書き込みが完了した時点で成功とみなします。 acks=all - 書き込みはISR全てへの書き込みが完了した時点で成功とみなします。ISRがmin.insync.replicasを下回る場合には処理されません。 その他情報 Kafkaは複雑な分散システムであり、学ばなければいけない事が多いのも事実です。Kafkaの他の重要な要素については以下も参考にしてください。\nKafka consumer data-access semantics - クライアント (Consumer) における欠損耐性、可用性、データ整合性の確保に関わる詳細。 Kafka controller - Broker間の連携がどの様になされるのかの詳細。特にレプリカが非同期 (Out-of-Sync) となるのはどういう条件下かについて説明しています。 “99th Percentile Latency at Scale with Apache Kafka - Kafkaのパフォーマンスに関するConfluent Blogエントリ。 Kafka Summit SF 2019 videos Confluent blog - Kafkaに関する様々なトピックを網羅。 Kafka documentation Kafkaは継続的かつアクティブに開発されていますが、機能追加や改善は活発なコミュニティにより支えられています。開発の最前線で何が起こっているか興味がある場合はぜひメーリングリスト に参加してください。\nこのエントリの著者であるStanislav Kozlovski は2 Minute StreamingというKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。\n(訳者注)ほとんどのユースケースではacks=allが適切であり、Kafkaのデフォルトでもあります。 ↩︎\n","date":1690848e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848e3,"objectID":"29d13f61167d64758e7d240fbb183dfa","permalink":"https://confluent-jp.github.io/community/blog/kafka-acks-explained/","publishdate":"2023-08-01T00:00:00Z","relpermalink":"/community/blog/kafka-acks-explained/","section":"blog","summary":"KafkaのAcksを完全に理解する by Kafkaコミッタ。","tags":["Kafka Client","Translated"],"title":"Kafka Acks再入門","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Streaming AudioはConfluentがPodcast\u0026amp;YouTubeシリーズとして提供しています。毎回ゲストを迎え様々なトピックについてフリーにディスカッションするポッドキャストで、Kafka初期開発メンバーのJun RaoやKRaftの開発メンバー、Kafkaのリアルユーザー等様々なゲストスピーカーが参加します。中でも「アナネキ」ことAnna McDonald (Technical Voice of CUstomer @Confluent)登場回は毎回必見で、いつも何か新しい発見があります。\n今回はその彼女の登場回の中でも最も最近の回のご紹介です：お題は「Kafkaに本当にあったヤバいバグ5選1」です。(オリジナルの公開は2022/12/21) このトークで紹介されたJIRAバグの一覧を用意しました。結構最近になってようやく入ったものや、まだ直っていないものもあります。Kafkaのバージョンはなるべく追従する事を強くお勧めしていますが、ここにあるのは全体の一部で、なかなかに怖いバグへの修正も入っています。\nあなたのKafkaクラスタはほんとに大丈夫です？\nKAFKA-10888: Sticky partition leads to uneven product msg, resulting in abnormal delays in some partitions Status: Resolved (3.0.0)\nSticky Partitionerを使用時、Partition間の処理数に大きな偏りが出る様な状況となり特定のPartitionのスループットが極端に下がる事がある: 場合によってはリカバリ不能なほどProducer側のバッチが肥大化する。\nKAFKA-9648: Add configuration to adjust listen backlog size for Acceptor Status: Resolved (3.2.0)\nOSがLinuxの場合に発生。ローリングアップグレード等の際、BrokerからPartition Leaderが他のBrokerに移る、もしくは移ったのちに元のBrokerに戻る (Preferred Leader Election) が発生。この際Partitionに関するメタデータ更新が行われる為これらPartitionを参照するクライアントから一斉に再接続のリクエストが送られる。状況によってはLinuxのSYN cookieの機能が動きTCPバッファーが制限されスループットが大幅に低下する。これは再接続しない限り復旧しない。\nKAFKA-12686: Race condition in AlterIsr response handling Status: Resolved (3.0.0)\nPartition.scala内の処理において、AlterIsrResponseとLeaderAndIsrRequestのレースコンディションが起因。クラスタサイズが小さくPartition数が多い場合、Brokerノードの変更時に大量のPartition変更が発生する。この際AlterIsrManagerがペンディング状態のリクエストをクリアしてしまう為、AlterIsrResponseが戻ってきた際に処理中 (in Flight) であるのに処理タスク (Pending) が無いという矛盾状態が発生する。\nKAFKA-12964: Corrupt segment recovery can delete new producer state snapshots Status: Resolved (3.0.0)\nBrokerの停止時、猶予時間内に終了しない場合には Unclearn Shutdownと判断される。この際Broker復帰時に残っていたセグメントは不要と判断され非同期で削除が実行される。この削除が完了する前に同じオフセットのセグメントが書き込まれる状態となると、新しいProducer Stateスナップショットが誤って削除される事がある。\nKAFKA-14334: DelayedFetch purgatory not completed when appending as follower Status: Resolved (3.4.0, 3.3.2)\nConsumerがPulgatoryからフェッチするケースにおいて、通常通りPartitionリーダーからフェッチする場合には正しくフェッチの完了が認識される。しかしConsumerがフォローワーがフェッチする設定としている(KIP-932)場合、フォローワーのPartitionはPulgatoryに存在しない為フェッチ出来ずタイムアウトする。\nオリジナルは6選であり、ここではそのうちKAFKA-9211: Kafka upgrade 2.3.0 may cause tcp delay ack(Congestion Control)も含んでいますが、トークの中ではKafka-9646の中で合わせて語られているので割愛しました。 ↩︎\n","date":1690588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690588800,"objectID":"bfc2a40b146c9eab46ad969b34c54bd4","permalink":"https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/","publishdate":"2023-07-29T00:00:00Z","relpermalink":"/community/blog/streaming-audio-worst-kafka-bugs/","section":"blog","summary":"Anna McDonaldによるKafkaのヤバいバグに関するトークです。日本語字幕でどうぞ。","tags":["Bugs"],"title":"Streaming Audio - Kafkaに本当にあった(まだある)ヤバいバグ5選","type":"blog"},{"authors":["kai","hashi"],"categories":["Blog","Use Cases"],"content":" このブログエントリはConfluent Field CTOであるKai Waeehnerのサイトで2022/1/4に公開された When NOT to use Apache Kafka?の日本語訳です。Kai本人の了承を得て翻訳/公開しています。\nApache Kafkaは、Data in Motionにおけるイベントストリーミングのデファクトスタンダードです。あらゆる業界でその採用が大きく伸びているため、私は毎週のように『ではApache Kafkaを使うべきでは無いのはどんな場合？』『ストリーム処理の基盤に重要な要素は？』『kafkaにこの機能性が無いのはなぜ？』『Kafkaを採用しないと判断する為の条件とは？』という質問を受けます。このブログ記事では、Kafkaを使うべき時、Kafkaを使うべきでない時、そしてKafkaを使うべきかもしれない時について順番に説明します。\n市場動向 - コネクテッド・ワールド まずは、なぜKafkaがいたるところで登場するのかを理解することから始めます。このことは、イベントストリーミングに対する市場の大きな需要を明らかにすると同時に、すべての問題を解決する銀の弾丸は存在しないことを示しています。Kafkaは繋がる世界 (コネクテッドワールド) の特効薬ではなく、重要なコンポーネントと捉える必要があります。\n世界はますます繋がりを広げています。膨大な量のデータが生成され、収益増加、コスト削減、リスク軽減のためにリアルタイムに関連付ける必要があります。この動きはどの業界でも進んでいますが、より速い業界もあれば遅い業界もあります。しかしこの繋がりはあらゆるところに届いています。製造業、スマートシティ、ゲーム 、小売、銀行、保険などどこでもです。私の過去のブログには、どの業界にも関連するKafkaの使用事例を見つけることができます。\n私はこのデータの急激な成長を、イノベーションと新しい最先端のユースケースの創出を示す2つのマーケットトレンドとして捉えています。(そしてKafkaの採用が業界を超えて急激である理由も併せて) 。\nコネクテッド・カー - 膨大な量のテレメトリデータとアフターセールス アライドマーケットリサーチの世界の機会分析と産業予測、2020-2027年 からの引用です: コネクテッドカー市場には、多くの人が考えているよりもはるかに幅広いユースケースと業界が含まれています。いくつか例を挙げると:ネットワークインフラとコネクティビティ、セキュリティ、エンターテインメント、小売、アフターマーケット、自動車保険、サードパーティデータ利用(スマートシティなど)。その他にも様々なユースケースが存在します。\nゲーミング - 数十億人のプレーヤーと巨額の収益 ゲーム産業はすでに他のすべてのメディア・カテゴリーを合わせたよりも大きくなっており、Bitkraftが描くように、これはまだ新しい時代の始まりに過ぎないとも言えます。 既に世界中で毎月何百万人もの新規プレイヤーがゲームコミュニティに参加しています。インターネットへの接続性と安価なスマートフォンは、それほど裕福でない国でも広く普及しています。 Play to Earnのような新しいビジネスモデルは、次世代のゲーマーのゲームの遊び方を変えており、5Gのような拡張性の高い低遅延技術が新たなユースケースを可能にしています。更にはブロックチェーンとNFT(Non-Fungible Token)は、マネタイズとコレクター市場を永遠に変えようとしています。\n業界を横断するこうした市場動向は、リアルタイムデータ処理のニーズが四半期ごとに大幅に増加している理由を明らかにしています。Apache Kafkaは分析およびトランザクションデータ ストリームを大規模に処理するためのデファクトスタンダードとしての地位を既に確立しています。しかしながら、Apache Kafkaとその周辺エコシステムの技術をプロジェクトで使用する(しない)タイミングを理解することも併せて非常に重要です。\nApache Kafkaとは何で、何では無いのか？ Kafkaは誤解されやすい技術です。例えばKafkaはメッセージキューだという話をいまだによく耳にします。その理由のひとつは、一部のベンダーが自社製品を売るために特定の問題(データレイクやデータウェアハウスへのデータ取り込みなど)に対してのみKafkaを売り込んでいるからだと思われます。\nKafkaは：\nスケーラブルなリアルタイム・メッセージング・プラットフォームで、毎秒数百万のメッセージを処理する。 大量のビッグデータ分析から少量のトランザクションデータ処理まで対応するイベント・ストリーミング・プラットフォーム。 分散ストレージは、背圧処理のための真のデカップリングを提供し、様々な通信プロトコルをサポートし、順序が保証されたイベントの再生可能性を提供する。 ストリーミングETLのためのデータ統合フレームワーク。 ステートレスまたはステートフルな連続ストリーム処理のためのデータ処理フレームワーク。 これら様々なユースケース/利用パターンを一つのプラットフォームで提供出来る点がKafkaの特徴です。\n一方以下はKafkaに当てはまりません：\n数百万を超えるクライアントからの直接接続 - Kafkaネイティブのプロキシ(RESTやMQTTなど)、いくつかのユースケースに対応しているが全てではない。 API管理プラットフォーム - これらのツールは通常補完的であり、Kafka APIの作成、ライフサイクル管理、または収益化のために使用される。 バッチ分析や複雑なクエリをサポートするDB - トランザクションクエリや比較的単純な集計(特にksqlDBを使用)では充分扱える。 デバイス管理を行うIoTプラットフォーム - MQTTやOPC-UAなどのIoTプロトコルとKafkaを直接統合することは可能であり、(一部の)ユースケースには適切なアプローチである。 ミリ秒レイテンシを達成するハード・リアルタイム・アプリケーションのための技術 (セーフティ・クリティカル・システムや決定論的システム) - ただ組み込みソフトウェアを除くと全てのプラットフォームが同様であり、Kafkaもその例外では無いというだけである。 このような理由から、Kafkaは他のテクノロジーと競合するものではなく、補完するものであると言えます。仕事に適したツールを選び、それらを組み合わせる上でKafkaは全体における重要な要素となり得ます。\nコネクテッドワールドにおけるApache Kafkaのケーススタディ ここではKafkaを他のテクノロジーと組み合わせることで、ビジネス上の問題を解決した素晴らしいサクセスストーリーの例をいくつか紹介します。エンドツーエンドのデータフローにKafka以上のものを必要とするケーススタディに焦点を当てています。\n私のブログ、Kafka Summitカンファレンス、MediumやDzoneのようなオンラインリソース、その他の技術関連のニュースなど、どれをフォローしても同じです。コネクテッドカー、IoTエッジデバイス、スマートフォンのゲーム/アプリなどからの大量のアナリティクスやトランザクショ・データをApache Kafkaでリアルタイム データストリー ミングする成功例をたくさん見つけることができます。\n業種や使用例をいくつか挙げてみます:\nAUDI - コネクテッドカー・プラットフォームが地域とクラウドプロバイダーを横断的に展開。 BMW - サプライチェーンとロジスティクスの最適化を実現するスマート工場。 SolarPower - 太陽光発電のソリューションとサービスを世界中で提供。 Royal Caribbian - エッジサービスとハイブリッド・クラウドの集約によるクルーズ船のエンターテイメント。 Disney+ Hotstar - インタラクティブなメディアコンテンツとゲーム/ベッティングをスマートフォンで数百万人のファンに提供。 このような素晴らしいIoTのサクセスストーリーにおいてKafkaは課題はあるかというと、問題無く非常に有機的に機能しています。しかしながら、Apache Kafkaエコシステムでイベントストリーミングを使用するタイミングと、他の補完的なソリューションを利用すべきかの判断について説明するためには、いくつか明確化が必要です。\nApache Kafkaを使うべき場合 Kafkaを使うべきでない場合について説明する前に、Kafkaを使うべき場所を理解し、必要に応じて他のテクノロジーと補完する方法とタイミングをより明確に説明します。ここから実例をユースケースごとに分けていくつかご紹介します。\nKafkaは大量のIoTやモバイルデータをリアルタイムかつ大量に扱う事ができる。 Teslaは単なる自動車メーカーではありません。Teslaは、革新的で最先端のソフトウェ アを数多く開発しているハイテク企業です。Teslaは自動車のためのエネルギーインフラも併せて提供しています。スーパーチャージャー、ギガファクトリーでの太陽エネルギー生産等も然りです。\n車両、スマートグリッド、工場からのデータを処理/分析し、残りのITバックエンドサービスとリアルタイムで統合することは、同社の成功に不可欠な要素です。\nTeslaはKafkaベースのデータプラットフォームインフラを構築し『1日あたり数百万台のデバイスと数兆のデータポイントをサポート』しています。テスラは2019年のKafka Summitで、彼らのKafka利用のな歴史とその進化について登壇しています。\n私はほとんどすべてのブログエントリでこのことを繰り返していますが、Kafkaは単なるメッセージングではないことを改めて強調させてください。Kafkaは分散ストレージレイヤーであり、プロデューサーとコンシューマーを真に分離し、さらにKafka StreamsやksqlDBのようなKafkaネイティブの処理ツールによってリアルタイム処理を可能にします。\nKafkaはIoTデータとMESやERPシステムからのトランザクションデータを結び付ける 規模の大きなリアルタイムでのデータ統合には、アナリティクスやERPやMESシステムのようなトランザクションシステムの利用に密接に関連しています。Kafka Connectやその他非Kafkaミドルウェアは、このタスクのためにイベントストリーミングのコアを補完する役割を果たします。\nBMWはエッジ(スマート工場など)とパブリッククラウドでミッションクリティカルなKafkaワークロードを運用しています。Kafkaはこれらシステムの疎結合性/透明性を高め活用によるイノベーションを可能にします。併せてConfluentの製品と専門知識により安定性を担保しています。後者は製造業での成功に不可欠です - 1分のダウンタイムによって組織に莫大なコストがかかリマス。関連記事Apache Kafka as Data Historian - an IIoT / Industry 4.0 Real-Time Data Lakeをご参照ください。Kafkaが製造業の総合設備効率(OEE)をどのように改善出来るか理解頂けると思います。\nBMWはリアルタイムでサプライチェーン管理を最適化しています。このソリューションは、物理的にもBMWのERP(SAP搭載)のようなトランザクションシステムにおいても、 適切な在庫に関する情報を提供します。「Just-in-Time/Just-in-Sequence」は、多くのアプリケーションにとって極めて重要です。KafkaとSAPの統合は、この分野で私が話をする顧客のほぼ半分で必要とされています。また、統合だけでなく多くの次世代トランザクションERPやMESプラットフォームもKafkaを利用しています。\nKafkaはエッジや …","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"5b03cf7f03ccd2d5a0d24dbbe2a8bf05","permalink":"https://confluent-jp.github.io/community/blog/when-not-to-use-kafka/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/when-not-to-use-kafka/","section":"blog","summary":"具体的なユースケースから紐解く、Kafkaが向くとき、向かないとき。","tags":["Edge computing","IoT","Translated"],"title":"Kafkaの利用が適さないユースケースとは？","type":"blog"},{"authors":["hashi"],"categories":["Announcement","developer.io"],"content":"developer.confluent.ioにてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。\nUXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto BrandoliniによるEvent Sourcingと近い思想によるデザイン手法の一つです。\nマイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。\n","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"ee151f0b106404b801569afa95f0a6a7","permalink":"https://confluent-jp.github.io/community/blog/developer-io-event-modeling/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/developer-io-event-modeling/","section":"blog","summary":"developer.confluent.ioにて新しいEvent Modelingに関するコースが公開されました。","tags":["Stream Processing"],"title":"新コース - Event Modeling","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。\nただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。\nExactly Once Semantics Kafka初期において最も注目を集めたエンハンスメントの一つにKIP-98 - Exactly Once Delivery and Transactional Messaging があります。「メッセージ基盤においてExactly Onceは不可能」という二人の将軍問題 観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして具体的な説明もたくさんなされています。1\n実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りはenable.idempotency=trueと設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。\nack=all retries \u0026gt; 1 max.inflight.requests.per.connection=1 必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。\nKAFKA-5494 KAFKA-5494: enable idempotence with max.in.flight… このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。2\n対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。3\nおわりに KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。\nオリジナルのデザイン資料はここにあります。 ↩︎\n合わせてOutOfSequenceExceptionが発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。 ↩︎\nまたこのPRに関する前提情報や設計については別途こちらにまとめられています。 ↩︎\n","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"74df3beba2a5f9987b985eed649fa9ac","permalink":"https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/community/blog/idempotent-producer-and-max-inflight/","section":"blog","summary":"Exactly Once Deliveryに関わる重要な変更がKIP-95にて対応されて暫く経ちます。仕組み上Producer側の並列送信数は1に設定する必要がありましたが、後日のエンハンスメントで最大5まで対応出来る事になっています。","tags":["Exactly Once Semantics","KIP"],"title":"Exactly Onceとmax.in.flightについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。KIP-932 Queues for Kafka はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。\nConsumer Group Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。\nConsumer Groupはアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。\n一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。\nこれまでのアプローチ ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。\nLINE Decaton はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。\nConfluent Parallel Consumer はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、順序保証しない設定を含め柔軟に処理構成を変更することが出来ます。\nQueue for Kafka - Kafka Nativeなアプローチ Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。\nShared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、group.typeをshare1と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。\nConsumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。\nおわりに Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。\ngroup.typeは新しいプロパティ。デフォルトはconsumerであり、この指定だと通常通りConsumer Groupとして機能する。デフォルトはconsumerである為下位互換性あり。 ↩︎\n","date":1688083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688083200,"objectID":"acf7b7266e27328e86367517f7aad12b","permalink":"https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/","publishdate":"2023-06-30T00:00:00Z","relpermalink":"/community/blog/kip923-queues-for-kafka/","section":"blog","summary":"KIP-932として登録されているQueues for Kafka。「Kafkaはメッセージキューなのに何を今更？」という疑問も伺いますが、Kafkaは本質的にはメッセージキューではありません。そのKafkaにとってKIP-932はどういう変更なのかについて説明します。","tags":["Stream Processing","Scalability","KIP"],"title":"Queues for Kafkaとは何か?","type":"blog"},{"authors":["akio"],"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686614400,"objectID":"34e0abbb19e1754f47c2421fc8d19739","permalink":"https://confluent-jp.github.io/community/talk/20230613-kafka-meetup/","publishdate":"2023-06-13T00:00:00Z","relpermalink":"/community/talk/20230613-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #13 - Apache Kafka Meetup Japan #13の発表資料です。2023年6月16日(JST)時点での、Apache Kafkaのアップデートやロードマップを紹介しています。","tags":["Slide","Kafka Update","KRaft","Kafka Core"],"title":"Apache Kafka 最新アップデート ~ What's New \u0026 What's Next","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":16848e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":16848e5,"objectID":"9140c62cab6d1127267a20beb29b158b","permalink":"https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/","publishdate":"2023-05-23T00:00:00Z","relpermalink":"/community/talk/20230523-eventdriven-meetup/","section":"talk","summary":"Event Driven Meetup #1 - イベント駆動というアプローチに対し、ストリームという文脈を持たせた上で処理をする概念とApache Kafkaのアプローチについてご紹介します。今回は特にExactly Once Semantics (全てのイベントを重複なく1度だけ処理する) というストリーム処理のゴールに対して、Kafkaがトランザクションの概念をどう導入したかについて 踏み込んでご説明します。","tags":["Slide","Operations","Kafka Core","Transaction","Exactly Once Semantics","Event Driven Architecture","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"030655d1a1a2bc308cdbf50f71fc6252","permalink":"https://confluent-jp.github.io/community/talk/20221226-kafka-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20221226-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #12 - 登壇資料Kafkaの活用が進みミッションクリティカルなワークロードを扱うようになると、Kafkaの持つ障害耐性を超えたSLAを目指すケースも見受けられます。本トークでは、Kafkaにおける基本的なHA/DRの概念やアプローチと、複数データセンター（or Cloud）を跨がる大規模な構成についてお話しします。","tags":["Slide","Operations","Availability","DR","Multi Region Cluster","Cluster Linking"],"title":"Hish SLA Kafka - Kafka Across Multiple DCs","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1668988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668988800,"objectID":"17f18e827864f20c2756a8cf75c85c53","permalink":"https://confluent-jp.github.io/community/talk/20221121-cloudnativedays-tokyo/","publishdate":"2022-11-21T00:00:00Z","relpermalink":"/community/talk/20221121-cloudnativedays-tokyo/","section":"talk","summary":"Cloud Native Days Tokyo 2022 - 本セッションでは、今も進化を続けるApahce Kafkaの構造的な仕組み、そしてこれまでどの様な進化を遂げて今に至るのかをインフラ的な観点からお話しします。中でもKafkaの構成上必要なZookeeperへの依存をどの様に断ち切ったのか、KIP-500と呼ばれる3年に渡る取り組みについて詳しくご紹介します。","tags":["Slide","Recording","Operations","Availability","KRaft","Tiered Storage"],"title":"Cloud Native Kafka - 分散データ基盤がクラウドネイティブを目指すということ","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1666656e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666656e3,"objectID":"9615648e7d05c78d0f462937e6ae2e19","permalink":"https://confluent-jp.github.io/community/talk/20221025-yugabytedb-japan-hour/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/community/talk/20221025-yugabytedb-japan-hour/","section":"talk","summary":"YugabyteDB Japan Hour #5 - モダナイゼーションという文脈ではマイクロサービスやDevOps、サーバーレスといったランタイムや手法に関する議論が多く見受けられます。一方実際のモダナイゼーションを検討する際にはアプリケーションのデータストアならびに他システムとのデータ連携も同様に重要な検討課題となります。本セッションでは様々なモダナイゼーションの手法と、特にデータ周りのモダナイゼーションをどう進めるかについてお話しします。","tags":["Slide","Recording","Kafka Connect","Change Data Capture","Modernization"],"title":"Apache Kafka®️ and Modernization - How Old Data Meets New Data","type":"talk"},{"authors":["akio"],"categories":null,"content":"","date":1659052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659052800,"objectID":"5f960ba5fb5b631ef927d48a2807ea09","permalink":"https://confluent-jp.github.io/community/talk/20220729-osc-kyoto-2022/","publishdate":"2022-07-29T00:00:00Z","relpermalink":"/community/talk/20220729-osc-kyoto-2022/","section":"talk","summary":"OSC Kyoto Online 2022の発表資料です。初心者向けにApache Kafkaの概要を解説しています。","tags":["Slide","Recording","Beginner"],"title":"イベントストリーミング入門 〜Apache Kafkaを活用した大規模リアルタイムデータ処理〜","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1653350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653350400,"objectID":"a5d2b42a4a7dbbc792a91e68ef25281e","permalink":"https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/","publishdate":"2022-05-24T00:00:00Z","relpermalink":"/community/talk/20220524-gcpug-tokyo/","section":"talk","summary":"GCPUG Tokyo Queue Day 2022 May - Apache Kafkaはイベント駆動の領域で広く活用されています。一つの大きな特徴は、イベントが連なる『ストリーム』をコア概念としている点であり、概念だけでなく構造自体もストリームを扱う少し変わった設計がなされています。この為一般的なイベント駆動アーキテクチャの様に見えて、他のアプローチでは難しいユースケースで利用されたり、より複雑なエコシステムを形成することが出来ます。 本セッションでは、ストリームを支えるKafkaの内部構造と、その特徴を活用した「広がるストリーミング・エコシステム」のアプローチと事例についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7169ad42fe68c2e8b43a90f53ca7f579","permalink":"https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/community/talk/20220414-bigdata-jaws/","section":"talk","summary":"BigData-JAWS 勉強会#20 - 加速度的に広がるデータのサイズや種類に対して、様々なデータストアやデータ基盤を活用して、これまで不可能だった体験や新たな価値を提供する。この無理ゲーに対して、我々はより大きなデータストアを求め、より高い並列処理能力を駆使する挑戦を続けています。本セッションでは少し異なる観点 - 分散するデータをメッシュとして繋ぐ、Apache KafkaとksqlDBによるDatabase Inside Outの概念についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"0b5d143c5efeaf1128d1dfffc31f579a","permalink":"https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220325-cloudnative-database/","section":"talk","summary":"Cloud Native Databse Meetup #4 - ksqlDBはKafkaを利用する事を前提としたストリーム処理エンジンです。 『DB』という名前が付いてはいますが、DBでありながらストリーム処理エンジンでもある少し変わった個性を持つ技術です。Kafkaエコシステムの中でKafka Streamsと共に育った技術ですが、ストリーム処理の枠を超えてDBとしての道を歩み始めています。KafkaとKafka Streamsと強いつながりを持つksqlDBは、その特性を理解することで長所を生かした活用が可能です。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"739a23b908c98d2a045e1d38b0887d16","permalink":"https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220217-developers-summit-2022/","section":"talk","summary":"Developers Summit 2022 - 本セッションでは分散システムにおけるデータ整合性と、それを支えるApache Kafkaの役割についてご説明します。また将来のステップとして、ドメイン駆動化されたデータを「Data as a Product」として横断的に活用するData Meshの構想についてご説明します。","tags":["Slide","Recording","Microservices","Data Mesh","Stream Processing"],"title":"マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632873600,"objectID":"6d8cd7b9d2759e74017c69af5a985b8a","permalink":"https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/","publishdate":"2021-09-29T00:00:00Z","relpermalink":"/community/demo/demo-cc-ksql-clickstream/","section":"demo","summary":"Confluent Cloudを利用してクリックストリームのデータを加工/分析するワークショップです。クリックストリーム用のテストデータの作成とksqlDBによるStream/Tableの利用方法、Pull Queryの基本的な使用方法等を体験いただけます。","tags":["Confluent Cloud","ksqlDB","Stream Processing","DataGen Connector","Stream Lineage"],"title":"ksqlDB Clickstream Workshop","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1632441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632441600,"objectID":"78e2b3fb66a4ad4e47a50b19563fdd79","permalink":"https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/","publishdate":"2021-09-24T00:00:00Z","relpermalink":"/community/talk/20210924-kafka-meetup/","section":"talk","summary":"Apache Kafkaはメッセージブローカーであると同時にストレージの役割も果たす、それまでのMQの世界観とは少し異なった機能性を有しています。またデータのグループとなるTopicの構成やKafkaを利用するクライアントの設定如何によって全く異なるワークロードを同一クラスタ上で処理する事が可能です。本セッションでは、Kafkaのデータデータモデルとそれを扱う論理構成、Stream-Table Duality、そしてデータ整合性の考え方についてご説明します。","tags":["Slide","Kafka Core","Stream Processing"],"title":"カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632355200,"objectID":"14dffe6b3cacb271516d6b24517263d0","permalink":"https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/","publishdate":"2021-09-23T00:00:00Z","relpermalink":"/community/demo/demo-cp-splunk-elastic/","section":"demo","summary":"ネットワーク機器のログをSplunkのUniversal Forwarderを利用してConfluentに転送し、ストリーム処理後にSplunkのHECに転送するサンドボックス環境。Splunk Universal Forwarderから送られるログを、Confluent内で機器ログ (CISCO ASA) とUniversal Forwarder自身のログ (SPLUNKD) にストリーム処理で分類。ストリーム処理にはksqlDBを利用。","tags":["Confluent Platform","ksqlDB","Splunk","Elasticsearch","SIEM","Stream Processing"],"title":"Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境","type":"demo"},{"authors":["admin"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"a3fe7c0a03c9e94bb67cc16ab71c0501","permalink":"https://confluent-jp.github.io/community/publication/designing-event-driven-systems/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/community/publication/designing-event-driven-systems/","section":"publication","summary":"イベント駆動アーキテクチャを、ストリーム処理というより包括的なアプローチで解決する手法についての本です。イベントの種類やイベント駆動におけるアーキテクチャ概論、CQRSやステートフル処理まで踏み込んで解説しています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Designing Event-Driven Systems","type":"publication"},{"authors":["admin"],"categories":null,"content":"","date":1506988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506988800,"objectID":"87b614131c7a4b56d410e37557a267de","permalink":"https://confluent-jp.github.io/community/publication/kafka-the-definitive-guide/","publishdate":"2017-10-03T00:00:00Z","relpermalink":"/community/publication/kafka-the-definitive-guide/","section":"publication","summary":"Kafka コミッター/PMCメンバーによる初めてのKafkaをメインに扱った書籍です。Kafkaのアーキテクチャからアプリケーションの設定、運用観点におけるベストプラクティス等、幅広い領域をカバーしています。 (英語)","tags":["ebook","Kafka Core","Kafka Connect","Stream Processing"],"title":"Kafka: The Definitive Guide","type":"publication"},{"authors":["admin"],"categories":null,"content":"","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"37c699b46dbbd999259987106c20daa4","permalink":"https://confluent-jp.github.io/community/publication/making-sense-of-stream-processing/","publishdate":"2016-03-01T00:00:00Z","relpermalink":"/community/publication/making-sense-of-stream-processing/","section":"publication","summary":"『データ指向アプリケーションデザイン』の著者であるクレップマン博士によるストリーム処理、中でもKafkaを利用した新たなイベント駆動モデルの概要についての入門書です。『Database Inside Out (データベースの内部構造を広く展開する)』の概念とその可能性について詳しく説明されています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Making Sense of Stream Processing","type":"publication"},{"authors":["admin"],"categories":null,"content":"","date":1413849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413849600,"objectID":"8b8adea67e39b4cbbef81d8aa4a3de58","permalink":"https://confluent-jp.github.io/community/publication/i-heart-logs/","publishdate":"2014-10-21T00:00:00Z","relpermalink":"/community/publication/i-heart-logs/","section":"publication","summary":"Confluent CEOであるJay Krepsによる、Kafkaの背景にある概念とログやストリーム処理アーキテクチャに関する考察です。 (英語)","tags":["ebook","Lambda Architecture","Stream Processing"],"title":"I ❤️ Logs","type":"publication"}]