[{"authors":null,"categories":null,"content":"","date":1690848e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1690848e3,"objectID":"6c0805fdbd7621e3bbd425457215404c","permalink":"https://confluent-jp.github.io/community/authors/hashi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/hashi/","section":"authors","summary":"","tags":null,"title":"hashi","type":"authors"},{"authors":null,"categories":null,"content":"","date":1690848e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1690848e3,"objectID":"7be59ae0d196dc1bbfb6c60c097b09ad","permalink":"https://confluent-jp.github.io/community/authors/stanislav/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/stanislav/","section":"authors","summary":"","tags":null,"title":"stanislav","type":"authors"},{"authors":null,"categories":null,"content":"","date":1689552e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1689552e3,"objectID":"d4ccb66a26bf2330497507875f5c9105","permalink":"https://confluent-jp.github.io/community/authors/kai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/kai/","section":"authors","summary":"","tags":null,"title":"kai","type":"authors"},{"authors":null,"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686614400,"objectID":"b0bc5dc322acaf3a4abf9d1fd4e8ac36","permalink":"https://confluent-jp.github.io/community/authors/akio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/akio/","section":"authors","summary":"","tags":null,"title":"akio","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://confluent-jp.github.io/community/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/admin/","section":"authors","summary":"","tags":null,"title":"admin","type":"authors"},{"authors":["stanislav","hashi"],"categories":["Kafka Core","Blog"],"content":" このブログエントリはKafkaコミッタである Stanislav Kozlovski(𝕏|Ln) のサイトで2022/11/06に公開されたKafka Acks Explainedの日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。\nKafkaに関する仕事を始めて4年になりますが、経験上未だに2つの設定について広く誤解されていると感じる事があります。それはacksとmin.insync.replicasであり、さらにはこの2つの設定がどう影響し合うかについてです。このエントリはこの非常に重要な2つの誤解を解き、適切に理解してもらう事を目的としています。\nReplication この2つの設定を理解するためにはまずKafka Replicationプロトコルについて少しおさらいする必要があります。\nこのブログの読者の皆さんはある程度Kafkaについてご存知だと想定しています - もし自信がない場合はぜひThorough Introduction to Apache Kafkaもご参照ください。\n各Partitionには1つのLeader Broker(1)と複数のFollower Broker(N)がアサインされます。この複製の数はreplication.factorで設定する事ができ(1+N)つまり総数を表します。つまりこの設定では「対象となるPartitionに対してクラスタ上で何個の複製が出来るか」を指定します。\nデフォルトであり通常推奨する設定値は3です。 ProducerクライアントはLeader Brokerにのみ書き込みに行きます - つまりFollower Brokerへのレプリケーションは非同期に行われます。ここで分散システムとして考慮しないといけないのは、何かしらの方法で「これらレプリケーションされる処理がどのようにLeaderに追従すべきか」を指定する方法です。具体的には「Leaderに書き込まれた更新がFollowerにも反映されているか否か」です。\nIn-Sync Replicas in-sync replica(ISR)は対象Partitionの最新状態と同期が取れているBrokerを指します。当然Leaderは常にISRとなり、Followerの場合はLeaderの更新に追い付き同期が取れた状態のもののみISRとなります。仮にFollowerがLeaderに追従できなくなった場合、そのFollowerはISRではなくなります。 上の図ではBroker 3は同期されていないのでISRではない、つまりout-of-syncとなります。\nちなみに、厳密にはISRか否かという判断はもう少し複雑で、ここで説明されているようにすんなり「このFollowerは最新の状態か」と判断出来る訳ではありません。ただ厳密な話をし始めるとこのエントリの主旨から外れるので、ここでは上の図にある赤いBrokerは同期が取れていないと、見たまま捉えてください。\nAcks Acksはクライアント (Producer) 側の設定で、「どこまでFollowを含めて書き込みの確認が取れてからクライアントに返答するか」を指定するものです。有効な値は0、1、そしてallの3つです。\nacks=0 0が設定された場合、クライアントはBrokerまで到達したかの確認さえ行いません - メッセージがKafka Brokerに対して送られたタイミングでackを返します。 ackと呼びますがBrokerからの返答さえ待ちません。送れたらOKです。\nacks=1 1が設定された場合、クライアント (Producer) はLeaderにまでメッセージが到達した時点で書き込みの完了と判断します。Leader Brokerはメッセージを受け取った時点でレスポンスを返します。 クライアントはレスポンスが返ってくるのを待ちます。Leaderからの返答が到着した時点で完了と判断しackとします。Leaderは受け取り次第レスポンスを返すので、Followerへのレプリケーションはレスポンスとは非同期に処理されます。\nacks=all allと設定された場合、クライアントは全てのISRにメッセージが到達した時点で書き込みの完了と判断します。この際Leader BrokerがKafka側の書き込み判定を行なっており、全てのISRへのメッセージ到達の上クライアントにレスポンスを返します。 上の図の状態ではBroker 3はまだメッセージを受け取っていません。この為Leaderはレスポンスを返しません。 全てのISRに渡って初めてレスポンスが返されます。\nacksの機能性 この通りacksはパフォーマンスとデータ欠損耐性のバランスを決める非常に有益な設定です。データ保全を優先するのであればacks=allの設定が適切です。1 一方レイテンシやスループットに関する要件が極めて高い場合には0に設定すれば最も効率が良くなりますが、同時にメッセージロスの可能性は高まります。\nMinimum In-Sync Replicas acks=allの設定に関して、もう一つ重要な要素があります。\n例えばLeaderが全てのISRへの書き込み完了した上でレスポンスを返すとして、LeaderのみがISRだった場合、結果としてacks=1と振る舞いは同じとなるのでしょうか？\nここでmin.insync.replicasの設定が重要になります。\nmin.insync.replicasというBroker側の設定は、acks=allの際に「最低いくつのISRとなっているか (Leaderを含めて幾つのレプリカが最新状態か) を指定するものです。つまりLeaderは、acks=allのリクエストに対して指定されたISRに満たないまでは返答せず、またそれが何かしらの理由で達成できない場合にはエラーを返します。データ保全観点でのゲートキーバーの様な役割を果たします。\n上記の状態だとBroker 3は同期されていない状態です。しかしながらmin.insync.replicas=2となっている場合には条件を満たす為この時点でレスポンスが返されます。\nBroker 2と3が同期されていない状態です。この場合指定されたmin.insync.replicasを下回るためLeaderからはエラーレスポンスが返る、つまり書き込みは失敗します。一方同じ状況であってもacksの設定が0もしくは1の場合には正常なレスポンスが返されます。\n注意点 一般的にmin.insync.replicasは「Leaderがクライアントに返答する際に、どれだけレプリケーションが完了しているかを指定する」と解釈されていますが、これは誤りです。正確には「リクエストを処理する為に最低いくつのレプリカが存在するか」を指定する設定です。 上記の場合、Broker 1から3までが全て同期状態です。この時に新たなリクエスト (ここではメッセージ6) を受け取った場合、Broker 2への同期が完了してもレスポンスは返しません。この場合、処理時にISRとなっているBroker 3への同期が完了して初めてレスポンスが返されます。\nまとめ 図で説明したことによって理解が深まったのではないかと思います。\nおさらいすると、acksとmin.insync.replicasはKafkaへの書き込みにおける欠損体制を指定する事ができます。\nacks=0 - 書き込みはクライアントがLeaderにメッセージを送った時点で成功とみなします。Leaderからのレスポンスを待つことはしません。 acks=1 - 書き込みはLeaderへの書き込みが完了した時点で成功とみなします。 acks=all - 書き込みはISR全てへの書き込みが完了した時点で成功とみなします。ISRがmin.insync.replicasを下回る場合には処理されません。 その他情報 Kafkaは複雑な分散システムであり、学ばなければいけない事が多いのも事実です。Kafkaの他の重要な要素については以下も参考にしてください。\nKafka consumer data-access semantics - クライアント (Consumer) における欠損耐性、可用性、データ整合性の確保に関わる詳細。 Kafka controller - Broker間の連携がどの様になされるのかの詳細。特にレプリカが非同期 (Out-of-Sync) となるのはどういう条件下かについて説明しています。 “99th Percentile Latency at Scale with Apache Kafka - Kafkaのパフォーマンスに関するConfluent Blogエントリ。 Kafka Summit SF 2019 videos Confluent blog - Kafkaに関する様々なトピックを網羅。 Kafka documentation Kafkaは継続的かつアクティブに開発されていますが、機能追加や改善は活発なコミュニティにより支えられています。開発の最前線で何が起こっているか興味がある場合はぜひメーリングリスト に参加してください。\nこのエントリの著者であるStanislav Kozlovski は2 Minute StreamingというKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。\n(訳者注)ほとんどのユースケースではacks=allが適切であり、Kafkaのデフォルトでもあります。 ↩︎\n","date":1690848e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848e3,"objectID":"29d13f61167d64758e7d240fbb183dfa","permalink":"https://confluent-jp.github.io/community/blog/kafka-acks-explained/","publishdate":"2023-08-01T00:00:00Z","relpermalink":"/community/blog/kafka-acks-explained/","section":"blog","summary":"KafkaのAcksを完全に理解する by Kafkaコミッタ。","tags":["Kafka Client","Translated"],"title":"Kafka Acks再入門","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Streaming AudioはConfluentがPodcast\u0026amp;YouTubeシリーズとして提供しています。毎回ゲストを迎え様々なトピックについてフリーにディスカッションするポッドキャストで、Kafka初期開発メンバーのJun RaoやKRaftの開発メンバー、Kafkaのリアルユーザー等様々なゲストスピーカーが参加します。中でも「アナネキ」ことAnna McDonald (Technical Voice of CUstomer @Confluent)登場回は毎回必見で、いつも何か新しい発見があります。\n今回はその彼女の登場回の中でも最も最近の回のご紹介です：お題は「Kafkaに本当にあったヤバいバグ5選1」です。(オリジナルの公開は2022/12/21) このトークで紹介されたJIRAバグの一覧を用意しました。結構最近になってようやく入ったものや、まだ直っていないものもあります。Kafkaのバージョンはなるべく追従する事を強くお勧めしていますが、ここにあるのは全体の一部で、なかなかに怖いバグへの修正も入っています。\nあなたのKafkaクラスタはほんとに大丈夫です？\nKAFKA-10888: Sticky partition leads to uneven product msg, resulting in abnormal delays in some partitions Status: Resolved (3.0.0)\nSticky Partitionerを使用時、Partition間の処理数に大きな偏りが出る様な状況となり特定のPartitionのスループットが極端に下がる事がある: 場合によってはリカバリ不能なほどProducer側のバッチが肥大化する。\nKAFKA-9648: Add configuration to adjust listen backlog size for Acceptor Status: Resolved (3.2.0)\nOSがLinuxの場合に発生。ローリングアップグレード等の際、BrokerからPartition Leaderが他のBrokerに移る、もしくは移ったのちに元のBrokerに戻る (Preferred Leader Election) が発生。この際Partitionに関するメタデータ更新が行われる為これらPartitionを参照するクライアントから一斉に再接続のリクエストが送られる。状況によってはLinuxのSYN cookieの機能が動きTCPバッファーが制限されスループットが大幅に低下する。これは再接続しない限り復旧しない。\nKAFKA-12686: Race condition in AlterIsr response handling Status: Resolved (3.0.0)\nPartition.scala内の処理において、AlterIsrResponseとLeaderAndIsrRequestのレースコンディションが起因。クラスタサイズが小さくPartition数が多い場合、Brokerノードの変更時に大量のPartition変更が発生する。この際AlterIsrManagerがペンディング状態のリクエストをクリアしてしまう為、AlterIsrResponseが戻ってきた際に処理中 (in Flight) であるのに処理タスク (Pending) が無いという矛盾状態が発生する。\nKAFKA-12964: Corrupt segment recovery can delete new producer state snapshots Status: Resolved (3.0.0)\nBrokerの停止時、猶予時間内に終了しない場合には Unclearn Shutdownと判断される。この際Broker復帰時に残っていたセグメントは不要と判断され非同期で削除が実行される。この削除が完了する前に同じオフセットのセグメントが書き込まれる状態となると、新しいProducer Stateスナップショットが誤って削除される事がある。\nKAFKA-14334: DelayedFetch purgatory not completed when appending as follower Status: Resolved (3.4.0, 3.3.2)\nConsumerがPulgatoryからフェッチするケースにおいて、通常通りPartitionリーダーからフェッチする場合には正しくフェッチの完了が認識される。しかしConsumerがフォローワーがフェッチする設定としている(KIP-932)場合、フォローワーのPartitionはPulgatoryに存在しない為フェッチ出来ずタイムアウトする。\nオリジナルは6選であり、ここではそのうちKAFKA-9211: Kafka upgrade 2.3.0 may cause tcp delay ack(Congestion Control)も含んでいますが、トークの中ではKafka-9646の中で合わせて語られているので割愛しました。 ↩︎\n","date":1690588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690588800,"objectID":"bfc2a40b146c9eab46ad969b34c54bd4","permalink":"https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/","publishdate":"2023-07-29T00:00:00Z","relpermalink":"/community/blog/streaming-audio-worst-kafka-bugs/","section":"blog","summary":"Anna McDonaldによるKafkaのヤバいバグに関するトークです。日本語字幕でどうぞ。","tags":["Bugs"],"title":"Streaming Audio - Kafkaに本当にあった(まだある)ヤバいバグ5選","type":"blog"},{"authors":["kai","hashi"],"categories":["Blog","Use Cases"],"content":" このブログエントリはConfluent Field CTOであるKai Waeehnerのサイトで2022/1/4に公開された When NOT to use Apache Kafka?の日本語訳です。Kai本人の了承を得て翻訳/公開しています。\nApache Kafkaは、Data in Motionにおけるイベントストリーミングのデファクトスタンダードです。あらゆる業界でその採用が大きく伸びているため、私は毎週のように『ではApache Kafkaを使うべきでは無いのはどんな場合？』『ストリーム処理の基盤に重要な要素は？』『kafkaにこの機能性が無いのはなぜ？』『Kafkaを採用しないと判断する為の条件とは？』という質問を受けます。このブログ記事では、Kafkaを使うべき時、Kafkaを使うべきでない時、そしてKafkaを使うべきかもしれない時について順番に説明します。\n市場動向 - コネクテッド・ワールド まずは、なぜKafkaがいたるところで登場するのかを理解することから始めます。このことは、イベントストリーミングに対する市場の大きな需要を明らかにすると同時に、すべての問題を解決する銀の弾丸は存在しないことを示しています。Kafkaは繋がる世界 (コネクテッドワールド) の特効薬ではなく、重要なコンポーネントと捉える必要があります。\n世界はますます繋がりを広げています。膨大な量のデータが生成され、収益増加、コスト削減、リスク軽減のためにリアルタイムに関連付ける必要があります。この動きはどの業界でも進んでいますが、より速い業界もあれば遅い業界もあります。しかしこの繋がりはあらゆるところに届いています。製造業、スマートシティ、ゲーム 、小売、銀行、保険などどこでもです。私の過去のブログには、どの業界にも関連するKafkaの使用事例を見つけることができます。\n私はこのデータの急激な成長を、イノベーションと新しい最先端のユースケースの創出を示す2つのマーケットトレンドとして捉えています。(そしてKafkaの採用が業界を超えて急激である理由も併せて) 。\nコネクテッド・カー - 膨大な量のテレメトリデータとアフターセールス アライドマーケットリサーチの世界の機会分析と産業予測、2020-2027年 からの引用です: コネクテッドカー市場には、多くの人が考えているよりもはるかに幅広いユースケースと業界が含まれています。いくつか例を挙げると:ネットワークインフラとコネクティビティ、セキュリティ、エンターテインメント、小売、アフターマーケット、自動車保険、サードパーティデータ利用(スマートシティなど)。その他にも様々なユースケースが存在します。\nゲーミング - 数十億人のプレーヤーと巨額の収益 ゲーム産業はすでに他のすべてのメディア・カテゴリーを合わせたよりも大きくなっており、Bitkraftが描くように、これはまだ新しい時代の始まりに過ぎないとも言えます。 既に世界中で毎月何百万人もの新規プレイヤーがゲームコミュニティに参加しています。インターネットへの接続性と安価なスマートフォンは、それほど裕福でない国でも広く普及しています。 Play to Earnのような新しいビジネスモデルは、次世代のゲーマーのゲームの遊び方を変えており、5Gのような拡張性の高い低遅延技術が新たなユースケースを可能にしています。更にはブロックチェーンとNFT(Non-Fungible Token)は、マネタイズとコレクター市場を永遠に変えようとしています。\n業界を横断するこうした市場動向は、リアルタイムデータ処理のニーズが四半期ごとに大幅に増加している理由を明らかにしています。Apache Kafkaは分析およびトランザクションデータ ストリームを大規模に処理するためのデファクトスタンダードとしての地位を既に確立しています。しかしながら、Apache Kafkaとその周辺エコシステムの技術をプロジェクトで使用する(しない)タイミングを理解することも併せて非常に重要です。\nApache Kafkaとは何で、何では無いのか？ Kafkaは誤解されやすい技術です。例えばKafkaはメッセージキューだという話をいまだによく耳にします。その理由のひとつは、一部のベンダーが自社製品を売るために特定の問題(データレイクやデータウェアハウスへのデータ取り込みなど)に対してのみKafkaを売り込んでいるからだと思われます。\nKafkaは：\nスケーラブルなリアルタイム・メッセージング・プラットフォームで、毎秒数百万のメッセージを処理する。 大量のビッグデータ分析から少量のトランザクションデータ処理まで対応するイベント・ストリーミング・プラットフォーム。 分散ストレージは、背圧処理のための真のデカップリングを提供し、様々な通信プロトコルをサポートし、順序が保証されたイベントの再生可能性を提供する。 ストリーミングETLのためのデータ統合フレームワーク。 ステートレスまたはステートフルな連続ストリーム処理のためのデータ処理フレームワーク。 これら様々なユースケース/利用パターンを一つのプラットフォームで提供出来る点がKafkaの特徴です。\n一方以下はKafkaに当てはまりません：\n数百万を超えるクライアントからの直接接続 - Kafkaネイティブのプロキシ(RESTやMQTTなど)、いくつかのユースケースに対応しているが全てではない。 API管理プラットフォーム - これらのツールは通常補完的であり、Kafka APIの作成、ライフサイクル管理、または収益化のために使用される。 バッチ分析や複雑なクエリをサポートするDB - トランザクションクエリや比較的単純な集計(特にksqlDBを使用)では充分扱える。 デバイス管理を行うIoTプラットフォーム - MQTTやOPC-UAなどのIoTプロトコルとKafkaを直接統合することは可能であり、(一部の)ユースケースには適切なアプローチである。 ミリ秒レイテンシを達成するハード・リアルタイム・アプリケーションのための技術 (セーフティ・クリティカル・システムや決定論的システム) - ただ組み込みソフトウェアを除くと全てのプラットフォームが同様であり、Kafkaもその例外では無いというだけである。 このような理由から、Kafkaは他のテクノロジーと競合するものではなく、補完するものであると言えます。仕事に適したツールを選び、それらを組み合わせる上でKafkaは全体における重要な要素となり得ます。\nコネクテッドワールドにおけるApache Kafkaのケーススタディ ここではKafkaを他のテクノロジーと組み合わせることで、ビジネス上の問題を解決した素晴らしいサクセスストーリーの例をいくつか紹介します。エンドツーエンドのデータフローにKafka以上のものを必要とするケーススタディに焦点を当てています。\n私のブログ、Kafka Summitカンファレンス、MediumやDzoneのようなオンラインリソース、その他の技術関連のニュースなど、どれをフォローしても同じです。コネクテッドカー、IoTエッジデバイス、スマートフォンのゲーム/アプリなどからの大量のアナリティクスやトランザクショ・データをApache Kafkaでリアルタイム データストリー ミングする成功例をたくさん見つけることができます。\n業種や使用例をいくつか挙げてみます:\nAUDI - コネクテッドカー・プラットフォームが地域とクラウドプロバイダーを横断的に展開。 BMW - サプライチェーンとロジスティクスの最適化を実現するスマート工場。 SolarPower - 太陽光発電のソリューションとサービスを世界中で提供。 Royal Caribbian - エッジサービスとハイブリッド・クラウドの集約によるクルーズ船のエンターテイメント。 Disney+ Hotstar - インタラクティブなメディアコンテンツとゲーム/ベッティングをスマートフォンで数百万人のファンに提供。 このような素晴らしいIoTのサクセスストーリーにおいてKafkaは課題はあるかというと、問題無く非常に有機的に機能しています。しかしながら、Apache Kafkaエコシステムでイベントストリーミングを使用するタイミングと、他の補完的なソリューションを利用すべきかの判断について説明するためには、いくつか明確化が必要です。\nApache Kafkaを使うべき場合 Kafkaを使うべきでない場合について説明する前に、Kafkaを使うべき場所を理解し、必要に応じて他のテクノロジーと補完する方法とタイミングをより明確に説明します。ここから実例をユースケースごとに分けていくつかご紹介します。\nKafkaは大量のIoTやモバイルデータをリアルタイムかつ大量に扱う事ができる。 Teslaは単なる自動車メーカーではありません。Teslaは、革新的で最先端のソフトウェ アを数多く開発しているハイテク企業です。Teslaは自動車のためのエネルギーインフラも併せて提供しています。スーパーチャージャー、ギガファクトリーでの太陽エネルギー生産等も然りです。\n車両、スマートグリッド、工場からのデータを処理/分析し、残りのITバックエンドサービスとリアルタイムで統合することは、同社の成功に不可欠な要素です。\nTeslaはKafkaベースのデータプラットフォームインフラを構築し『1日あたり数百万台のデバイスと数兆のデータポイントをサポート』しています。テスラは2019年のKafka Summitで、彼らのKafka利用のな歴史とその進化について登壇しています。\n私はほとんどすべてのブログエントリでこのことを繰り返していますが、Kafkaは単なるメッセージングではないことを改めて強調させてください。Kafkaは分散ストレージレイヤーであり、プロデューサーとコンシューマーを真に分離し、さらにKafka StreamsやksqlDBのようなKafkaネイティブの処理ツールによってリアルタイム処理を可能にします。\nKafkaはIoTデータとMESやERPシステムからのトランザクションデータを結び付ける 規模の大きなリアルタイムでのデータ統合には、アナリティクスやERPやMESシステムのようなトランザクションシステムの利用に密接に関連しています。Kafka Connectやその他非Kafkaミドルウェアは、このタスクのためにイベントストリーミングのコアを補完する役割を果たします。\nBMWはエッジ(スマート工場など)とパブリッククラウドでミッションクリティカルなKafkaワークロードを運用しています。Kafkaはこれらシステムの疎結合性/透明性を高め活用によるイノベーションを可能にします。併せてConfluentの製品と専門知識により安定性を担保しています。後者は製造業での成功に不可欠です - 1分のダウンタイムによって組織に莫大なコストがかかリマス。関連記事Apache Kafka as Data Historian - an IIoT / Industry 4.0 Real-Time Data Lakeをご参照ください。Kafkaが製造業の総合設備効率(OEE)をどのように改善出来るか理解頂けると思います。\nBMWはリアルタイムでサプライチェーン管理を最適化しています。このソリューションは、物理的にもBMWのERP(SAP搭載)のようなトランザクションシステムにおいても、 適切な在庫に関する情報を提供します。「Just-in-Time/Just-in-Sequence」は、多くのアプリケーションにとって極めて重要です。KafkaとSAPの統合は、この分野で私が話をする顧客のほぼ半分で必要とされています。また、統合だけでなく多くの次世代トランザクションERPやMESプラットフォームもKafkaを利用しています。\nKafkaはエッジや …","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"5b03cf7f03ccd2d5a0d24dbbe2a8bf05","permalink":"https://confluent-jp.github.io/community/blog/when-not-to-use-kafka/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/when-not-to-use-kafka/","section":"blog","summary":"Kafkaの利用が適さないユースケースとは？","tags":["Edge computing","IoT","Translated"],"title":"When NOT to use Apache Kafka?","type":"blog"},{"authors":["hashi"],"categories":["Announcement","developer.io"],"content":"developer.confluent.ioにてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。\nUXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto BrandoliniによるEvent Sourcingと近い思想によるデザイン手法の一つです。\nマイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。\n","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"ee151f0b106404b801569afa95f0a6a7","permalink":"https://confluent-jp.github.io/community/blog/developer-io-event-modeling/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/developer-io-event-modeling/","section":"blog","summary":"developer.confluent.ioにて新しいEvent Modelingに関するコースが公開されました。","tags":["Stream Processing"],"title":"新コース - Event Modeling","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。\nただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。\nExactly Once Semantics Kafka初期において最も注目を集めたエンハンスメントの一つにKIP-98 - Exactly Once Delivery and Transactional Messaging があります。「メッセージ基盤においてExactly Onceは不可能」というビザンチン将軍問題観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして具体的な説明もたくさんなされています。1\n実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りはenable.idempotency=trueと設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。\nack=all retries \u0026gt; 1 max.inflight.requests.per.connection=1 必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。\nKAFKA-5494 KAFKA-5494: enable idempotence with max.in.flight… このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。2\n対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。3\nおわりに KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。\nオリジナルのデザイン資料はここにあります。 ↩︎\n合わせてOutOfSequenceExceptionが発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。 ↩︎\nまたこのPRに関する前提情報や設計については別途こちらにまとめられています。 ↩︎\n","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"74df3beba2a5f9987b985eed649fa9ac","permalink":"https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/community/blog/idempotent-producer-and-max-inflight/","section":"blog","summary":"Exactly Once Deliveryに関わる重要な変更がKIP-95にて対応されて暫く経ちます。仕組み上Producer側の並列送信数は1に設定する必要がありましたが、後日のエンハンスメントで最大5まで対応出来る事になっています。","tags":["Exactly Once Semantics","KIP"],"title":"Exactly Onceとmax.in.flightについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。KIP-932 Queues for Kafka はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。\nConsumer Group Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。\nConsumer Groupはアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。\n一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。\nこれまでのアプローチ ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。\nLINE Decaton はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。\nConfluent Parallel Consumer はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、順序保証しない設定を含め柔軟に処理構成を変更することが出来ます。\nQueue for Kafka - Kafka Nativeなアプローチ Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。\nShared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、group.typeをshare1と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。\nConsumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。\nおわりに Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。\ngroup.typeは新しいプロパティ。デフォルトはconsumerであり、この指定だと通常通りConsumer Groupとして機能する。デフォルトはconsumerである為下位互換性あり。 ↩︎\n","date":1688083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688083200,"objectID":"acf7b7266e27328e86367517f7aad12b","permalink":"https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/","publishdate":"2023-06-30T00:00:00Z","relpermalink":"/community/blog/kip923-queues-for-kafka/","section":"blog","summary":"KIP-932として登録されているQueues for Kafka。「Kafkaはメッセージキューなのに何を今更？」という疑問も伺いますが、Kafkaは本質的にはメッセージキューではありません。そのKafkaにとってKIP-932はどういう変更なのかについて説明します。","tags":["Stream Processing","Scalability","KIP"],"title":"Queues for Kafkaとは何か?","type":"blog"},{"authors":["akio"],"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686614400,"objectID":"34e0abbb19e1754f47c2421fc8d19739","permalink":"https://confluent-jp.github.io/community/talk/20230613-kafka-meetup/","publishdate":"2023-06-13T00:00:00Z","relpermalink":"/community/talk/20230613-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #13 - Apache Kafka Meetup Japan #13の発表資料です。2023年6月16日(JST)時点での、Apache Kafkaのアップデートやロードマップを紹介しています。","tags":["Slide","Kafka Update","KRaft","Kafka Core"],"title":"Apache Kafka 最新アップデート ~ What's New \u0026 What's Next","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"9140c62cab6d1127267a20beb29b158b","permalink":"https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20230523-eventdriven-meetup/","section":"talk","summary":"Event Driven Meetup #1 - イベント駆動というアプローチに対し、ストリームという文脈を持たせた上で処理をする概念とApache Kafkaのアプローチについてご紹介します。今回は特にExactly Once Semantics (全てのイベントを重複なく1度だけ処理する) というストリーム処理のゴールに対して、Kafkaがトランザクションの概念をどう導入したかについて 踏み込んでご説明します。","tags":["Slide","Operations","Kafka Core","Transaction","Exactly Once Semantics","Event Driven Architecture","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"030655d1a1a2bc308cdbf50f71fc6252","permalink":"https://confluent-jp.github.io/community/talk/20221226-kafka-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20221226-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #12 - 登壇資料Kafkaの活用が進みミッションクリティカルなワークロードを扱うようになると、Kafkaの持つ障害耐性を超えたSLAを目指すケースも見受けられます。本トークでは、Kafkaにおける基本的なHA/DRの概念やアプローチと、複数データセンター（or Cloud）を跨がる大規模な構成についてお話しします。","tags":["Slide","Operations","Availability","DR","Multi Region Cluster","Cluster Linking"],"title":"Hish SLA Kafka - Kafka Across Multiple DCs","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1668988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668988800,"objectID":"17f18e827864f20c2756a8cf75c85c53","permalink":"https://confluent-jp.github.io/community/talk/20221121-cloudnativedays-tokyo/","publishdate":"2022-11-21T00:00:00Z","relpermalink":"/community/talk/20221121-cloudnativedays-tokyo/","section":"talk","summary":"Cloud Native Days Tokyo 2022 - 本セッションでは、今も進化を続けるApahce Kafkaの構造的な仕組み、そしてこれまでどの様な進化を遂げて今に至るのかをインフラ的な観点からお話しします。中でもKafkaの構成上必要なZookeeperへの依存をどの様に断ち切ったのか、KIP-500と呼ばれる3年に渡る取り組みについて詳しくご紹介します。","tags":["Slide","Recording","Operations","Availability","KRaft","Tiered Storage"],"title":"Cloud Native Kafka - 分散データ基盤がクラウドネイティブを目指すということ","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1666656e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666656e3,"objectID":"9615648e7d05c78d0f462937e6ae2e19","permalink":"https://confluent-jp.github.io/community/talk/20221025-yugabytedb-japan-hour/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/community/talk/20221025-yugabytedb-japan-hour/","section":"talk","summary":"YugabyteDB Japan Hour #5 - モダナイゼーションという文脈ではマイクロサービスやDevOps、サーバーレスといったランタイムや手法に関する議論が多く見受けられます。一方実際のモダナイゼーションを検討する際にはアプリケーションのデータストアならびに他システムとのデータ連携も同様に重要な検討課題となります。本セッションでは様々なモダナイゼーションの手法と、特にデータ周りのモダナイゼーションをどう進めるかについてお話しします。","tags":["Slide","Recording","Kafka Connect","Change Data Capture","Modernization"],"title":"Apache Kafka®️ and Modernization - How Old Data Meets New Data","type":"talk"},{"authors":["akio"],"categories":null,"content":"","date":1659052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659052800,"objectID":"5f960ba5fb5b631ef927d48a2807ea09","permalink":"https://confluent-jp.github.io/community/talk/20220729-osc-kyoto-2022/","publishdate":"2022-07-29T00:00:00Z","relpermalink":"/community/talk/20220729-osc-kyoto-2022/","section":"talk","summary":"OSC Kyoto Online 2022の発表資料です。初心者向けにApache Kafkaの概要を解説しています。","tags":["Slide","Recording","Beginner"],"title":"イベントストリーミング入門 〜Apache Kafkaを活用した大規模リアルタイムデータ処理〜","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1653350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653350400,"objectID":"a5d2b42a4a7dbbc792a91e68ef25281e","permalink":"https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/","publishdate":"2022-05-24T00:00:00Z","relpermalink":"/community/talk/20220524-gcpug-tokyo/","section":"talk","summary":"GCPUG Tokyo Queue Day 2022 May - Apache Kafkaはイベント駆動の領域で広く活用されています。一つの大きな特徴は、イベントが連なる『ストリーム』をコア概念としている点であり、概念だけでなく構造自体もストリームを扱う少し変わった設計がなされています。この為一般的なイベント駆動アーキテクチャの様に見えて、他のアプローチでは難しいユースケースで利用されたり、より複雑なエコシステムを形成することが出来ます。 本セッションでは、ストリームを支えるKafkaの内部構造と、その特徴を活用した「広がるストリーミング・エコシステム」のアプローチと事例についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7169ad42fe68c2e8b43a90f53ca7f579","permalink":"https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/community/talk/20220414-bigdata-jaws/","section":"talk","summary":"BigData-JAWS 勉強会#20 - 加速度的に広がるデータのサイズや種類に対して、様々なデータストアやデータ基盤を活用して、これまで不可能だった体験や新たな価値を提供する。この無理ゲーに対して、我々はより大きなデータストアを求め、より高い並列処理能力を駆使する挑戦を続けています。本セッションでは少し異なる観点 - 分散するデータをメッシュとして繋ぐ、Apache KafkaとksqlDBによるDatabase Inside Outの概念についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"0b5d143c5efeaf1128d1dfffc31f579a","permalink":"https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220325-cloudnative-database/","section":"talk","summary":"Cloud Native Databse Meetup #4 - ksqlDBはKafkaを利用する事を前提としたストリーム処理エンジンです。 『DB』という名前が付いてはいますが、DBでありながらストリーム処理エンジンでもある少し変わった個性を持つ技術です。Kafkaエコシステムの中でKafka Streamsと共に育った技術ですが、ストリーム処理の枠を超えてDBとしての道を歩み始めています。KafkaとKafka Streamsと強いつながりを持つksqlDBは、その特性を理解することで長所を生かした活用が可能です。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"739a23b908c98d2a045e1d38b0887d16","permalink":"https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220217-developers-summit-2022/","section":"talk","summary":"Developers Summit 2022 - 本セッションでは分散システムにおけるデータ整合性と、それを支えるApache Kafkaの役割についてご説明します。また将来のステップとして、ドメイン駆動化されたデータを「Data as a Product」として横断的に活用するData Meshの構想についてご説明します。","tags":["Slide","Recording","Microservices","Data Mesh","Stream Processing"],"title":"マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632873600,"objectID":"6d8cd7b9d2759e74017c69af5a985b8a","permalink":"https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/","publishdate":"2021-09-29T00:00:00Z","relpermalink":"/community/demo/demo-cc-ksql-clickstream/","section":"demo","summary":"Confluent Cloudを利用してクリックストリームのデータを加工/分析するワークショップです。クリックストリーム用のテストデータの作成とksqlDBによるStream/Tableの利用方法、Pull Queryの基本的な使用方法等を体験いただけます。","tags":["Confluent Cloud","ksqlDB","Stream Processing","DataGen Connector","Stream Lineage"],"title":"ksqlDB Clickstream Workshop","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1632441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632441600,"objectID":"78e2b3fb66a4ad4e47a50b19563fdd79","permalink":"https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/","publishdate":"2021-09-24T00:00:00Z","relpermalink":"/community/talk/20210924-kafka-meetup/","section":"talk","summary":"Apache Kafkaはメッセージブローカーであると同時にストレージの役割も果たす、それまでのMQの世界観とは少し異なった機能性を有しています。またデータのグループとなるTopicの構成やKafkaを利用するクライアントの設定如何によって全く異なるワークロードを同一クラスタ上で処理する事が可能です。本セッションでは、Kafkaのデータデータモデルとそれを扱う論理構成、Stream-Table Duality、そしてデータ整合性の考え方についてご説明します。","tags":["Slide","Kafka Core","Stream Processing"],"title":"カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632355200,"objectID":"14dffe6b3cacb271516d6b24517263d0","permalink":"https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/","publishdate":"2021-09-23T00:00:00Z","relpermalink":"/community/demo/demo-cp-splunk-elastic/","section":"demo","summary":"ネットワーク機器のログをSplunkのUniversal Forwarderを利用してConfluentに転送し、ストリーム処理後にSplunkのHECに転送するサンドボックス環境。Splunk Universal Forwarderから送られるログを、Confluent内で機器ログ (CISCO ASA) とUniversal Forwarder自身のログ (SPLUNKD) にストリーム処理で分類。ストリーム処理にはksqlDBを利用。","tags":["Confluent Platform","ksqlDB","Splunk","Elasticsearch","SIEM","Stream Processing"],"title":"Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"a3fe7c0a03c9e94bb67cc16ab71c0501","permalink":"https://confluent-jp.github.io/community/publication/designing-event-driven-systems/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/community/publication/designing-event-driven-systems/","section":"publication","summary":"イベント駆動アーキテクチャを、ストリーム処理というより包括的なアプローチで解決する手法についての本です。イベントの種類やイベント駆動におけるアーキテクチャ概論、CQRSやステートフル処理まで踏み込んで解説しています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Designing Event-Driven Systems","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1506988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506988800,"objectID":"87b614131c7a4b56d410e37557a267de","permalink":"https://confluent-jp.github.io/community/publication/kafka-the-definitive-guide/","publishdate":"2017-10-03T00:00:00Z","relpermalink":"/community/publication/kafka-the-definitive-guide/","section":"publication","summary":"Kafka コミッター/PMCメンバーによる初めてのKafkaをメインに扱った書籍です。Kafkaのアーキテクチャからアプリケーションの設定、運用観点におけるベストプラクティス等、幅広い領域をカバーしています。 (英語)","tags":["ebook","Kafka Core","Kafka Connect","Stream Processing"],"title":"Kafka: The Definitive Guide","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"37c699b46dbbd999259987106c20daa4","permalink":"https://confluent-jp.github.io/community/publication/making-sense-of-stream-processing/","publishdate":"2016-03-01T00:00:00Z","relpermalink":"/community/publication/making-sense-of-stream-processing/","section":"publication","summary":"『データ指向アプリケーションデザイン』の著者であるクレップマン博士によるストリーム処理、中でもKafkaを利用した新たなイベント駆動モデルの概要についての入門書です。『Database Inside Out (データベースの内部構造を広く展開する)』の概念とその可能性について詳しく説明されています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Making Sense of Stream Processing","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1413849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413849600,"objectID":"8b8adea67e39b4cbbef81d8aa4a3de58","permalink":"https://confluent-jp.github.io/community/publication/i-heart-logs/","publishdate":"2014-10-21T00:00:00Z","relpermalink":"/community/publication/i-heart-logs/","section":"publication","summary":"Confluent CEOであるJay Krepsによる、Kafkaの背景にある概念とログやストリーム処理アーキテクチャに関する考察です。 (英語)","tags":["ebook","Lambda Architecture","Stream Processing"],"title":"I ❤️ Logs","type":"publication"}]