[{"authors":null,"categories":null,"content":"","date":1688342400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1688342400,"objectID":"6c0805fdbd7621e3bbd425457215404c","permalink":"https://confluent-jp.github.com/community/authors/hashi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/hashi/","section":"authors","summary":"","tags":null,"title":"hashi","type":"authors"},{"authors":null,"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686614400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://confluent-jp.github.com/community/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/admin/","section":"authors","summary":"","tags":null,"title":"admin","type":"authors"},{"authors":["hashi"],"categories":["Blog","Kafka Core","KIP"],"content":"はじめに メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。\nただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。\nExactly Once Semantics Kafka初期において最も注目を集めたエンハンスメントの一つにKIP-98 - Exactly Once Delivery and Transactional Messaging があります。「メッセージ基盤においてExactly Onceは不可能」というビザンチン将軍問題観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして具体的な説明もたくさんなされています。1\n実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りはenable.idempotency=trueと設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。\nack=all retries \u0026gt; 1 max.inflight.requests.per.connection=1 必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。\nKAFKA-5494 KAFKA-5494: enable idempotence with max.in.flight… このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。2\n対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。3\nおわりに KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。\nオリジナルのデザイン資料はここにあります。 ↩︎\n合わせてOutOfSequenceExceptionが発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。 ↩︎\nまたこのPRに関する前提情報や設計については別途こちらにまとめられています。 ↩︎\n","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"74df3beba2a5f9987b985eed649fa9ac","permalink":"https://confluent-jp.github.com/community/blog/idempotent-producer-and-max-inflight/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/community/blog/idempotent-producer-and-max-inflight/","section":"blog","summary":"Exactly Once Deliveryに関わる重要な変更がKIP-95にて対応されて暫く経ちます。仕組み上Producer側の並列送信数は1に設定する必要がありましたが、後日のエンハンスメントで最大5まで対応出来る事になっています。","tags":["Exactly Once Semantics"],"title":"Exactly Onceとmax.in.flightについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core","KIP"],"content":"はじめに Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。KIP-932 Queues for Kafka はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。\nConsumer Group Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。\nConsumer Groupはアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。\n一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。\nこれまでのアプローチ ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。\nLINE Decaton はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。\nConfluent Parallel Consumer はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、順序保証しない設定を含め柔軟に処理構成を変更することが出来ます。\nQueue for Kafka - Kafka Nativeなアプローチ Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。\nShared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、group.typeをshare1と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。\nConsumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。\nおわりに Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。\ngroup.typeは新しいプロパティ。デフォルトはconsumerであり、この指定だと通常通りConsumer Groupとして機能する。デフォルトはconsumerである為下位互換性あり。 ↩︎\n","date":1688083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688083200,"objectID":"acf7b7266e27328e86367517f7aad12b","permalink":"https://confluent-jp.github.com/community/blog/kip923-queues-for-kafka/","publishdate":"2023-06-30T00:00:00Z","relpermalink":"/community/blog/kip923-queues-for-kafka/","section":"blog","summary":"KIP-932として登録されているQueues for Kafka。「Kafkaはメッセージキューなのに何を今更？」という疑問も伺いますが、Kafkaは本質的にはメッセージキューではありません。そのKafkaにとってKIP-932はどういう変更なのかについて説明します。","tags":["Stream Processing","Scalability"],"title":"Queues for Kafkaとは何か?","type":"blog"},{"authors":["admin"],"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686614400,"objectID":"34e0abbb19e1754f47c2421fc8d19739","permalink":"https://confluent-jp.github.com/community/talk/20230613-kafka-meetup/","publishdate":"2023-06-13T00:00:00Z","relpermalink":"/community/talk/20230613-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #13 - Apache Kafka Meetup Japan #13の発表資料です。2023年6月16日(JST)時点での、Apache Kafkaのアップデートやロードマップを紹介しています。","tags":["Slide","Kafka Update","KRaft","Kafka Core"],"title":"Apache Kafka 最新アップデート ~ What's New \u0026 What's Next","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"9140c62cab6d1127267a20beb29b158b","permalink":"https://confluent-jp.github.com/community/talk/20230523-eventdriven-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20230523-eventdriven-meetup/","section":"talk","summary":"Event Driven Meetup #1 - イベント駆動というアプローチに対し、ストリームという文脈を持たせた上で処理をする概念とApache Kafkaのアプローチについてご紹介します。今回は特にExactly Once Semantics (全てのイベントを重複なく1度だけ処理する) というストリーム処理のゴールに対して、Kafkaがトランザクションの概念をどう導入したかについて 踏み込んでご説明します。","tags":["Slide","Operations","Kafka Core","Transaction","Exactly Once Semantics","Event Driven Architecture","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"030655d1a1a2bc308cdbf50f71fc6252","permalink":"https://confluent-jp.github.com/community/talk/20221226-kafka-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20221226-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #12 - 登壇資料Kafkaの活用が進みミッションクリティカルなワークロードを扱うようになると、Kafkaの持つ障害耐性を超えたSLAを目指すケースも見受けられます。本トークでは、Kafkaにおける基本的なHA/DRの概念やアプローチと、複数データセンター（or Cloud）を跨がる大規模な構成についてお話しします。","tags":["Slide","Operations","Availability","DR","Multi Region Cluster","Cluster Linking"],"title":"Hish SLA Kafka - Kafka Across Multiple DCs","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1668988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668988800,"objectID":"17f18e827864f20c2756a8cf75c85c53","permalink":"https://confluent-jp.github.com/community/talk/20221121-cloudnativedays-tokyo/","publishdate":"2022-11-21T00:00:00Z","relpermalink":"/community/talk/20221121-cloudnativedays-tokyo/","section":"talk","summary":"Cloud Native Days Tokyo 2022 - 本セッションでは、今も進化を続けるApahce Kafkaの構造的な仕組み、そしてこれまでどの様な進化を遂げて今に至るのかをインフラ的な観点からお話しします。中でもKafkaの構成上必要なZookeeperへの依存をどの様に断ち切ったのか、KIP-500と呼ばれる3年に渡る取り組みについて詳しくご紹介します。","tags":["Slide","Recording","Operations","Availability","KRaft","Tiered Storage"],"title":"Cloud Native Kafka - 分散データ基盤がクラウドネイティブを目指すということ","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1666656e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666656e3,"objectID":"9615648e7d05c78d0f462937e6ae2e19","permalink":"https://confluent-jp.github.com/community/talk/20221025-yugabytedb-japan-hour/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/community/talk/20221025-yugabytedb-japan-hour/","section":"talk","summary":"YugabyteDB Japan Hour #5 - モダナイゼーションという文脈ではマイクロサービスやDevOps、サーバーレスといったランタイムや手法に関する議論が多く見受けられます。一方実際のモダナイゼーションを検討する際にはアプリケーションのデータストアならびに他システムとのデータ連携も同様に重要な検討課題となります。本セッションでは様々なモダナイゼーションの手法と、特にデータ周りのモダナイゼーションをどう進めるかについてお話しします。","tags":["Slide","Recording","Kafka Connect","Change Data Capture","Modernization"],"title":"Apache Kafka®️ and Modernization - How Old Data Meets New Data","type":"talk"},{"authors":["admin"],"categories":null,"content":"","date":1659052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659052800,"objectID":"5f960ba5fb5b631ef927d48a2807ea09","permalink":"https://confluent-jp.github.com/community/talk/20220729-osc-kyoto-2022/","publishdate":"2022-07-29T00:00:00Z","relpermalink":"/community/talk/20220729-osc-kyoto-2022/","section":"talk","summary":"OSC Kyoto Online 2022の発表資料です。初心者向けにApache Kafkaの概要を解説しています。","tags":["Slide","Recording","Beginner"],"title":"イベントストリーミング入門 〜Apache Kafkaを活用した大規模リアルタイムデータ処理〜","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1653350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653350400,"objectID":"a5d2b42a4a7dbbc792a91e68ef25281e","permalink":"https://confluent-jp.github.com/community/talk/20220524-gcpug-tokyo/","publishdate":"2022-05-24T00:00:00Z","relpermalink":"/community/talk/20220524-gcpug-tokyo/","section":"talk","summary":"GCPUG Tokyo Queue Day 2022 May - Apache Kafkaはイベント駆動の領域で広く活用されています。一つの大きな特徴は、イベントが連なる『ストリーム』をコア概念としている点であり、概念だけでなく構造自体もストリームを扱う少し変わった設計がなされています。この為一般的なイベント駆動アーキテクチャの様に見えて、他のアプローチでは難しいユースケースで利用されたり、より複雑なエコシステムを形成することが出来ます。 本セッションでは、ストリームを支えるKafkaの内部構造と、その特徴を活用した「広がるストリーミング・エコシステム」のアプローチと事例についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7169ad42fe68c2e8b43a90f53ca7f579","permalink":"https://confluent-jp.github.com/community/talk/20220414-bigdata-jaws/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/community/talk/20220414-bigdata-jaws/","section":"talk","summary":"BigData-JAWS 勉強会#20 - 加速度的に広がるデータのサイズや種類に対して、様々なデータストアやデータ基盤を活用して、これまで不可能だった体験や新たな価値を提供する。この無理ゲーに対して、我々はより大きなデータストアを求め、より高い並列処理能力を駆使する挑戦を続けています。本セッションでは少し異なる観点 - 分散するデータをメッシュとして繋ぐ、Apache KafkaとksqlDBによるDatabase Inside Outの概念についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"0b5d143c5efeaf1128d1dfffc31f579a","permalink":"https://confluent-jp.github.com/community/talk/20220325-cloudnative-database/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220325-cloudnative-database/","section":"talk","summary":"Cloud Native Databse Meetup #4 - ksqlDBはKafkaを利用する事を前提としたストリーム処理エンジンです。 『DB』という名前が付いてはいますが、DBでありながらストリーム処理エンジンでもある少し変わった個性を持つ技術です。Kafkaエコシステムの中でKafka Streamsと共に育った技術ですが、ストリーム処理の枠を超えてDBとしての道を歩み始めています。KafkaとKafka Streamsと強いつながりを持つksqlDBは、その特性を理解することで長所を生かした活用が可能です。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"739a23b908c98d2a045e1d38b0887d16","permalink":"https://confluent-jp.github.com/community/talk/20220217-developers-summit-2022/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220217-developers-summit-2022/","section":"talk","summary":"Developers Summit 2022 - 本セッションでは分散システムにおけるデータ整合性と、それを支えるApache Kafkaの役割についてご説明します。また将来のステップとして、ドメイン駆動化されたデータを「Data as a Product」として横断的に活用するData Meshの構想についてご説明します。","tags":["Slide","Recording","Microservices","Data Mesh","Stream Processing"],"title":"マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632873600,"objectID":"6d8cd7b9d2759e74017c69af5a985b8a","permalink":"https://confluent-jp.github.com/community/demo/demo-cc-ksql-clickstream/","publishdate":"2021-09-29T00:00:00Z","relpermalink":"/community/demo/demo-cc-ksql-clickstream/","section":"demo","summary":"Confluent Cloudを利用してクリックストリームのデータを加工/分析するワークショップです。クリックストリーム用のテストデータの作成とksqlDBによるStream/Tableの利用方法、Pull Queryの基本的な使用方法等を体験いただけます。","tags":["Confluent Cloud","ksqlDB","Stream Processing","DataGen Connector","Stream Lineage"],"title":"ksqlDB Clickstream Workshop","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1632441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632441600,"objectID":"78e2b3fb66a4ad4e47a50b19563fdd79","permalink":"https://confluent-jp.github.com/community/talk/20210924-kafka-meetup/","publishdate":"2021-09-24T00:00:00Z","relpermalink":"/community/talk/20210924-kafka-meetup/","section":"talk","summary":"Apache Kafkaはメッセージブローカーであると同時にストレージの役割も果たす、それまでのMQの世界観とは少し異なった機能性を有しています。またデータのグループとなるTopicの構成やKafkaを利用するクライアントの設定如何によって全く異なるワークロードを同一クラスタ上で処理する事が可能です。本セッションでは、Kafkaのデータデータモデルとそれを扱う論理構成、Stream-Table Duality、そしてデータ整合性の考え方についてご説明します。","tags":["Slide","Kafka Core","Stream Processing"],"title":"カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632355200,"objectID":"14dffe6b3cacb271516d6b24517263d0","permalink":"https://confluent-jp.github.com/community/demo/demo-cp-splunk-elastic/","publishdate":"2021-09-23T00:00:00Z","relpermalink":"/community/demo/demo-cp-splunk-elastic/","section":"demo","summary":"ネットワーク機器のログをSplunkのUniversal Forwarderを利用してConfluentに転送し、ストリーム処理後にSplunkのHECに転送するサンドボックス環境。Splunk Universal Forwarderから送られるログを、Confluent内で機器ログ (CISCO ASA) とUniversal Forwarder自身のログ (SPLUNKD) にストリーム処理で分類。ストリーム処理にはksqlDBを利用。","tags":["Confluent Platform","ksqlDB","Splunk","Elasticsearch","SIEM","Stream Processing"],"title":"Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1413849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413849600,"objectID":"8b8adea67e39b4cbbef81d8aa4a3de58","permalink":"https://confluent-jp.github.com/community/publication/i-heart-logs/","publishdate":"2014-10-21T00:00:00Z","relpermalink":"/community/publication/i-heart-logs/","section":"publication","summary":"Confluent CEOであるJay Krepsによる、Kafkaの背景にある概念とログに関するアーキテクチャに関する考察です。 (英語)","tags":["ebook","Lambda Architecture","Stream Processing"],"title":"I ❤️ Logs","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"87b614131c7a4b56d410e37557a267de","permalink":"https://confluent-jp.github.com/community/publication/kafka-the-definitive-guide/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/publication/kafka-the-definitive-guide/","section":"publication","summary":"Kafka コミッター/PMCメンバーによる初めてのKafkaをメインに扱った書籍です。Kafkaのアーキテクチャからアプリケーションの設定、運用観点におけるベストプラクティス等、幅広い領域をカバーしています。 (英語)","tags":["ebook","Kafka Core","Kafka Connect","Stream Processing"],"title":"Kafka: The Definitive Guide","type":"publication"}]