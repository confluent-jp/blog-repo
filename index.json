[{"authors":null,"categories":null,"content":"","date":1692057600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1692057600,"objectID":"6c0805fdbd7621e3bbd425457215404c","permalink":"https://confluent-jp.github.io/community/authors/hashi/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/hashi/","section":"authors","summary":"","tags":null,"title":"hashi","type":"authors"},{"authors":null,"categories":null,"content":"","date":1690848e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1690848e3,"objectID":"7be59ae0d196dc1bbfb6c60c097b09ad","permalink":"https://confluent-jp.github.io/community/authors/stanislav/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/stanislav/","section":"authors","summary":"","tags":null,"title":"stanislav","type":"authors"},{"authors":null,"categories":null,"content":"","date":1689552e3,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1689552e3,"objectID":"d4ccb66a26bf2330497507875f5c9105","permalink":"https://confluent-jp.github.io/community/authors/kai/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/kai/","section":"authors","summary":"","tags":null,"title":"kai","type":"authors"},{"authors":null,"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1686614400,"objectID":"b0bc5dc322acaf3a4abf9d1fd4e8ac36","permalink":"https://confluent-jp.github.io/community/authors/akio/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/akio/","section":"authors","summary":"","tags":null,"title":"akio","type":"authors"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://confluent-jp.github.io/community/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/community/authors/admin/","section":"authors","summary":"","tags":null,"title":"admin","type":"authors"},{"authors":["hashi"],"categories":["Blog","Cluster Linking"],"content":"クラスタ間のレプリケーション - 一般的なアプローチ クラスタ間でデータのレプリケーションのニーズは古くからあり、DRや組織内のグループ会社間/事業部間の部分的なデータ共有、またはUberさんのActive-Active双方向レプリケーションの様な使い方もあります。いずれにせよ、何かしらの形でKafkaクラスタから他のクラスタにデータをレプリケートするという手法は変わらず、また利用できるツールも (多少の機能差異はありながらも) 基本的に同じアプローチを取っています。 基本的なアプローチはどのレプリケーションツールでも同じで、Producer/Consumerの両方を司るKafka Connectコネクタとして稼働します。SourceクラスタのTopicからConsumeし、DestinationクラスタのTopicにProduceする、理解し易いアプローチだと思います。当然SourceとDestinationのTopicは別々のものなのでPartition数を変える事も出来ますし、一般的なコネクタ同様SMTを利用する事も出来ます。\n同時に、Kafkaクラスタの外で双方にアクセス出来るコンポーネントを別途運用する必要性もあります。レプリケーションツールとKafkaブローカー間にはペイロードの圧縮/解凍処理を挟み、独立したConsume/Produce処理となる為レイテンシも比較的高くなります。またKafkaクラスタ同士がお互いを認識している訳ではなく、それぞれのクラスタに存在するTopic同士も機械的な関連性はありません。当然双方のTopicのConsumer Offsetは全く独立して管理されている為、TopicにアクセスするConsumerをクラスタを跨いで移動させる場合には、何かしらの方法でConsumer Offsetを変換する必要性も発生します。\nCluser Linking - クラスタを跨いだReplica Fetching Confluent Cluster Linkingのアプローチは大きく異なります。結果としてConsumer Offsetを含め全てのTopicに関するメタデータを完全に同期した状態でデータのレプリケーションが可能です。 仕組みとしては、同一クラスタ内におけるKafkaのレプリケーションの仕組みに近く、Replica Fetcherと近い形でDestinationクラスタにあるBrokerがクラスタ境界を跨いでフェッチする形でレプリケーションを行います。処理を仲介するものも、ワークロードの何かしらの受け渡しの様な処理も無いため、スループットも高く、また低レイテンシなレプリケーションが可能です。\n当然仲介用のConnectクラスタ等別途立ち上げる必要はありません。リンクの設置も、SourceもしくはDestinationクラスタであるConfluent CloudもしくはPlatformに対してリンク作成コマンドを実行すれば完了します。\n特徴と注意点 先にメリットについては記載しましたが、非同期レプリケーションではありながらSourceとDestinationのデータ差 (オフセット) がこれまでのアプローチよりかなり小さく、また安定的に同期出来るので、DR等の適用時において復旧/欠損対象となるデータ量を限定する事が出来ます。メタデータごと完全に同期しているのでクラスタ間のデータギャップやその復旧時の運用負荷も下がります。フェイルオーバーを考えると、Cluster Linkingを利用した場合にはオペレーションをかなり簡素化出来るのが特徴です。\n注意点 1 - 障害時にデータの欠損は起こり得る Cluster LinkingはMirrorMaker2等と比べると、確かに低レイテンシでデータの同期が可能です。しかしながらあくまで同期ではなく非同期のレプリケーションである為、RPO (Recovery Point Objective: 目標復旧地点) は0ではありません。Sourceクラスタにおいて、「書き込み完了と判断された後」かつ「その変更がDestinationクラスタ側からフェッチされるまで」にSourceクラスタがダウンしてしまう可能性はあり、この条件に合致する差分はSourceが再度復旧出来るまでアクセス出来ません。\n注意点 2 - TopicはPartition数を含め完全一致 DestinationクラスタにレプリケートされたTopicはMirror Topicと呼ばれる少し特殊なTopicです。具体的には：\n全Partitionのイベント数、イベント順序、各イベントのデータが全てSource Topicと全く同じとなる。 Read OnlyでありDestinationクラスタ内から書き込み不可。1 となります。 この為、例えばSourceクラスタのTopicからSMTを使って特定フィールドをマスキングしたり、Sourceと異なるPartition数をDestinationで指定する事は出来ません。\n注意点 3 - フェイルオーバー後の復旧はフェイルフォワードを推奨 Cluster LinkingではDR時にフェイルオーバーした際、基本的にDRであったクラスタを今度は本番と位置付けるようコマンドが整備されています。例えば東京リージョン (Prod) から大阪リージョン (DR) へのフェイルオーバー時に、大阪が本番リージョンとして機能します。その後東京リージョンが復旧した場合、フェイルバックするのではなく今度は東京をDRとして継続オペレーションを実施することを推奨しています。\nおわりに 上記に注意点を幾つか並べましたが、どれもCluster Linkingの欠点と言うよりは特性であり、つまりこの特性を充分理解した上でレプリケーション戦略を立てる事が大事です。\n注意点 1 - これは非同期レプリケーションである限り避けようがありません。逆に、非同期なのでSourceクラスタに対する書き込みレイテンシには影響を与えないメリットもあります。 注意点 2 - 通常のReplica Fetcherの仕組みと近いと考えると当然で、バイトレベルで同一のデータをDestinationクラスタ上に持てるというメリットを考えると納得出来る制約だと思います。 注意点 3 - これは意見が分かれるところかも知れません。データ基盤全体におけるBC戦略はKafkaのみのルールで決めれるものでは無いので、許容出来ないユースケースは多いと思います。ただ作業の手間が増えるだけで、フェイルバックする事は不可能ではありません。 他にも場合によってはMirrorMaker2やConfluent Replicatorの方が理に適った選択肢であるケースはあり、実際にもCluster LinkingではなくConfluent Replicatorを採用されるユーザーもいます。確かにCluster Linkingは画期的なレプリケーション機能ではありますが、その特性を理解した上で採用を判断する事が (何事に言える事ですが) 重要です。\n当然DR時にはMirror Topicを元にオペレーションを再開するので、その際はkafka-mirrors --failoverコマンドで書き込み出来るよう切り替えます。 ↩︎\n","date":1692057600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1692057600,"objectID":"d38329ae8f04fbf37cf3251d02b60473","permalink":"https://confluent-jp.github.io/community/blog/cluster-linking-demystified/","publishdate":"2023-08-15T00:00:00Z","relpermalink":"/community/blog/cluster-linking-demystified/","section":"blog","summary":"クラスタ間レプリケーションの新たなアプローチとその有効性について。","tags":["Replication","High Availability"],"title":"Confluent Cluster Linkingの仕組みについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"Tiered Storageとは 今年の後半にリリースが予定されているApache Kafka 3.6には、Tiered Storageと呼ばれるKafkaコミュニティが待ち望んだ新機能が含まれる予定です。この機能はKIP-405として何年も前に登録されたKIPであり、長い期間をかけてようやくリリース目処が経ちました。\nこれまでKafkaのデータは常にBrokerのストレージに格納されていましたが、これを二層化して古いセグメントを自動的に退避するという機能です。Kafkaに格納されたイベントをオブジェクトストレージに退避するというプラクティスは一般的であり、これまではKafka Connectコネクタを使って自分で退避させるアプローチを取っていました。これをKafkaネイティブな機能として提供する、その役割をKafka Brokerが行うというものです。クライアントからはこのオペレーションは隠蔽化されており、新しいイベントも古いイベントも同じアプローチでアクセスする事が出来ます。\nTiered Storageの動き - 図解 これまで通り、クライアントから送られたイベントはkafka Brokerのストレージにセグメント単位で保存されます。セグメントはログファイルであり、ランダムアクセスではなくアペンドでしかデータを足せない為、最も新しいセグメント (Active Segmentと呼ばれます) 以外のファイルは不可変 (Immutable) です。\nTiered Storageはこのうち古いセグメントを自動的にオブジェクトストレージに退避します。 中では新しくRemoteLogManagerと呼ばれるプロセスが、これまでのLogManagerに近い役割を果たしつつリモートストレージにコピーし、合わせてリモートストレージのインデックス状態のキャッシュを保持します。\n上にあるように、Broker側の保全期間 (Retention Period) を超過しセグメントが削除された後も、リモートストレージにはそのコピーが残ります。ストレージの動きはこれだけで、リモートからローカルにセグメントが戻ってくる様な事はありません。これまでのLog Managerの役割もそのままで、ローカルのログは今まで通り管理されます。\nほとんどのユースケースでは、クライアントは最新のセグメントに集中してアクセスします。 書き込みは当然最新であるActive Segmentにしか発生しませんが、読み込みも多少のラグはありながらもほぼ最新に近いセグメントへのアクセスとなります。このアクセスはこれまでと何も変わらず、今まで通りBrokerがディスクI/O経由でデータを取得しクライアントに帰します。\n違いは、クライアントが古いセグメントにあるオフセットを指定して読み込みをリクエストした場合です。 既にBrokerのローカルストレージにはセグメントは存在しませんが、リモートストレージに存在する限りBrokerはデータを取得しクライアントに返すことが出来ます。\nメリット 1 - 拡張性 (Scalability) Kafkaは拡張性に極めて優れたストリーミングプラットフォームであり、原則Brokerノードを追加することにより水平スケールする事ができます。一方、拡張には限界があります。一般的に大規模Kafkaクラスタにおけるボトルネックはネットワーク帯域で、次にストレージと言われています。これらを充分確保出来続ける限りKafkaクラスタは相当規模まで拡張出来ます。Tiered Storageによってストレージ容量の削減とより高度なコントロールが可能になります。\nKafkaにとってそれぞれのTopicの保全期間 (Retention Period) と書き込みスループットは基本的にはバランスゲームです - 高書き込みスループットの場合はストレージ容量の増加を加味してより短い保全期間を指定する必要があります。保全期間のデフォルトでは1週間、通常運用では1日という場合も多くありますが、高負荷のクラスタでは数時間程度に留める事も多くあります。\nkafkaは内部でデータのレプリケーションを行なっています。Replication Factorと呼ばれるこの設定のデフォルトは3であり、稀に金融やストレッチクラスタ (複数のサイトに跨がる大きなクラスタ) では4を指定する場合もありますが、ほとんどデフォルトのままではないかと思います。いずれにせよ、その指定分だけデータはレプリケートされるので、必要ディスク容量は増えます。\n例えば100MBpsで書き込みがなされる場合、レプリケーションも考慮するとクラスタ内のネットワーク帯域には300MBps、当然ストレージにも300MBpsのスピードで消費します。保全期間を1日とした場合、100 * 3600 * 3 = 1,080,000MB ≒ 1TBのストレージ容量が必要となります。書き込みスループットが倍になればストレージも倍、当然保全期間を倍にしてもストレージは倍必要になります。\nストレージがボトルネックになった場合、ディスクを足せば解消しますが、それも限界を超えるとBroker自体を追加する必要が出てきます。Tiered Storageを導入すると、Brokerが必要とするストレージの絶対量を制限できます。同一ハード構成におけるキャパシティを上げ、将来的な拡張性も高く出来ます。\nメリット 2 - 障害耐性 (Resiliency) ストレージを分離する事によって障害耐性が上がるというのはピンと来ないかも知れませんが、Tiered Stoargeによる効果と期待は障害耐性の向上にも集まっています。\nKafkaが何事もなく稼働している限り、またデータが適切にパーティションされている限り、Kafkaクラスタは均一にデータを分散配置し管理出来ます。しかしBrokerのシャットダウンと復帰は必ず発生します。時としてハードやソフトの障害によって、他ではBroker/JVM/Guest OS/Host OS/Host Hardwareのアップグレードによって、クラスタ構成は短期/長期的にその構成が変わります - Kafkaは絶えずメンバーシップを変えつつ稼働し続ける分散システムであり、構成が変わる前提の上で成立している技術です。\nBrokerがクラスタメンバーから外れると、それまでそのBrokerで保全していたデータは必ず何かしらの方法で他のBrokerに再配置されなければデータの保全性が保てません。この為クラスタメンバーシップの変更は、大規模なメタデータの更新と、データの移動を意味します。\nTiered Storageによって管理/移動対象となるセグメントの物理的な数が減れば、その分クラスタ内で移動するデータ量が減少し、また大量メタデータ更新に伴う二次災害の危険性も減少し、結果としてより安全に、より短い期間にクラスタが正常状態に復帰します。Kafkaクラスタ自体が軽量になればなるだけ、例えばコンテナの様により頻繁に刷新されるランタイム上でKafkaを運用する場合にも大きなメリットとなります。\nメリット 3 - リソースの有効活用 (Resource Utilization) Kafkaとは基本的にディスクI/Oへの負荷が高いプラットフォームです。これは書き込み/読み込みの発生頻度が高く、またディスクI/Oの有効利用が今回の設計思想に織り込まれています。併せて、Kafkaは原則マルチテナントプラットフォームであり、様々なワークロードが共存し易い (各々のワークロードの影響を受けにくい) ストリーミング基盤です。しかしながらKafkaにも物理的な制約は存在し、ワークロードのニーズ的にはクラスタ自体を分ける事も実際には多くあります。1\nTiered Storageへのアクセスは、Kafkaでは珍しくディスクI/OではなくネットワークI/Oへの比重が高い処理となります。例えば長期間実行するバッチ処理 (古いデータなのでTiered Storage経由) と、超低レイテンシな処理が求められるオンライン処理 (新しいデータなのでBrokerから) とではKafkaかかるリソース負荷が全く異なります。これら特性を上手く利用すれば、オンライン処理を実行しながら低負荷でバッチ処理を同一クラスタ内で扱う事も出来ます。2\nおわりに Tiered StorageはApache Pulserの様なコンピュートとストレージを完全に切り離す目的で導入される訳ではありません。Kafkaはある意味意図的に原始的な設計をしている点が長所であり、時として短所となり得る技術です。Tiered StoargeはKafkaが本来持つ高スループットかつ低遅延な処理能力を殺す事なく、短所であるディスク容量やディスクI/Oというボトルネックを軽減させ得る可能性を持った非常に有望な機能です。併せて、よりクラウドネイティブな環境で動く機会の増えたKafkaにとって、その新しい環境により適合性の高い機能であるとも言えます。\n例えば長期実行されるバッチ処理が継続してKafkaにアクセスしている状態で、非常にレイテンシ要件の高いオンライン処理が同居する様な場合です。 ↩︎\n当然、充分なネットワーク帯域が確保されている場合には、という条件は付きます。 ↩︎\n","date":169128e4,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":169128e4,"objectID":"68408a092777b66631fb8e9e96356bf1","permalink":"https://confluent-jp.github.io/community/blog/kip405-why-tiered-storage-important/","publishdate":"2023-08-06T00:00:00Z","relpermalink":"/community/blog/kip405-why-tiered-storage-important/","section":"blog","summary":"単純にストレージを分割するだけでない、Tiered Storageが見据える新しいKafkaと将来について。","tags":["Storage","High Availability","KIP"],"title":"Tiered Storageは何故そんなに重要なのか？","type":"blog"},{"authors":["stanislav","hashi"],"categories":["Kafka Core","Blog"],"content":" このブログエントリはKafkaコミッタである Stanislav Kozlovski(𝕏|Ln) のサイトで2022/11/06に公開されたKafka Acks Explainedの日本語訳です。Stanislav本人の了承を得て翻訳/公開しています。\nKafkaに関する仕事を始めて4年になりますが、経験上未だに2つの設定について広く誤解されていると感じる事があります。それはacksとmin.insync.replicasであり、さらにはこの2つの設定がどう影響し合うかについてです。このエントリはこの非常に重要な2つの誤解を解き、適切に理解してもらう事を目的としています。\nReplication この2つの設定を理解するためにはまずKafka Replicationプロトコルについて少しおさらいする必要があります。\nこのブログの読者の皆さんはある程度Kafkaについてご存知だと想定しています - もし自信がない場合はぜひThorough Introduction to Apache Kafkaもご参照ください。\n各Partitionには1つのLeader Broker(1)と複数のFollower Broker(N)がアサインされます。この複製の数はreplication.factorで設定する事ができ(1+N)つまり総数を表します。つまりこの設定では「対象となるPartitionに対してクラスタ上で何個の複製が出来るか」を指定します。\nデフォルトであり通常推奨する設定値は3です。 ProducerクライアントはLeader Brokerにのみ書き込みに行きます - つまりFollower Brokerへのレプリケーションは非同期に行われます。ここで分散システムとして考慮しないといけないのは、何かしらの方法で「これらレプリケーションされる処理がどのようにLeaderに追従すべきか」を指定する方法です。具体的には「Leaderに書き込まれた更新がFollowerにも反映されているか否か」です。\nIn-Sync Replicas in-sync replica(ISR)は対象Partitionの最新状態と同期が取れているBrokerを指します。当然Leaderは常にISRとなり、Followerの場合はLeaderの更新に追い付き同期が取れた状態のもののみISRとなります。仮にFollowerがLeaderに追従できなくなった場合、そのFollowerはISRではなくなります。 上の図ではBroker 3は同期されていないのでISRではない、つまりout-of-syncとなります。\nちなみに、厳密にはISRか否かという判断はもう少し複雑で、ここで説明されているようにすんなり「このFollowerは最新の状態か」と判断出来る訳ではありません。ただ厳密な話をし始めるとこのエントリの主旨から外れるので、ここでは上の図にある赤いBrokerは同期が取れていないと、見たまま捉えてください。\nAcks Acksはクライアント (Producer) 側の設定で、「どこまでFollowを含めて書き込みの確認が取れてからクライアントに返答するか」を指定するものです。有効な値は0、1、そしてallの3つです。\nacks=0 0が設定された場合、クライアントはBrokerまで到達したかの確認さえ行いません - メッセージがKafka Brokerに対して送られたタイミングでackを返します。 ackと呼びますがBrokerからの返答さえ待ちません。送れたらOKです。\nacks=1 1が設定された場合、クライアント (Producer) はLeaderにまでメッセージが到達した時点で書き込みの完了と判断します。Leader Brokerはメッセージを受け取った時点でレスポンスを返します。 クライアントはレスポンスが返ってくるのを待ちます。Leaderからの返答が到着した時点で完了と判断しackとします。Leaderは受け取り次第レスポンスを返すので、Followerへのレプリケーションはレスポンスとは非同期に処理されます。\nacks=all allと設定された場合、クライアントは全てのISRにメッセージが到達した時点で書き込みの完了と判断します。この際Leader BrokerがKafka側の書き込み判定を行なっており、全てのISRへのメッセージ到達の上クライアントにレスポンスを返します。 上の図の状態ではBroker 3はまだメッセージを受け取っていません。この為Leaderはレスポンスを返しません。 全てのISRに渡って初めてレスポンスが返されます。\nacksの機能性 この通りacksはパフォーマンスとデータ欠損耐性のバランスを決める非常に有益な設定です。データ保全を優先するのであればacks=allの設定が適切です。1 一方レイテンシやスループットに関する要件が極めて高い場合には0に設定すれば最も効率が良くなりますが、同時にメッセージロスの可能性は高まります。\nMinimum In-Sync Replicas acks=allの設定に関して、もう一つ重要な要素があります。\n例えばLeaderが全てのISRへの書き込み完了した上でレスポンスを返すとして、LeaderのみがISRだった場合、結果としてacks=1と振る舞いは同じとなるのでしょうか？\nここでmin.insync.replicasの設定が重要になります。\nmin.insync.replicasというBroker側の設定は、acks=allの際に「最低いくつのISRとなっているか (Leaderを含めて幾つのレプリカが最新状態か) を指定するものです。つまりLeaderは、acks=allのリクエストに対して指定されたISRに満たないまでは返答せず、またそれが何かしらの理由で達成できない場合にはエラーを返します。データ保全観点でのゲートキーバーの様な役割を果たします。\n上記の状態だとBroker 3は同期されていない状態です。しかしながらmin.insync.replicas=2となっている場合には条件を満たす為この時点でレスポンスが返されます。\nBroker 2と3が同期されていない状態です。この場合指定されたmin.insync.replicasを下回るためLeaderからはエラーレスポンスが返る、つまり書き込みは失敗します。一方同じ状況であってもacksの設定が0もしくは1の場合には正常なレスポンスが返されます。\n注意点 一般的にmin.insync.replicasは「Leaderがクライアントに返答する際に、どれだけレプリケーションが完了しているかを指定する」と解釈されていますが、これは誤りです。正確には「リクエストを処理する為に最低いくつのレプリカが存在するか」を指定する設定です。 上記の場合、Broker 1から3までが全て同期状態です。この時に新たなリクエスト (ここではメッセージ6) を受け取った場合、Broker 2への同期が完了してもレスポンスは返しません。この場合、処理時にISRとなっているBroker 3への同期が完了して初めてレスポンスが返されます。\nまとめ 図で説明したことによって理解が深まったのではないかと思います。\nおさらいすると、acksとmin.insync.replicasはKafkaへの書き込みにおける欠損体制を指定する事ができます。\nacks=0 - 書き込みはクライアントがLeaderにメッセージを送った時点で成功とみなします。Leaderからのレスポンスを待つことはしません。 acks=1 - 書き込みはLeaderへの書き込みが完了した時点で成功とみなします。 acks=all - 書き込みはISR全てへの書き込みが完了した時点で成功とみなします。ISRがmin.insync.replicasを下回る場合には処理されません。 その他情報 Kafkaは複雑な分散システムであり、学ばなければいけない事が多いのも事実です。Kafkaの他の重要な要素については以下も参考にしてください。\nKafka consumer data-access semantics - クライアント (Consumer) における欠損耐性、可用性、データ整合性の確保に関わる詳細。 Kafka controller - Broker間の連携がどの様になされるのかの詳細。特にレプリカが非同期 (Out-of-Sync) となるのはどういう条件下かについて説明しています。 “99th Percentile Latency at Scale with Apache Kafka - Kafkaのパフォーマンスに関するConfluent Blogエントリ。 Kafka Summit SF 2019 videos Confluent blog - Kafkaに関する様々なトピックを網羅。 Kafka documentation Kafkaは継続的かつアクティブに開発されていますが、機能追加や改善は活発なコミュニティにより支えられています。開発の最前線で何が起こっているか興味がある場合はぜひメーリングリスト に参加してください。\nこのエントリの著者であるStanislav Kozlovski は2 Minute StreamingというKafkaに関する隔週ニュースレターを発行しています。是非購読してみてください。\n(訳者注)ほとんどのユースケースではacks=allが適切であり、Kafkaのデフォルトでもあります。 ↩︎\n","date":1690848e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690848e3,"objectID":"29d13f61167d64758e7d240fbb183dfa","permalink":"https://confluent-jp.github.io/community/blog/kafka-acks-explained/","publishdate":"2023-08-01T00:00:00Z","relpermalink":"/community/blog/kafka-acks-explained/","section":"blog","summary":"KafkaのAcksを完全に理解する by Kafkaコミッタ。","tags":["Kafka Client","Translated"],"title":"Kafka Acks再入門","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Streaming AudioはConfluentがPodcast\u0026amp;YouTubeシリーズとして提供しています。毎回ゲストを迎え様々なトピックについてフリーにディスカッションするポッドキャストで、Kafka初期開発メンバーのJun RaoやKRaftの開発メンバー、Kafkaのリアルユーザー等様々なゲストスピーカーが参加します。中でも「アナネキ」ことAnna McDonald (Technical Voice of CUstomer @Confluent)登場回は毎回必見で、いつも何か新しい発見があります。\n今回はその彼女の登場回の中でも最も最近の回のご紹介です：お題は「Kafkaに本当にあったヤバいバグ5選1」です。(オリジナルの公開は2022/12/21) このトークで紹介されたJIRAバグの一覧を用意しました。結構最近になってようやく入ったものや、まだ直っていないものもあります。Kafkaのバージョンはなるべく追従する事を強くお勧めしていますが、ここにあるのは全体の一部で、なかなかに怖いバグへの修正も入っています。\nあなたのKafkaクラスタはほんとに大丈夫です？\nKAFKA-10888: Sticky partition leads to uneven product msg, resulting in abnormal delays in some partitions Status: Resolved (3.0.0)\nSticky Partitionerを使用時、Partition間の処理数に大きな偏りが出る様な状況となり特定のPartitionのスループットが極端に下がる事がある: 場合によってはリカバリ不能なほどProducer側のバッチが肥大化する。\nKAFKA-9648: Add configuration to adjust listen backlog size for Acceptor Status: Resolved (3.2.0)\nOSがLinuxの場合に発生。ローリングアップグレード等の際、BrokerからPartition Leaderが他のBrokerに移る、もしくは移ったのちに元のBrokerに戻る (Preferred Leader Election) が発生。この際Partitionに関するメタデータ更新が行われる為これらPartitionを参照するクライアントから一斉に再接続のリクエストが送られる。状況によってはLinuxのSYN cookieの機能が動きTCPバッファーが制限されスループットが大幅に低下する。これは再接続しない限り復旧しない。\nKAFKA-12686: Race condition in AlterIsr response handling Status: Resolved (3.0.0)\nPartition.scala内の処理において、AlterIsrResponseとLeaderAndIsrRequestのレースコンディションが起因。クラスタサイズが小さくPartition数が多い場合、Brokerノードの変更時に大量のPartition変更が発生する。この際AlterIsrManagerがペンディング状態のリクエストをクリアしてしまう為、AlterIsrResponseが戻ってきた際に処理中 (in Flight) であるのに処理タスク (Pending) が無いという矛盾状態が発生する。\nKAFKA-12964: Corrupt segment recovery can delete new producer state snapshots Status: Resolved (3.0.0)\nBrokerの停止時、猶予時間内に終了しない場合には Unclearn Shutdownと判断される。この際Broker復帰時に残っていたセグメントは不要と判断され非同期で削除が実行される。この削除が完了する前に同じオフセットのセグメントが書き込まれる状態となると、新しいProducer Stateスナップショットが誤って削除される事がある。\nKAFKA-14334: DelayedFetch purgatory not completed when appending as follower Status: Resolved (3.4.0, 3.3.2)\nConsumerがPulgatoryからフェッチするケースにおいて、通常通りPartitionリーダーからフェッチする場合には正しくフェッチの完了が認識される。しかしConsumerがフォローワーがフェッチする設定としている(KIP-932)場合、フォローワーのPartitionはPulgatoryに存在しない為フェッチ出来ずタイムアウトする。\nオリジナルは6選であり、ここではそのうちKAFKA-9211: Kafka upgrade 2.3.0 may cause tcp delay ack(Congestion Control)も含んでいますが、トークの中ではKafka-9646の中で合わせて語られているので割愛しました。 ↩︎\n","date":1690588800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1690588800,"objectID":"bfc2a40b146c9eab46ad969b34c54bd4","permalink":"https://confluent-jp.github.io/community/blog/streaming-audio-worst-kafka-bugs/","publishdate":"2023-07-29T00:00:00Z","relpermalink":"/community/blog/streaming-audio-worst-kafka-bugs/","section":"blog","summary":"Anna McDonaldによるKafkaのヤバいバグに関するトークです。日本語字幕でどうぞ。","tags":["Bugs"],"title":"Streaming Audio - Kafkaに本当にあった(まだある)ヤバいバグ5選","type":"blog"},{"authors":["kai","hashi"],"categories":["Blog","Use Cases"],"content":" このブログエントリはConfluent Field CTOであるKai Waeehnerのサイトで2022/1/4に公開された When NOT to use Apache Kafka?の日本語訳です。Kai本人の了承を得て翻訳/公開しています。\nApache Kafkaは、Data in Motionにおけるイベントストリーミングのデファクトスタンダードです。あらゆる業界でその採用が大きく伸びているため、私は毎週のように『ではApache Kafkaを使うべきでは無いのはどんな場合？』『ストリーム処理の基盤に重要な要素は？』『kafkaにこの機能性が無いのはなぜ？』『Kafkaを採用しないと判断する為の条件とは？』という質問を受けます。このブログ記事では、Kafkaを使うべき時、Kafkaを使うべきでない時、そしてKafkaを使うべきかもしれない時について順番に説明します。\n市場動向 - コネクテッド・ワールド まずは、なぜKafkaがいたるところで登場するのかを理解することから始めます。このことは、イベントストリーミングに対する市場の大きな需要を明らかにすると同時に、すべての問題を解決する銀の弾丸は存在しないことを示しています。Kafkaは繋がる世界 (コネクテッドワールド) の特効薬ではなく、重要なコンポーネントと捉える必要があります。\n世界はますます繋がりを広げています。膨大な量のデータが生成され、収益増加、コスト削減、リスク軽減のためにリアルタイムに関連付ける必要があります。この動きはどの業界でも進んでいますが、より速い業界もあれば遅い業界もあります。しかしこの繋がりはあらゆるところに届いています。製造業、スマートシティ、ゲーム 、小売、銀行、保険などどこでもです。私の過去のブログには、どの業界にも関連するKafkaの使用事例を見つけることができます。\n私はこのデータの急激な成長を、イノベーションと新しい最先端のユースケースの創出を示す2つのマーケットトレンドとして捉えています。(そしてKafkaの採用が業界を超えて急激である理由も併せて) 。\nコネクテッド・カー - 膨大な量のテレメトリデータとアフターセールス アライドマーケットリサーチの世界の機会分析と産業予測、2020-2027年 からの引用です: コネクテッドカー市場には、多くの人が考えているよりもはるかに幅広いユースケースと業界が含まれています。いくつか例を挙げると:ネットワークインフラとコネクティビティ、セキュリティ、エンターテインメント、小売、アフターマーケット、自動車保険、サードパーティデータ利用(スマートシティなど)。その他にも様々なユースケースが存在します。\nゲーミング - 数十億人のプレーヤーと巨額の収益 ゲーム産業はすでに他のすべてのメディア・カテゴリーを合わせたよりも大きくなっており、Bitkraftが描くように、これはまだ新しい時代の始まりに過ぎないとも言えます。 既に世界中で毎月何百万人もの新規プレイヤーがゲームコミュニティに参加しています。インターネットへの接続性と安価なスマートフォンは、それほど裕福でない国でも広く普及しています。 Play to Earnのような新しいビジネスモデルは、次世代のゲーマーのゲームの遊び方を変えており、5Gのような拡張性の高い低遅延技術が新たなユースケースを可能にしています。更にはブロックチェーンとNFT(Non-Fungible Token)は、マネタイズとコレクター市場を永遠に変えようとしています。\n業界を横断するこうした市場動向は、リアルタイムデータ処理のニーズが四半期ごとに大幅に増加している理由を明らかにしています。Apache Kafkaは分析およびトランザクションデータ ストリームを大規模に処理するためのデファクトスタンダードとしての地位を既に確立しています。しかしながら、Apache Kafkaとその周辺エコシステムの技術をプロジェクトで使用する(しない)タイミングを理解することも併せて非常に重要です。\nApache Kafkaとは何で、何では無いのか？ Kafkaは誤解されやすい技術です。例えばKafkaはメッセージキューだという話をいまだによく耳にします。その理由のひとつは、一部のベンダーが自社製品を売るために特定の問題(データレイクやデータウェアハウスへのデータ取り込みなど)に対してのみKafkaを売り込んでいるからだと思われます。\nKafkaは：\nスケーラブルなリアルタイム・メッセージング・プラットフォームで、毎秒数百万のメッセージを処理する。 大量のビッグデータ分析から少量のトランザクションデータ処理まで対応するイベント・ストリーミング・プラットフォーム。 分散ストレージは、背圧処理のための真のデカップリングを提供し、様々な通信プロトコルをサポートし、順序が保証されたイベントの再生可能性を提供する。 ストリーミングETLのためのデータ統合フレームワーク。 ステートレスまたはステートフルな連続ストリーム処理のためのデータ処理フレームワーク。 これら様々なユースケース/利用パターンを一つのプラットフォームで提供出来る点がKafkaの特徴です。\n一方以下はKafkaに当てはまりません：\n数百万を超えるクライアントからの直接接続 - Kafkaネイティブのプロキシ(RESTやMQTTなど)、いくつかのユースケースに対応しているが全てではない。 API管理プラットフォーム - これらのツールは通常補完的であり、Kafka APIの作成、ライフサイクル管理、または収益化のために使用される。 バッチ分析や複雑なクエリをサポートするDB - トランザクションクエリや比較的単純な集計(特にksqlDBを使用)では充分扱える。 デバイス管理を行うIoTプラットフォーム - MQTTやOPC-UAなどのIoTプロトコルとKafkaを直接統合することは可能であり、(一部の)ユースケースには適切なアプローチである。 ミリ秒レイテンシを達成するハード・リアルタイム・アプリケーションのための技術 (セーフティ・クリティカル・システムや決定論的システム) - ただ組み込みソフトウェアを除くと全てのプラットフォームが同様であり、Kafkaもその例外では無いというだけである。 このような理由から、Kafkaは他のテクノロジーと競合するものではなく、補完するものであると言えます。仕事に適したツールを選び、それらを組み合わせる上でKafkaは全体における重要な要素となり得ます。\nコネクテッドワールドにおけるApache Kafkaのケーススタディ ここではKafkaを他のテクノロジーと組み合わせることで、ビジネス上の問題を解決した素晴らしいサクセスストーリーの例をいくつか紹介します。エンドツーエンドのデータフローにKafka以上のものを必要とするケーススタディに焦点を当てています。\n私のブログ、Kafka Summitカンファレンス、MediumやDzoneのようなオンラインリソース、その他の技術関連のニュースなど、どれをフォローしても同じです。コネクテッドカー、IoTエッジデバイス、スマートフォンのゲーム/アプリなどからの大量のアナリティクスやトランザクショ・データをApache Kafkaでリアルタイム データストリー ミングする成功例をたくさん見つけることができます。\n業種や使用例をいくつか挙げてみます:\nAUDI - コネクテッドカー・プラットフォームが地域とクラウドプロバイダーを横断的に展開。 BMW - サプライチェーンとロジスティクスの最適化を実現するスマート工場。 SolarPower - 太陽光発電のソリューションとサービスを世界中で提供。 Royal Caribbian - エッジサービスとハイブリッド・クラウドの集約によるクルーズ船のエンターテイメント。 Disney+ Hotstar - インタラクティブなメディアコンテンツとゲーム/ベッティングをスマートフォンで数百万人のファンに提供。 このような素晴らしいIoTのサクセスストーリーにおいてKafkaは課題はあるかというと、問題無く非常に有機的に機能しています。しかしながら、Apache Kafkaエコシステムでイベントストリーミングを使用するタイミングと、他の補完的なソリューションを利用すべきかの判断について説明するためには、いくつか明確化が必要です。\nApache Kafkaを使うべき場合 Kafkaを使うべきでない場合について説明する前に、Kafkaを使うべき場所を理解し、必要に応じて他のテクノロジーと補完する方法とタイミングをより明確に説明します。ここから実例をユースケースごとに分けていくつかご紹介します。\nKafkaは大量のIoTやモバイルデータをリアルタイムかつ大量に扱う事ができる。 Teslaは単なる自動車メーカーではありません。Teslaは、革新的で最先端のソフトウェ アを数多く開発しているハイテク企業です。Teslaは自動車のためのエネルギーインフラも併せて提供しています。スーパーチャージャー、ギガファクトリーでの太陽エネルギー生産等も然りです。\n車両、スマートグリッド、工場からのデータを処理/分析し、残りのITバックエンドサービスとリアルタイムで統合することは、同社の成功に不可欠な要素です。\nTeslaはKafkaベースのデータプラットフォームインフラを構築し『1日あたり数百万台のデバイスと数兆のデータポイントをサポート』しています。テスラは2019年のKafka Summitで、彼らのKafka利用のな歴史とその進化について登壇しています。\n私はほとんどすべてのブログエントリでこのことを繰り返していますが、Kafkaは単なるメッセージングではないことを改めて強調させてください。Kafkaは分散ストレージレイヤーであり、プロデューサーとコンシューマーを真に分離し、さらにKafka StreamsやksqlDBのようなKafkaネイティブの処理ツールによってリアルタイム処理を可能にします。\nKafkaはIoTデータとMESやERPシステムからのトランザクションデータを結び付ける 規模の大きなリアルタイムでのデータ統合には、アナリティクスやERPやMESシステムのようなトランザクションシステムの利用に密接に関連しています。Kafka Connectやその他非Kafkaミドルウェアは、このタスクのためにイベントストリーミングのコアを補完する役割を果たします。\nBMWはエッジ(スマート工場など)とパブリッククラウドでミッションクリティカルなKafkaワークロードを運用しています。Kafkaはこれらシステムの疎結合性/透明性を高め活用によるイノベーションを可能にします。併せてConfluentの製品と専門知識により安定性を担保しています。後者は製造業での成功に不可欠です - 1分のダウンタイムによって組織に莫大なコストがかかリマス。関連記事Apache Kafka as Data Historian - an IIoT / Industry 4.0 Real-Time Data Lakeをご参照ください。Kafkaが製造業の総合設備効率(OEE)をどのように改善出来るか理解頂けると思います。\nBMWはリアルタイムでサプライチェーン管理を最適化しています。このソリューションは、物理的にもBMWのERP(SAP搭載)のようなトランザクションシステムにおいても、 適切な在庫に関する情報を提供します。「Just-in-Time/Just-in-Sequence」は、多くのアプリケーションにとって極めて重要です。KafkaとSAPの統合は、この分野で私が話をする顧客のほぼ半分で必要とされています。また、統合だけでなく多くの次世代トランザクションERPやMESプラットフォームもKafkaを利用しています。\nKafkaはエッジや …","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"5b03cf7f03ccd2d5a0d24dbbe2a8bf05","permalink":"https://confluent-jp.github.io/community/blog/when-not-to-use-kafka/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/when-not-to-use-kafka/","section":"blog","summary":"具体的なユースケースから紐解く、Kafkaが向くとき、向かないとき。","tags":["Edge computing","IoT","Translated"],"title":"Kafkaの利用が適さないユースケースとは？","type":"blog"},{"authors":["hashi"],"categories":["Announcement","developer.io"],"content":"developer.confluent.ioにてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。\nUXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto BrandoliniによるEvent Sourcingと近い思想によるデザイン手法の一つです。\nマイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。\n","date":1689552e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1689552e3,"objectID":"ee151f0b106404b801569afa95f0a6a7","permalink":"https://confluent-jp.github.io/community/blog/developer-io-event-modeling/","publishdate":"2023-07-17T00:00:00Z","relpermalink":"/community/blog/developer-io-event-modeling/","section":"blog","summary":"developer.confluent.ioにて新しいEvent Modelingに関するコースが公開されました。","tags":["Stream Processing"],"title":"新コース - Event Modeling","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに メッセージブローカー界隈でのデリバリー保証はAt Least Once (必ず送信するが1度以上送信する可能性がある) というのが常識であり、データを受け取るConsumer側で冪等性を保証する必要がありました。そのExactly Once SemantisがKafkaでサポートされた時には多くの反響を呼びましたが、この設定は最近DefaultでOnになる程Kafkaコミュニティでは広く利用されています。\nただこのエンハンスメントにも制限がありました。この制限は後日、ひっそりと一つのPRによって解消されています。話題には上りませんでしたが、この機能が広く利用される上では非常に重要なエンハンスメントでした。\nExactly Once Semantics Kafka初期において最も注目を集めたエンハンスメントの一つにKIP-98 - Exactly Once Delivery and Transactional Messaging があります。「メッセージ基盤においてExactly Onceは不可能」というビザンチン将軍問題観点からの懐疑的な意見も多く議論を呼びました。そもそもKafkaが唱えるExactly Onceのスコープは何か、そして何がその前提となっているのかについてはKafka初期開発者であるネハさんを始めとして具体的な説明もたくさんなされています。1\n実際のKIPに記載されている設定条件は以下で、これらも同様に適切に設定しない限りはenable.idempotency=trueと設定してもProducerの冪等性を確保する保証はないと記載されています (仮にIdempotent Producerとして動いてPIDに値が設定されているとしても)。\nack=all retries \u0026gt; 1 max.inflight.requests.per.connection=1 必ずISRへの同期が完了し、エラー時にはリトライする様にし、かつProducerからの並列送信は許容しない、という条件です。理には適っています。\nKAFKA-5494 KAFKA-5494: enable idempotence with max.in.flight… このPRではKIP-98実装における課題の説明と、それに対する解決策が記載されています。具体的には2つの課題への対応が纏まったPRとなっており、結果としてmax.in.flight.requests.per.connectionが1である制限を最大5まで増やす対応となっています。2\n対応としてのポイントは、Brokerとの通信途絶時のProducer側 (Client) のシーケンス番号の採番ルールです。送信エラーとなった場合にはシーケンス番号を採番し直す事により処理を自動復旧すること、また再採番の前に送信処理中のバッチが全て処理済みである確認等が考慮されています。3\nおわりに KIPではなくPRとして実装されたこの変更ですが、シーケンス例外が出た際に事後復旧出来るようになる事、max.in.flightを1より大きく指定できる事、より広くIdempotent Producerを利用する上で重要な改善が含まれています。\nオリジナルのデザイン資料はここにあります。 ↩︎\n合わせてOutOfSequenceExceptionが発生してしまうとクライアント側での後続処理は全て同じ例外が発生する課題についても対応されています。 ↩︎\nまたこのPRに関する前提情報や設計については別途こちらにまとめられています。 ↩︎\n","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"74df3beba2a5f9987b985eed649fa9ac","permalink":"https://confluent-jp.github.io/community/blog/idempotent-producer-and-max-inflight/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/community/blog/idempotent-producer-and-max-inflight/","section":"blog","summary":"Exactly Once Deliveryに関わる重要な変更がKIP-95にて対応されて暫く経ちます。仕組み上Producer側の並列送信数は1に設定する必要がありましたが、後日のエンハンスメントで最大5まで対応出来る事になっています。","tags":["Exactly Once Semantics","KIP"],"title":"Exactly Onceとmax.in.flightについて","type":"blog"},{"authors":["hashi"],"categories":["Blog","Kafka Core"],"content":"はじめに Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。KIP-932 Queues for Kafka はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。\nConsumer Group Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。\nConsumer Groupはアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。\n一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。\nこれまでのアプローチ ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。\nLINE Decaton はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。\nConfluent Parallel Consumer はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、順序保証しない設定を含め柔軟に処理構成を変更することが出来ます。\nQueue for Kafka - Kafka Nativeなアプローチ Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。\nShared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、group.typeをshare1と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。\nConsumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。\nおわりに Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。\ngroup.typeは新しいプロパティ。デフォルトはconsumerであり、この指定だと通常通りConsumer Groupとして機能する。デフォルトはconsumerである為下位互換性あり。 ↩︎\n","date":1688083200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688083200,"objectID":"acf7b7266e27328e86367517f7aad12b","permalink":"https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/","publishdate":"2023-06-30T00:00:00Z","relpermalink":"/community/blog/kip923-queues-for-kafka/","section":"blog","summary":"KIP-932として登録されているQueues for Kafka。「Kafkaはメッセージキューなのに何を今更？」という疑問も伺いますが、Kafkaは本質的にはメッセージキューではありません。そのKafkaにとってKIP-932はどういう変更なのかについて説明します。","tags":["Stream Processing","Scalability","KIP"],"title":"Queues for Kafkaとは何か?","type":"blog"},{"authors":["akio"],"categories":null,"content":"","date":1686614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1686614400,"objectID":"34e0abbb19e1754f47c2421fc8d19739","permalink":"https://confluent-jp.github.io/community/talk/20230613-kafka-meetup/","publishdate":"2023-06-13T00:00:00Z","relpermalink":"/community/talk/20230613-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #13 - Apache Kafka Meetup Japan #13の発表資料です。2023年6月16日(JST)時点での、Apache Kafkaのアップデートやロードマップを紹介しています。","tags":["Slide","Kafka Update","KRaft","Kafka Core"],"title":"Apache Kafka 最新アップデート ~ What's New \u0026 What's Next","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":16848e5,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":16848e5,"objectID":"9140c62cab6d1127267a20beb29b158b","permalink":"https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/","publishdate":"2023-05-23T00:00:00Z","relpermalink":"/community/talk/20230523-eventdriven-meetup/","section":"talk","summary":"Event Driven Meetup #1 - イベント駆動というアプローチに対し、ストリームという文脈を持たせた上で処理をする概念とApache Kafkaのアプローチについてご紹介します。今回は特にExactly Once Semantics (全てのイベントを重複なく1度だけ処理する) というストリーム処理のゴールに対して、Kafkaがトランザクションの概念をどう導入したかについて 踏み込んでご説明します。","tags":["Slide","Operations","Kafka Core","Transaction","Exactly Once Semantics","Event Driven Architecture","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1671148800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671148800,"objectID":"030655d1a1a2bc308cdbf50f71fc6252","permalink":"https://confluent-jp.github.io/community/talk/20221226-kafka-meetup/","publishdate":"2022-12-16T00:00:00Z","relpermalink":"/community/talk/20221226-kafka-meetup/","section":"talk","summary":"Kafka Meetup JP #12 - 登壇資料Kafkaの活用が進みミッションクリティカルなワークロードを扱うようになると、Kafkaの持つ障害耐性を超えたSLAを目指すケースも見受けられます。本トークでは、Kafkaにおける基本的なHA/DRの概念やアプローチと、複数データセンター（or Cloud）を跨がる大規模な構成についてお話しします。","tags":["Slide","Operations","Availability","DR","Multi Region Cluster","Cluster Linking"],"title":"Hish SLA Kafka - Kafka Across Multiple DCs","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1668988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668988800,"objectID":"17f18e827864f20c2756a8cf75c85c53","permalink":"https://confluent-jp.github.io/community/talk/20221121-cloudnativedays-tokyo/","publishdate":"2022-11-21T00:00:00Z","relpermalink":"/community/talk/20221121-cloudnativedays-tokyo/","section":"talk","summary":"Cloud Native Days Tokyo 2022 - 本セッションでは、今も進化を続けるApahce Kafkaの構造的な仕組み、そしてこれまでどの様な進化を遂げて今に至るのかをインフラ的な観点からお話しします。中でもKafkaの構成上必要なZookeeperへの依存をどの様に断ち切ったのか、KIP-500と呼ばれる3年に渡る取り組みについて詳しくご紹介します。","tags":["Slide","Recording","Operations","Availability","KRaft","Tiered Storage"],"title":"Cloud Native Kafka - 分散データ基盤がクラウドネイティブを目指すということ","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1666656e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1666656e3,"objectID":"9615648e7d05c78d0f462937e6ae2e19","permalink":"https://confluent-jp.github.io/community/talk/20221025-yugabytedb-japan-hour/","publishdate":"2022-10-25T00:00:00Z","relpermalink":"/community/talk/20221025-yugabytedb-japan-hour/","section":"talk","summary":"YugabyteDB Japan Hour #5 - モダナイゼーションという文脈ではマイクロサービスやDevOps、サーバーレスといったランタイムや手法に関する議論が多く見受けられます。一方実際のモダナイゼーションを検討する際にはアプリケーションのデータストアならびに他システムとのデータ連携も同様に重要な検討課題となります。本セッションでは様々なモダナイゼーションの手法と、特にデータ周りのモダナイゼーションをどう進めるかについてお話しします。","tags":["Slide","Recording","Kafka Connect","Change Data Capture","Modernization"],"title":"Apache Kafka®️ and Modernization - How Old Data Meets New Data","type":"talk"},{"authors":["akio"],"categories":null,"content":"","date":1659052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659052800,"objectID":"5f960ba5fb5b631ef927d48a2807ea09","permalink":"https://confluent-jp.github.io/community/talk/20220729-osc-kyoto-2022/","publishdate":"2022-07-29T00:00:00Z","relpermalink":"/community/talk/20220729-osc-kyoto-2022/","section":"talk","summary":"OSC Kyoto Online 2022の発表資料です。初心者向けにApache Kafkaの概要を解説しています。","tags":["Slide","Recording","Beginner"],"title":"イベントストリーミング入門 〜Apache Kafkaを活用した大規模リアルタイムデータ処理〜","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1653350400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653350400,"objectID":"a5d2b42a4a7dbbc792a91e68ef25281e","permalink":"https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/","publishdate":"2022-05-24T00:00:00Z","relpermalink":"/community/talk/20220524-gcpug-tokyo/","section":"talk","summary":"GCPUG Tokyo Queue Day 2022 May - Apache Kafkaはイベント駆動の領域で広く活用されています。一つの大きな特徴は、イベントが連なる『ストリーム』をコア概念としている点であり、概念だけでなく構造自体もストリームを扱う少し変わった設計がなされています。この為一般的なイベント駆動アーキテクチャの様に見えて、他のアプローチでは難しいユースケースで利用されたり、より複雑なエコシステムを形成することが出来ます。 本セッションでは、ストリームを支えるKafkaの内部構造と、その特徴を活用した「広がるストリーミング・エコシステム」のアプローチと事例についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Apache Kafka and the World of Streams","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1651190400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1651190400,"objectID":"7169ad42fe68c2e8b43a90f53ca7f579","permalink":"https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/","publishdate":"2022-04-29T00:00:00Z","relpermalink":"/community/talk/20220414-bigdata-jaws/","section":"talk","summary":"BigData-JAWS 勉強会#20 - 加速度的に広がるデータのサイズや種類に対して、様々なデータストアやデータ基盤を活用して、これまで不可能だった体験や新たな価値を提供する。この無理ゲーに対して、我々はより大きなデータストアを求め、より高い並列処理能力を駆使する挑戦を続けています。本セッションでは少し異なる観点 - 分散するデータをメッシュとして繋ぐ、Apache KafkaとksqlDBによるDatabase Inside Outの概念についてお話しします。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"0b5d143c5efeaf1128d1dfffc31f579a","permalink":"https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220325-cloudnative-database/","section":"talk","summary":"Cloud Native Databse Meetup #4 - ksqlDBはKafkaを利用する事を前提としたストリーム処理エンジンです。 『DB』という名前が付いてはいますが、DBでありながらストリーム処理エンジンでもある少し変わった個性を持つ技術です。Kafkaエコシステムの中でKafka Streamsと共に育った技術ですが、ストリーム処理の枠を超えてDBとしての道を歩み始めています。KafkaとKafka Streamsと強いつながりを持つksqlDBは、その特性を理解することで長所を生かした活用が可能です。","tags":["Slide","Recording","Beginner","ksqlDB","Stream Processing"],"title":"KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1648166400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1648166400,"objectID":"739a23b908c98d2a045e1d38b0887d16","permalink":"https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/","publishdate":"2022-03-25T00:00:00Z","relpermalink":"/community/talk/20220217-developers-summit-2022/","section":"talk","summary":"Developers Summit 2022 - 本セッションでは分散システムにおけるデータ整合性と、それを支えるApache Kafkaの役割についてご説明します。また将来のステップとして、ドメイン駆動化されたデータを「Data as a Product」として横断的に活用するData Meshの構想についてご説明します。","tags":["Slide","Recording","Microservices","Data Mesh","Stream Processing"],"title":"マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632873600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632873600,"objectID":"6d8cd7b9d2759e74017c69af5a985b8a","permalink":"https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/","publishdate":"2021-09-29T00:00:00Z","relpermalink":"/community/demo/demo-cc-ksql-clickstream/","section":"demo","summary":"Confluent Cloudを利用してクリックストリームのデータを加工/分析するワークショップです。クリックストリーム用のテストデータの作成とksqlDBによるStream/Tableの利用方法、Pull Queryの基本的な使用方法等を体験いただけます。","tags":["Confluent Cloud","ksqlDB","Stream Processing","DataGen Connector","Stream Lineage"],"title":"ksqlDB Clickstream Workshop","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1632441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632441600,"objectID":"78e2b3fb66a4ad4e47a50b19563fdd79","permalink":"https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/","publishdate":"2021-09-24T00:00:00Z","relpermalink":"/community/talk/20210924-kafka-meetup/","section":"talk","summary":"Apache Kafkaはメッセージブローカーであると同時にストレージの役割も果たす、それまでのMQの世界観とは少し異なった機能性を有しています。またデータのグループとなるTopicの構成やKafkaを利用するクライアントの設定如何によって全く異なるワークロードを同一クラスタ上で処理する事が可能です。本セッションでは、Kafkaのデータデータモデルとそれを扱う論理構成、Stream-Table Duality、そしてデータ整合性の考え方についてご説明します。","tags":["Slide","Kafka Core","Stream Processing"],"title":"カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて","type":"talk"},{"authors":["hashi"],"categories":null,"content":"","date":1632355200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632355200,"objectID":"14dffe6b3cacb271516d6b24517263d0","permalink":"https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/","publishdate":"2021-09-23T00:00:00Z","relpermalink":"/community/demo/demo-cp-splunk-elastic/","section":"demo","summary":"ネットワーク機器のログをSplunkのUniversal Forwarderを利用してConfluentに転送し、ストリーム処理後にSplunkのHECに転送するサンドボックス環境。Splunk Universal Forwarderから送られるログを、Confluent内で機器ログ (CISCO ASA) とUniversal Forwarder自身のログ (SPLUNKD) にストリーム処理で分類。ストリーム処理にはksqlDBを利用。","tags":["Confluent Platform","ksqlDB","Splunk","Elasticsearch","SIEM","Stream Processing"],"title":"Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境","type":"demo"},{"authors":["hashi"],"categories":null,"content":"","date":1522540800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1522540800,"objectID":"a3fe7c0a03c9e94bb67cc16ab71c0501","permalink":"https://confluent-jp.github.io/community/publication/designing-event-driven-systems/","publishdate":"2018-04-01T00:00:00Z","relpermalink":"/community/publication/designing-event-driven-systems/","section":"publication","summary":"イベント駆動アーキテクチャを、ストリーム処理というより包括的なアプローチで解決する手法についての本です。イベントの種類やイベント駆動におけるアーキテクチャ概論、CQRSやステートフル処理まで踏み込んで解説しています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Designing Event-Driven Systems","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1506988800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1506988800,"objectID":"87b614131c7a4b56d410e37557a267de","permalink":"https://confluent-jp.github.io/community/publication/kafka-the-definitive-guide/","publishdate":"2017-10-03T00:00:00Z","relpermalink":"/community/publication/kafka-the-definitive-guide/","section":"publication","summary":"Kafka コミッター/PMCメンバーによる初めてのKafkaをメインに扱った書籍です。Kafkaのアーキテクチャからアプリケーションの設定、運用観点におけるベストプラクティス等、幅広い領域をカバーしています。 (英語)","tags":["ebook","Kafka Core","Kafka Connect","Stream Processing"],"title":"Kafka: The Definitive Guide","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1456790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1456790400,"objectID":"37c699b46dbbd999259987106c20daa4","permalink":"https://confluent-jp.github.io/community/publication/making-sense-of-stream-processing/","publishdate":"2016-03-01T00:00:00Z","relpermalink":"/community/publication/making-sense-of-stream-processing/","section":"publication","summary":"『データ指向アプリケーションデザイン』の著者であるクレップマン博士によるストリーム処理、中でもKafkaを利用した新たなイベント駆動モデルの概要についての入門書です。『Database Inside Out (データベースの内部構造を広く展開する)』の概念とその可能性について詳しく説明されています。 (英語)","tags":["ebook","Kafka Core","CQRS","Stream Processing"],"title":"Making Sense of Stream Processing","type":"publication"},{"authors":["hashi"],"categories":null,"content":"","date":1413849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1413849600,"objectID":"8b8adea67e39b4cbbef81d8aa4a3de58","permalink":"https://confluent-jp.github.io/community/publication/i-heart-logs/","publishdate":"2014-10-21T00:00:00Z","relpermalink":"/community/publication/i-heart-logs/","section":"publication","summary":"Confluent CEOであるJay Krepsによる、Kafkaの背景にある概念とログやストリーム処理アーキテクチャに関する考察です。 (英語)","tags":["ebook","Lambda Architecture","Stream Processing"],"title":"I ❤️ Logs","type":"publication"}]