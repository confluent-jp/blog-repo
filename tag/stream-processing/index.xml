<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Stream Processing | Confluent Japan Community</title><link>https://confluent-jp.github.io/community/tag/stream-processing/</link><atom:link href="https://confluent-jp.github.io/community/tag/stream-processing/index.xml" rel="self" type="application/rss+xml"/><description>Stream Processing</description><generator>Wowchemy (https://wowchemy.com)</generator><language>ja-jp</language><lastBuildDate>Thu, 02 Nov 2023 00:00:00 +0000</lastBuildDate><image><url>https://confluent-jp.github.io/community/media/icon_hubade5daff97c80353b10ab16b141ee15_5385_512x512_fill_lanczos_center_3.png</url><title>Stream Processing</title><link>https://confluent-jp.github.io/community/tag/stream-processing/</link></image><item><title>ストリーム処理でKafka TopicのKeyを扱う in KSQL</title><link>https://confluent-jp.github.io/community/blog/handling-keys-in-ksql/</link><pubDate>Thu, 02 Nov 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/handling-keys-in-ksql/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Kafkaをベースとしたストリーム処理では、Kafka Topicに流れるイベントを取り込み、処理後に別のTopicに書き込む事を繋げる事によりパイプラインを構築します。ksqlDBの様なストリーム処理基盤はこの処理を開発者から隠蔽化し、SQLを用いてそのロジックのみに注力できるよう補助してくれます。&lt;/p>
&lt;p>一方、この隠蔽化によってksqlDBが行なっている内部処理の多くは開発者にはタッチする事が出来ず、出来た場合でも直感的に扱えない事も多くあります。Kafka TopicのKeyもその一つです。&lt;/p>
&lt;p>今回はksqlDBにおけるStreamの概念と、Topic Keyを扱う方法について説明します。&lt;/p>
&lt;h2 id="streamとtable">StreamとTable&lt;/h2>
&lt;p>ksqlDBのストリーム処理では、Topicと紐付けるデータモデルを定義しそのモデルに対してクエリを実行する形でデータにアクセスします。具体的には&lt;code>Stream&lt;/code>と&lt;code>Table&lt;/code>で：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>STREAM&lt;/strong> - Topicを流れるイベントを、時系列を維持したデータの流れとして体現。ステートレス。&lt;/li>
&lt;li>&lt;strong>TABLE&lt;/strong> - Topicを流れるイベントからKey単位でデータの最新状態をマテリアライズ。ステートフル。&lt;/li>
&lt;/ul>
&lt;p>同じKafka上で扱うデータですが、モデルによってksqlDBにおける扱いも、そしてそれを支える内部の仕組みも異なります。&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> ただksqlDBのクエリ上はどちらも&lt;code>CREATE&lt;/code>構文を利用してSQL同様の手順で作成します。例としてStreamの定義のサンプルは以下の様になります。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Clickstream&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REMOTE_USER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REQUEST&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REFERRER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">AGENT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;datagen-topic&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ここでは&lt;code>datagen-topic&lt;/code>というJSONでシリアライズされたTopicに対して&lt;code>Clickstream&lt;/code>という名前のStreamデータモデルを定義しています。&lt;/p>
&lt;h4 id="csasとctas">CSASとCTAS&lt;/h4>
&lt;p>Topicをモデル化したStreamやTableを定義したとして、今度はそのモデルに対して処理をする必要性が出てきます。一般的なデータフロープログラミングのモデルではプログラム内で処理をチェイニングした結果を別Topicに出力しますが、SQLにはそのような構文モデルはありません。一方リレーショナルDBではストアドプロシージャを利用しますが、DB毎にその仕様は異なります。&lt;/p>
&lt;p>ksqlDBではもっと汎用的な&lt;code>SELECT&lt;/code>と&lt;code>CREATE STREAM&lt;/code>を組み合わせる事により処理とストアを結びつけます。具体的には&lt;code>CREATE STREAM AS SELECT&lt;/code>構文を利用します。&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">EventsWithoutKey&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;404events&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SELECT&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TIME_IN_INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Clickstream&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">WHERE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="s1">&amp;#39;404&amp;#39;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">EMIT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHANGES&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>ここでは前述した&lt;code>Clickstream&lt;/code>というStreamから必要なカラムを指定してSELECTした結果を新たなStreamとして定義する処理です。ここではWHERE句を利用してフィルタリングした結果のみ抽出し、かつ新たに&lt;code>404events&lt;/code>というTopicに対して出力しています。物理的には&lt;code>Clickstream&lt;/code>に紐付く&lt;code>datagen-topic&lt;/code> Topicにあるデータが変換/加工され&lt;code>404events&lt;/code>という新たなTopicに登録されます。&lt;/p>
&lt;p>当然この構文はksqlDBでのストリーム処理には頻出構文であり、CSAS (&lt;code>CREATE STREAM AS SELECT&lt;/code>)、CTAS (&lt;code>CREATE TABLE AS SELECT&lt;/code>)と呼ばれます。&lt;/p>
&lt;h4 id="keyとデータモデル">Keyとデータモデル&lt;/h4>
&lt;p>&lt;code>CREATE STREAM&lt;/code>と&lt;code>CREATE TABLE&lt;/code>ではTopicのKeyの扱い方が異なります。&lt;/p>
&lt;p>以前のバージョンではStreamでもTableでも&lt;code>ROWKEY&lt;/code>という名称でTopicのKeyに紐づくフィールドをモデルに追加します。この&lt;code>ROWKEY&lt;/code>は物理的にはTopicのKeyでありながら、Valueを扱うksqlDBから参照出来るという、他のフィールドとは扱いも振る舞いも異なります。また、コミュニティではこの勝手に追加される&lt;code>ROWKEY&lt;/code>というフィールドの扱い方に関して多くの混乱を招きました。ストリーム処理をSQLで処理をする上では直感的では無いという判断でした。&lt;/p>
&lt;p>このKeyの扱い方は&lt;a href="https://www.confluent.io/blog/ksqldb-0-10-updates-key-columns/#keyless-streams" target="_blank" rel="noopener">ksqlDB 0.10で大きく変わりました&lt;/a>。これは一律ではなくStreamとTableで定義を変える事で：&lt;/p>
&lt;ul>
&lt;li>&lt;strong>CREATE TABLE&lt;/strong> - 明示的にKeyを指定する必要があり、それには&lt;code>PRIMARY KEY&lt;/code>と指定するフィールドが必要。&lt;/li>
&lt;li>&lt;strong>CREATE STREAM&lt;/strong> - キーをそもそも指定しない。&lt;/li>
&lt;/ul>
&lt;p>このアプローチはTABLEの構文としても自然であり、かつSTREAMを扱う際にはKeyが存在すらしないという潔いものです。結果としてこの変更と思想が以降のksqlDBのコミュニティに広がりました。&lt;/p>
&lt;h2 id="streamとkey">StreamとKey&lt;/h2>
&lt;p>それでもStreamでKeyを扱いたいというのが本エントリの主旨です。&lt;/p>
&lt;p>実際にStreamでKeyを指定する必要性がある場合は存在し、具体的には&lt;a href="https://docs.ksqldb.io/en/latest/developer-guide/joins/partition-data/#keys" target="_blank" rel="noopener">JOINの際にはKey指定したものしかJOIN出来ません&lt;/a>。この為StreamでもKeyを指定する事は可能になっています。&lt;/p>
&lt;p>具体的にはフィールドに&lt;code>Key&lt;/code>と指定する事により、そのフィールドをValueの一部ではなくKeyとして扱います。先程の&lt;code>CREATE STREAM&lt;/code>を例に取ると：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ClickstreamWithKey&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">Key&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REMOTE_USER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REQUEST&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">REFERRER&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">AGENT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="nb">VARCHAR&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;datagen-topic&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">);&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>同じTopicを参照していますが、ここで生成されるStreamにはレコードKeyに&lt;code>IP&lt;/code>が指定され、と言うよりValueからKeyに移動します。&lt;/p>
&lt;p>この振る舞いを実際に確認するには&lt;code>CSAS&lt;/code>で再定義したものに新たなTopicを割り当て、その結果を比較する必要があります。これら2つのStreamに以下のCSASを適用すると：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TransformedEvents&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;events&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SELECT&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TIME_IN_INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">Clickstream&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="c1">-- Keyがある方はClickstreamWithKeyと指定
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="c1">&lt;/span>&lt;span class="n">EMIT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHANGES&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>通常の&lt;code>CREATE STREAM&lt;/code>で生成した場合、Topicには
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM without Key - Key" srcset="
/community/media/blogs/handling-keys-in-ksql/keyless-key_huc56dfe2a7de818cca4a10762291b8507_8953_ecfa51475f8ff3a419613f69c09fc1ca.webp 400w,
/community/media/blogs/handling-keys-in-ksql/keyless-key_huc56dfe2a7de818cca4a10762291b8507_8953_8f8d9bc9cc3660c85c6b11ccd6ac1e19.webp 760w,
/community/media/blogs/handling-keys-in-ksql/keyless-key_huc56dfe2a7de818cca4a10762291b8507_8953_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/keyless-key_huc56dfe2a7de818cca4a10762291b8507_8953_ecfa51475f8ff3a419613f69c09fc1ca.webp"
width="760"
height="107"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM without Key - Value" srcset="
/community/media/blogs/handling-keys-in-ksql/keyless-value_hub62a909993c35cf3e9faf6edd4064341_22835_acd0bf529162173000fa253a496ad6ca.webp 400w,
/community/media/blogs/handling-keys-in-ksql/keyless-value_hub62a909993c35cf3e9faf6edd4064341_22835_417c284ab3b5a3aea8d4eea4c5356152.webp 760w,
/community/media/blogs/handling-keys-in-ksql/keyless-value_hub62a909993c35cf3e9faf6edd4064341_22835_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/keyless-value_hub62a909993c35cf3e9faf6edd4064341_22835_acd0bf529162173000fa253a496ad6ca.webp"
width="760"
height="227"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
となり、&lt;code>Key&lt;/code>を指定したStreamに対する&lt;code>CSAS&lt;/code>の結果は
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM with Key - Key" srcset="
/community/media/blogs/handling-keys-in-ksql/withkey-key_hu9e69a7ba4db462c29de818c1fc309f8f_10708_df18645726bb440f01116ec0287989d7.webp 400w,
/community/media/blogs/handling-keys-in-ksql/withkey-key_hu9e69a7ba4db462c29de818c1fc309f8f_10708_dea25a34e37ae0696ff0e8d268b7112b.webp 760w,
/community/media/blogs/handling-keys-in-ksql/withkey-key_hu9e69a7ba4db462c29de818c1fc309f8f_10708_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/withkey-key_hu9e69a7ba4db462c29de818c1fc309f8f_10708_df18645726bb440f01116ec0287989d7.webp"
width="760"
height="122"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM with Key - Value" srcset="
/community/media/blogs/handling-keys-in-ksql/withkey-value_hu0d59ac08b4969ca3f4e3160a7bf26c4e_19880_0336fd2f085a987b996ec3e8ca08ed91.webp 400w,
/community/media/blogs/handling-keys-in-ksql/withkey-value_hu0d59ac08b4969ca3f4e3160a7bf26c4e_19880_4d3e8ddaab41154738ee4a263ffa6f16.webp 760w,
/community/media/blogs/handling-keys-in-ksql/withkey-value_hu0d59ac08b4969ca3f4e3160a7bf26c4e_19880_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/withkey-value_hu0d59ac08b4969ca3f4e3160a7bf26c4e_19880_0336fd2f085a987b996ec3e8ca08ed91.webp"
width="760"
height="211"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
となります。IPがTopicのKeyに移っている事が確認できます。&lt;/p>
&lt;h2 id="keyをvalueの中にも持つ">KeyをValueの中にも持つ&lt;/h2>
&lt;p>先述した通り、StreamにおいてKeyを扱う事は混乱を招く恐れがある為、JOIN等明確な利用がある場合のみに利用する事が推奨されます。それでもJoinもするがValueの中でもKeyを参照する、つまりksqlDB内でKeyを参照したいというユースケースも存在します。&lt;/p>
&lt;p>この場合、KeyのコピーをValue内に持たせるする必要がありますが、ハックに近い対応が必要となります。&lt;/p>
&lt;p>KeyをValueにコピーする関数は存在し、&lt;a href="https://docs.ksqldb.io/en/latest/developer-guide/ksqldb-reference/scalar-functions/#as_value" target="_blank" rel="noopener">AS_VALUE&lt;/a>関数を利用すればコピー出来ます。&lt;/p>
&lt;p>しかしながら、&lt;code>AS_VALUE&lt;/code>はTableを前提とした関数であり、Tableには明示的に PRIMARYKEYを指定するのでKeyとそのフィールド名も参照出来ますが、Streamの場合にはKeyは必須ではありません。また、先程の&lt;code>Key&lt;/code>を利用した&lt;code>CREATE STREAM&lt;/code>の結果にあるように、Keyには値のみ、ここでは&lt;code>IP&lt;/code>で指定した値のみが入っています。なので&lt;code>AS_VALUE&lt;/code>を&lt;code>ROWKEY&lt;/code>に対して実行したいのですが：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TransformedEventsWithKey&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;events-with-key&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SELECT&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">AS_VALUE&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">ROWKEY&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TIME_IN_INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ClickstreamWithKey&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">EMIT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHANGES&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>このクエリは構文エラーとなります。&lt;code>AS_VALUE&lt;/code>はTableの&lt;code>PRIMARY KEY&lt;/code>は引数として受け付けますが、値だけのROWKEYは受け付けません。つまり&lt;code>AS_VALUE&lt;/code>は通常の使用法ではStreamに対しては利用出来ません。&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/p>
&lt;p>ハックとしての解答は以下になります：&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-sql" data-lang="sql">&lt;span class="line">&lt;span class="cl">&lt;span class="k">CREATE&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">STREAM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TransformedEventsWithKey&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">WITH&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">KAFKA_TOPIC&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;events-with-key&amp;#39;&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">VALUE_FORMAT&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s1">&amp;#39;JSON&amp;#39;&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">SELECT&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ROWKEY&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">AS_VALUE&lt;/span>&lt;span class="p">(&lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="p">)&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="k">AS&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">IP&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">USERID&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">_TIME&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">TIME_IN_INT&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">STATUS&lt;/span>&lt;span class="p">,&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w"> &lt;/span>&lt;span class="n">BYTES&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="k">FROM&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">ClickstreamWithKey&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl">&lt;span class="w">&lt;/span>&lt;span class="n">EMIT&lt;/span>&lt;span class="w"> &lt;/span>&lt;span class="n">CHANGES&lt;/span>&lt;span class="p">;&lt;/span>&lt;span class="w">
&lt;/span>&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>&lt;code>ROWKEY&lt;/code>に対して&lt;code>IP&lt;/code>というフィールド名を割り当て、そのフィールドを&lt;code>AS_VALUE&lt;/code>で利用する方法になります。上記クエリを分解解釈すると以下となります：&lt;/p>
&lt;ul>
&lt;li>StreamにはないPrimary Keyのフィールドを&lt;code>IP&lt;/code>として明示的に指定。&lt;/li>
&lt;li>そのフィールドを&lt;code>AS_VALUE&lt;/code>で参照。この際元々あるフィールドと同名で定義。&lt;/li>
&lt;/ul>
&lt;p>妙な構文になりますが、結果は：
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM with Key and Value - Key" srcset="
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-key_hub6bc2ca3d3546dcb19b585c16576dd32_11126_5546ce75955df420911d529bdf97456e.webp 400w,
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-key_hub6bc2ca3d3546dcb19b585c16576dd32_11126_0a613f4b5ee7def537bab3b886a6b798.webp 760w,
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-key_hub6bc2ca3d3546dcb19b585c16576dd32_11126_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/withkeyvalue-key_hub6bc2ca3d3546dcb19b585c16576dd32_11126_5546ce75955df420911d529bdf97456e.webp"
width="760"
height="123"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
&lt;figure >
&lt;div class="d-flex justify-content-center">
&lt;div class="w-100" >&lt;img alt="CREATE STREAM with Key and Value - Value" srcset="
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-value_hu40264929708375a514000712072b6e5e_22598_b0bd9f06a5173545c9ab68c6ef7e0eea.webp 400w,
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-value_hu40264929708375a514000712072b6e5e_22598_123f4688e4a7d7b0ddfa6a8b9e5fbce5.webp 760w,
/community/media/blogs/handling-keys-in-ksql/withkeyvalue-value_hu40264929708375a514000712072b6e5e_22598_1200x1200_fit_q75_h2_lanczos_3.webp 1200w"
src="https://confluent-jp.github.io/community/community/media/blogs/handling-keys-in-ksql/withkeyvalue-value_hu40264929708375a514000712072b6e5e_22598_b0bd9f06a5173545c9ab68c6ef7e0eea.webp"
width="760"
height="230"
loading="lazy" data-zoomable />&lt;/div>
&lt;/div>&lt;/figure>
と期待通りの結果となります。&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>このハック的なアプローチを見ると「ksqlDBは面倒くさい。直感的ではない。」と思うかも知れません。確かにハックだけを見るとその通りで、無意味な制約のようにも思えます。しかしながらこれには背景があり、より直感的なデータモデル定義へと変更した事による副作用である事を理解して頂ければと思います。また、ksqlDB、というよりデータフロー処理内でKeyを参照するというのは特殊な要件です。このハックを怪しい要件/ロジックのスメルと捉える事もできます。&lt;/p>
&lt;p>何より、やや面倒くさいksqlDBにおけるKeyの扱いを理解すると、ksqlDBの仕組みやデータモデルへの理解が深まります。ksqlDBの裏側を少し垣間見る機会と思って頂ければ幸いです。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>実際のステート管理はksqlDBが内部で利用する&lt;a href="https://docs.confluent.io/platform/current/streams/architecture.html#state" target="_blank" rel="noopener">Kafka Streamsの仕組み&lt;/a>を利用している。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2">
&lt;p>これはStreamの構文だからエラーではなく、そもそも&lt;code>AS_VALUE&lt;/code>に&lt;code>ROWKEY&lt;/code>を指定出来ないという仕様によるもの。&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Handling Keys in ksqlDB</title><link>https://confluent-jp.github.io/community/demo/demo-cc-ksqldb-handling-keys/</link><pubDate>Wed, 01 Nov 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/demo/demo-cc-ksqldb-handling-keys/</guid><description/></item><item><title>新コース - Event Modeling</title><link>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</link><pubDate>Mon, 17 Jul 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/developer-io-event-modeling/</guid><description>&lt;p>&lt;a href="developer.confluent.io">developer.confluent.io&lt;/a>にてEvent Modelingに関する新しいコースが発表されました。Event Modelingは情報システムのヴィジュアルデザイン手法で、システム間の非同期通信に利用されるイベントをblueprintという成果物を作成する形で設計します。&lt;/p>
&lt;p>UXやドメイン駆動設計と強い繋がりを持ち、複数人によるコラボレーションをビジュアルツールを使って設計するという点が特徴です。目的や手法は少し異なりますが、Alberto Brandoliniによる&lt;a href="https://www.eventstorming.com/" target="_blank" rel="noopener">Event Sourcing&lt;/a>と近い思想によるデザイン手法の一つです。&lt;/p>
&lt;p>マイクロサービスにおけるイベント駆動設計とは特に親和性の高い設計アプローチではないかと思います。&lt;/p></description></item><item><title>Queues for Kafkaとは何か?</title><link>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</link><pubDate>Fri, 30 Jun 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/blog/kip923-queues-for-kafka/</guid><description>&lt;h2 id="はじめに">はじめに&lt;/h2>
&lt;p>Apache Kafka® はメッセージキューと比較される事も多く、またメッセージキューとして利用される事も多くあります。&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-932%3A&amp;#43;Queues&amp;#43;for&amp;#43;Kafka" target="_blank" rel="noopener">KIP-932 Queues for Kafka&lt;/a> はそのKafkaに対してネイティブにメッセージキューとして利用する機能性を追加するKIPです。&lt;/p>
&lt;h2 id="consumer-group">Consumer Group&lt;/h2>
&lt;p>Kafkaは仕組み的にはメッセージキューではない、と言うのは語弊があるかも知れません。もう少し正確に説明すると「メッセージの順序保証 (Order Guarantee) を確保する為にスケールする際に制限がある」仕組みを採用しています。この仕組みはConsumer Groupと呼ばれ、Kafkaにおけるデータの分離単位であるPartition単位にメッセージの順序保証をするアプローチです。&lt;/p>
&lt;p>&lt;a href="https://www.confluent.io/blog/dynamic-vs-static-kafka-consumer-rebalancing/" target="_blank" rel="noopener">Consumer Group&lt;/a>はアプリケーションが任意に指定することができ、その管理はKafka Brokerにて稼働するConsumer Group Coordinatorというプロセスが行います。Consumer Group CoordinatorはGroupメンバーの追加/削除の自動検知とリバランスを担当し、Consumer Groupメンバーの追加/離脱やこれらの死活監視、グループメンバーシップをトリガーとした処理のリバランス (メンバーへのPartitionのリアサイン) を自動的に行います。Consumer Groupの仕組みは、ストリームアプリケーションの可用性と拡張性に重要な役割を担っています。&lt;/p>
&lt;p>一方、メッセージ処理の順序保証を前提としている為、 Partitionに複数のConsumerを設定する事が出来ず、この為Topicに指定するPartition数が並列処理能力の拡張性を決定します。 また、そもそも順序性の保証が不要なユースケースであってもConsumer Groupのルールに則らないといけないという制約は存在します。大容量のデータ処理 and/or 非常に柔軟な拡張性の制御が要求されるようなユースケースでは課題となり得る、というより歯痒い条件と見られる事もあります。&lt;/p>
&lt;h2 id="これまでのアプローチ">これまでのアプローチ&lt;/h2>
&lt;p>ほとんどのユースケースでは6、10、12といったベストプラクティスに沿ったPartition数を指定する事により、充分な並列処理能力と拡張性を確保することが出来ます。仮にどれだけの並列処理能力が求められるとしても、将来的にも1処理に対して24インスタンスによる並列処理が必要となる事が無いのであれば、Partition数を24としておけば安全圏です。一般的にはこのアプローチが多く取られます。&lt;/p>
&lt;p>&lt;a href="https://github.com/line/decaton" target="_blank" rel="noopener">LINE Decaton&lt;/a> はLINE Corporationが社内利用の為に開発しオープンソース化したKafkaライブラリです。大容量のストリーム処理を安定的に、かつKey単位の順序保証とAt Least Onceのデリバリを保証する事が可能です。&lt;/p>
&lt;p>&lt;a href="https://github.com/confluentinc/parallel-consumer" target="_blank" rel="noopener">Confluent Parallel Consumer&lt;/a> はConfluentがオープンソースで提供している分散処理Kafkaライブラリです。こちらもKey単位での順序保証をしており、&lt;a href="https://www.confluent.io/blog/introducing-confluent-parallel-message-processing-client/" target="_blank" rel="noopener">順序保証しない設定を含め柔軟に処理構成を変更&lt;/a>することが出来ます。&lt;/p>
&lt;h2 id="queue-for-kafka---kafka-nativeなアプローチ">Queue for Kafka - Kafka Nativeなアプローチ&lt;/h2>
&lt;p>Queues for KafkaはConsumer Groupと異なる新しいグループ化を提供するものです。Share Groupと呼ばれ、Partition数に影響なくメンバーを追加することが出来ます。&lt;/p>
&lt;p>Shared Groupは全く異なるインターフェースではなく、これまでのConsumer Groupと同列に扱われ、&lt;code>group.type&lt;/code>を&lt;code>share&lt;/code>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>と設定する事によって指定します。Consumer Groupの場合、Partition数を超えるメンバーを指定しても処理に参加できなかったり、Partition数をきっちり割り切れるメンバー数でないとアサインメントに偏りが出ますが、Share Groupの場合は任意のメンバー数を指定する事により均一かつ水平にスケールします。&lt;/p>
&lt;p>Consumer Groupと構成も同じで、BrokerのうちConsumer Group CoorinatorではなくShare Group Coordinatorを司るプロセスがグループメンバーの死活監視、リバランス等をConsumer Group同様に実施します。アプリケーション観点でもデプロイ観点でも、Consuemr Groupとの差はなく、あくまでプロパティ設定するのみでグループの振る舞いを変えることができます。&lt;/p>
&lt;h2 id="おわりに">おわりに&lt;/h2>
&lt;p>Kafkaというはそのシンプルな設計ゆえに、十分理解しないと活用が難しいイメージがありました。ただこのシンプルさによってスケーラビリティとあらゆるユースケースでの活用することができ、Kafkaの理解を深める事はより良い設計をする上で非常に重要です。KIP-932は、Kafka誕生から変わることの無かったConsumer Groupというアプローチとは異なるデータアクセスのパターンに対する変更という意味では非常に興味深いKIPです。&lt;/p>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;code>group.type&lt;/code>は新しいプロパティ。デフォルトは&lt;code>consumer&lt;/code>であり、この指定だと通常通りConsumer Groupとして機能する。デフォルトは&lt;code>consumer&lt;/code>である為下位互換性あり。&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Apache Kafka and the World of Streams</title><link>https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/</link><pubDate>Tue, 23 May 2023 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20230523-eventdriven-meetup/</guid><description/></item><item><title>Apache Kafka and the World of Streams</title><link>https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/</link><pubDate>Tue, 24 May 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220524-gcpug-tokyo/</guid><description/></item><item><title>Database Inside Out - Apache Kafka®️ と ksqlDB®️ によって広がるデータ活用</title><link>https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/</link><pubDate>Fri, 29 Apr 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220414-bigdata-jaws/</guid><description/></item><item><title>KafkaとksqlDBと Streaming DB - Commit Log Streamを捌くテクノロジー</title><link>https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/</link><pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220325-cloudnative-database/</guid><description/></item><item><title>マイクロサービスとデータとData Mesh - アプリは分けた。データはどうだ。</title><link>https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/</link><pubDate>Fri, 25 Mar 2022 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20220217-developers-summit-2022/</guid><description/></item><item><title>ksqlDB Clickstream Workshop</title><link>https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/</link><pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/demo/demo-cc-ksql-clickstream/</guid><description/></item><item><title>カフカはデータベースの夢をみるか - あるいはApache Kafkaの双対性という思想とksqlDBについて</title><link>https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/</link><pubDate>Fri, 24 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/talk/20210924-kafka-meetup/</guid><description/></item><item><title>Splunkにフィードされるネットワーク機器 (Cisco ASA) のログデータをConfluentで加工する実験環境</title><link>https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/</link><pubDate>Thu, 23 Sep 2021 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/demo/demo-cp-splunk-elastic/</guid><description/></item><item><title>Designing Event-Driven Systems</title><link>https://confluent-jp.github.io/community/publication/designing-event-driven-systems/</link><pubDate>Sun, 01 Apr 2018 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/publication/designing-event-driven-systems/</guid><description/></item><item><title>Kafka: The Definitive Guide</title><link>https://confluent-jp.github.io/community/publication/kafka-the-definitive-guide/</link><pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/publication/kafka-the-definitive-guide/</guid><description/></item><item><title>Making Sense of Stream Processing</title><link>https://confluent-jp.github.io/community/publication/making-sense-of-stream-processing/</link><pubDate>Tue, 01 Mar 2016 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/publication/making-sense-of-stream-processing/</guid><description/></item><item><title>I ❤️ Logs</title><link>https://confluent-jp.github.io/community/publication/i-heart-logs/</link><pubDate>Tue, 21 Oct 2014 00:00:00 +0000</pubDate><guid>https://confluent-jp.github.io/community/publication/i-heart-logs/</guid><description/></item></channel></rss>